[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Angewandte Datenverarbeitung und Visualisierung (WiSe23/24)",
    "section": "",
    "text": "Kursübersicht\nDies ist die Webseite der Lehrveranstaltung “Angewandte Datenverarbeitung und Visualisierung” an der Humboldt-Universität zu Berlin, Institut der deutschen Sprache und Linguistik für das Wintersemester 2023/24. Wenn Sie für den Kurs eingeschrieben sind, finden Sie alle relevanten Materialien auf dem Kurs Moodle hier (Moodle-Schlüssel wird in der Vorlesung bereitgestellt).\nJedes Kapitel entspricht einer Vorlesung von einer Woche. Vorerst werden die Materialien auf dieser Website im Bullet-Point-Format erscheinen und genau denselben Inhalt wie die Kursfolien enthalten. Ich plane, die Aufzählungspunkte später in Prosa umzuwandeln und die einzelnen Themen zu vertiefen."
  },
  {
    "objectID": "index.html#kursbeschreibung-auf-agnes",
    "href": "index.html#kursbeschreibung-auf-agnes",
    "title": "Angewandte Datenverarbeitung und Visualisierung (WiSe23/24)",
    "section": "Kursbeschreibung auf AGNES",
    "text": "Kursbeschreibung auf AGNES\n\nDies ist ein Einführungskurs in das Denken, Arbeiten und Kommunizieren mit / über sprachliche Daten. Der Kurs fokussiert sich auf praktische Anwendungen und die Vermittlung übertragbarer Fähigkeiten. In RStudio machen sich die Teilnehmenden sich mit der Programmiersprache R vertraut und entwickeln Fähigkeiten zur Erstellung und Vermittlung zusammenfassender Statistiken für den akademischen und beruflichen Kontext. Die Teilnehmenden lernen, Rohdaten zu laden und zu manipulieren, Tabellen mit deskriptiven Statistiken zu erstellen und die Daten angemessen visuell darzustellen. Am Ende des Kurses werden die Teilnehmenden ein besseres Verständnis dafür haben, wie man mit Daten umgeht und die Fähigkeiten besitzen, Ergebnisse klar zu kommunizieren. Studierende, die keinen eigenen Laptop zum Unterricht mitbringen können, setzen sich bitte so früh wie möglich mit der Dozentin in Verbindung, damit ein alternativer Laptop organisiert werden kann. Der Kurs wird auf Deutsch gehalten."
  },
  {
    "objectID": "index.html#ziele-des-kurses",
    "href": "index.html#ziele-des-kurses",
    "title": "Angewandte Datenverarbeitung und Visualisierung (WiSe23/24)",
    "section": "Ziele des Kurses",
    "text": "Ziele des Kurses\nDas Hauptziel dieses Kurses ist es, die Kenntnisse und Fähigkeiten zu entwickeln, die für die Durchführung einer “Explorativen Datenanalyse (EDA)” erforderlich sind. EDA ist kein formaler Prozess mit spezifischen Regeln, sondern vielmehr “a state of mind” (Wickham et al., 2023, Kapitel 11). Das Wissen, das für die Durchführung einer EDA erforderlich ist, besteht einfach darin, die Daten zu verstehen und ihre Struktur zu erforschen, um ein Verständnis für ihre Verteilung und Muster zu bekommen. Die für die Durchführung einer EDA erforderlichen Fähigkeiten sind spezifisch für die zur Durchführung der EDA verwendete Sprache, in unserem Fall R."
  },
  {
    "objectID": "index.html#ressourcen",
    "href": "index.html#ressourcen",
    "title": "Angewandte Datenverarbeitung und Visualisierung (WiSe23/24)",
    "section": "Ressourcen",
    "text": "Ressourcen\nDie meisten unserer Materialien basieren auf dem Buch “R for Data Science” von Hadley Wickham (2. Auflage), das Sie hier vollständig online einsehen können. Wo es möglich war, habe ich die in diesem Buch verwendeten Daten durch linguistische Datensätze ersetzt, damit Sie sich ein Bild davon machen können, wie Linguisten R verwenden könnten.\nEinige andere Ressourcen, die wir von Zeit zu Zeit verwenden werden oder die Sie vielleicht selbst erkunden möchten, sind das E-book Data visualisation using R, for researchers who don’t use R (Nordmann et al., 2022) und das Lehrbuch Statistics for Linguists: An Introduction Using R by Bodo Winter [Winter (2019); PDF erhältlich über das Grimm Zentrum].\n\n\n\n\n\n\nNordmann, E., McAleer, P., Toivo, W., Paterson, H., & DeBruine, L. M. (2022). Data Visualization Using R for Researchers Who Do Not Use R. Advances in Methods and Practices in Psychological Science, 5(2), 251524592210746. https://doi.org/10.1177/25152459221074654\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for Data Science (2. Aufl.).\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Die vorgeschlagene Lektüre erleichtert die Arbeit mit dem Material für jede Woche. Die Lektüre umfasst Kapitel oder Abschnitte aus Nordmann et al. (2022) (web tutorial), Wickham et al. (2023) (E-book), and Winter (2019) (PDF verfügbar über die Grimm-Bibliothek).\n\n\n\n\n\n\n  \n    \n    \n    \n    \n  \n  \n    \n    \n      Woche\n      Datum\n      Thema\n      Vorbereitung\n    \n  \n  \n    1\n18.10.2023\nEinführung in R und RStudio\n\n📚 R4DS - Ch 1 (Introduction) \n📚 R4DS - Ch 3 (Workflow: Basics)\n\n    2\n25.10.2023\nData Viz 1: Verteilungen\n\n📚 R4DS - Ch 2 (Data visualization), Abschnitte 2.1-2.4\n\n    3\n01.11.2023\nDynamische Berichte mit Quarto\n\n📚 R4DS - Ch 29 (Quarto)\n\n    4\n08.11.2023\nWrangling 1: Umwandlung von Daten\n\n📚 R4DS - Ch 4 (Data transformation)\n\n    5\n15.11.2023\nData Viz 2: Visualisierung von Beziehungen\n\n📚 R4DS - Ch 5 (Workflow: code style)\n\n    6\n22.11.2023\nBericht 1\n\n\n    7\n29.11.2023\nDaten einlesen\n\n📚 R4DS - Ch 8 (Data import)\n\n    8\n06.12.2023\nWrangling 2: Tidying data\n\n📚 R4DS - Ch 6 (Data tidying)\n\n    9\n13.12.2023\nDeskriptive Statistik\n\n📚 Winter (2019) - Ch 3 (Descriptive statistics, models, and distributions)\n\n    10\n20.12.2023\nData Viz 3: Visualisierung von Zusammenfassungen\n\n📚 R4DS - Ch 2 (Data visualization), Abschnitte 2.5 \n📚 Nordmann et al. (2002) - Ch 4 (Representing Summary Statistics), Abschnitte 2.5\n\n    Vorlesungsfrei\n27.12.2023\nNA\n\n🎿\n\n    Vorlesungsfrei\n03.01.2024\nNA\n\n🎿\n\n    11\n10.01.2024\nBericht 2\n\n\n    12\n17.01.2024\nEinführung in Base R\n\n📚 R4DS - Ch 28 (A field guide to base R)\n\n    13\n24.01.2024\nRegular expressions\n\n📚 R4DS - Ch 16 (Regular expressions)\n\n    14\n31.01.2024\nData Viz 4: Kommunikation\n\n📚 R4DS - Ch 12 (Communication)\n\n    15\n07.02.2024\nBericht 3\n\n\n    16\n14.02.2024\nOffene Sitzung: Q&A\n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\nNordmann, E., McAleer, P., Toivo, W., Paterson, H., & DeBruine, L. M. (2022). Data Visualization Using R for Researchers Who Do Not Use R. Advances in Methods and Practices in Psychological Science, 5(2), 251524592210746. https://doi.org/10.1177/25152459221074654\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for Data Science (2. Aufl.).\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547"
  },
  {
    "objectID": "setup/setup.html",
    "href": "setup/setup.html",
    "title": "Erforderliche Software",
    "section": "",
    "text": "R und RStudio\nUm an diesem Kurs teilnehmen zu können, müssen Sie R und RStudio installieren.\nR ist eine statistische Programmiersprache, die für statistische Berechnungen und grafische Darstellungen verwendet wird. Am häufigsten wird sie zur Analyse und Visualisierung von Daten verwendet, beides werden wir in diesem Semester tun. RStudio ist eine IDE (integrierte Entwicklungsumgebung) für R und andere Sprachen. RStudio macht die Analyse und Visualisierung von Daten in R viel einfacher (glauben Sie mir, als ich mit R anfing, gab es kein RStudio!).\nSie müssen R herunterladen, bevor Sie RStudio herunterladen können.\nIm weiteren Verlauf des Kurses werden wir lernen, wie man verschiedene Ausgabeformate, einschließlich PDF, erzeugt. Um PDF-Dokumente mit LaTeX unter der Haube darstellen zu können, müssen wir tinytex installieren. Es gibt verschiedene Möglichkeiten, dies zu tun:\nSie können diesen Schritt vorerst überspringen, falls Sie Probleme haben."
  },
  {
    "objectID": "setup/setup.html#sec-packages",
    "href": "setup/setup.html#sec-packages",
    "title": "Erforderliche Software",
    "section": "Pakete",
    "text": "Pakete\nR-Pakete, die im Comprehensive R Archive Network, allgemein bekannt als CRAN-Repository, verfügbar sind, können einfach mit dem Befehl install.packages(\"packageName\") installiert werden. Einige Pakete, die wir brauchen werden, sind:\n\n\nhere Paket (Müller, 2020)\n\n\ntidyverse-Paketfamilie (Wickham et al., 2019)\n\nenthält automatisch Pakete, die wir brauchen, wie dplyr und ggplot2\n\n\n\n\nlanguageR-Paket (Baayen & Shafaei-Bajestan, 2019)\n\n\nUm mehrere Pakete auf einmal herunterzuladen, verwenden Sie die ‘concatenate’-Funktion in r (c()) innerhalb von install.packages():\n\ninstall.packages(c(\"here\", \n                   \"tidyverse\",\n                   \"pacman\"))"
  },
  {
    "objectID": "setup/setup.html#rstudio-globale-optionen-optional",
    "href": "setup/setup.html#rstudio-globale-optionen-optional",
    "title": "Erforderliche Software",
    "section": "RStudio Globale Optionen (optional)",
    "text": "RStudio Globale Optionen (optional)\nHier sind meine bevorzugten globalen Optionen (RStudio &gt; Werkzeuge &gt; Globale Optionen). Ich empfehle dringend, die Einstellungen für “Arbeitsbereich” und “R-Sitzungen” zu befolgen, um die Reproduzierbarkeit zu gewährleisten. Mit den anderen Einstellungen können Sie herumspielen, um herauszufinden, was Ihnen gefällt.\n\nAllgemein &gt; Grundeinstellungen\n\n\nArbeitsbereich (für reproduzierbare Arbeitsabläufe!!!)\n\nDeaktivieren Sie das Kontrollkästchen “.RData beim Starten in Arbeitsbereich wiederherstellen”.\nArbeitsbereich beim Beenden in .RData speichern: Niemals\n\n\n\n\nR-Sitzungen\n\nDeaktivieren Sie das Kontrollkästchen “Zuvor geöffnete Quelldokumente beim Start wiederherstellen”.\n\n\n\n\nCode &gt; Anzeige\n\nAllgemein\n\nLeerzeichen anzeigen\nScrollen über das Ende des Dokuments hinaus zulassen\nAusgewählte Zeile hervorheben\n\n\n\n\nErscheinungsbild\n\nEditor-Thema: Kobalt"
  },
  {
    "objectID": "mats/01-intro_r.html#heutige-ziele",
    "href": "mats/01-intro_r.html#heutige-ziele",
    "title": "1  Einführung in R und RStudio",
    "section": "Heutige Ziele",
    "text": "Heutige Ziele\n\nR und RStudio installieren\nin der Lage sein, Zusatzpakete zu installieren\nin der Lage sein, Hilfe für Pakete und Funktionen zu erhalten\nin der Lage sein, Objekte in der Konsole zu erstellen"
  },
  {
    "objectID": "mats/01-intro_r.html#weitere-lektüre",
    "href": "mats/01-intro_r.html#weitere-lektüre",
    "title": "1  Einführung in R und RStudio",
    "section": "Weitere Lektüre",
    "text": "Weitere Lektüre\n\nDieser Vortrag basiert lose auf Kapitel 1 - Introduction und Kapitel 3 - Workflow Basics von Wickham et al. (2023)\ndieser Kurs folgt mehr oder weniger diesem Buch\nwo möglich, ersetze ich die Datensätze im Buch durch linguistische Datenbeispiele"
  },
  {
    "objectID": "mats/01-intro_r.html#vorbereitung",
    "href": "mats/01-intro_r.html#vorbereitung",
    "title": "1  Einführung in R und RStudio",
    "section": "1.1 Vorbereitung",
    "text": "1.1 Vorbereitung\n\nhoffentlich haben Sie R und RStudio bereits installiert/aktualisiert\n\nfalls nicht: Versuchen Sie es mit Posit Cloud für heute posit.cloud\n\nGehen Sie zum Kurs GitHub und laden Sie eine ZIP-Datei des Repositorys herunter\n\ngroße grüne Schaltfläche ‘&lt;&gt; Code’ &gt; ZIP herunterladen\n\n\n\n\n\n\n\nDownload GitHub repositiory"
  },
  {
    "objectID": "mats/01-intro_r.html#rprojekt",
    "href": "mats/01-intro_r.html#rprojekt",
    "title": "1  Einführung in R und RStudio",
    "section": "1.2 RProjekt",
    "text": "1.2 RProjekt\n\nSuchen Sie die ZIP-Datei, die Sie soeben heruntergeladen haben, auf Ihrem Computer und dekomprimieren Sie sie.\nÖffnen Sie den Ordner und navigieren Sie zu r4ling_student.Rproj, doppelklicken Sie darauf\nSie sollten nun RStudio sehen, wie in Abbildung 1.1\nJetzt können wir an unserem ersten Skript arbeiten\n\n\n\n\n\n\nAbbildung 1.1: Student RProject\n\n\n\n\n\n\n\n\n\n\n\nWarnung\n\n\n\nWichtig!!\nVerschieben oder benennen Sie den Ordner data/ nicht um! Sie müssen denselben Dateipfad zu den Datensätzen haben, um meinen Code in den nächsten Wochen nahtlos verwenden zu können."
  },
  {
    "objectID": "mats/01-intro_r.html#r-in-rstudio",
    "href": "mats/01-intro_r.html#r-in-rstudio",
    "title": "1  Einführung in R und RStudio",
    "section": "1.3 R in RStudio",
    "text": "1.3 R in RStudio\n\nÖffnen Sie RStudio immer durch einen Doppelklick auf r4ling_student.Rproj (für diesen Kurs)\nklicken Sie auf File &gt; New File &gt; R Script\n\nsehen Sie nun vier Quadrate (statt 3 in Abbildung 1.1):\n\n\nTexteditor - oben Links - wo wir unseren Code schreiben werden\nR-Konsole (EN: Console) - unten links - wo wir die Ausgabe unseres Codes und Warn-/Fehlermeldungen sehen werden\nArbeitsumgebung (EN: Environment) - oben rechts - wo unsere Daten und Objekte nach dem Laden gespeichert werden\nDateien und Grafikausgabe - unten links - wo wir unsere Dateien und die von uns erstellten Grafiken sehen oder Hilfe bekommen können\n\n\n\n1.3.1 Erweitungspakete\n\nR hat eine Reihe von nativen Funktionen und Datensätzen, auf die wir zugreifen können\n\nähnlich wie die Standard-Apps, die auf Ihrem Handy vorinstalliert sind\n\nJeder kann Zusatzpakete für R erstellen, z.B.,\n\nfür Datenvisualisierung\nDatenverarbeitung\n\nDies ist ähnlich wie bei Handy-Apps, die von jedem erstellt und auf Ihr Gerät heruntergeladen werden können\n\naber Pakete sind immer kostenlos\n\nEs gibt 2 Schritte, um ein Paket zu verwenden:\n\nInstallieren des Pakets (einmalig) mit install.packages(\"Paket\")\nLaden Sie das Paket (zu Beginn jeder Sitzung) library(Paket)\n\n\n\n1.3.1.1 Paket-Installation\n\nerfolgt mit der Funktion install.packages()\n\nSie machen dies nur einmal (wie das Herunterladen einer App)\n\ndas Paket tidyverse ist sehr hilfreich für Datenverarbeitung und Visualisierung\n\nInstallieren wir es jetzt\n\n\n\n\nPaket-Installation\n\ninstallieren Sie die Pakete tidyverse und beepr\n\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"beepr\")\n\n\n\n\n\n\n\nPakete in der Konsole installieren\n\n\n\nInstallieren Sie Pakete immer über die Konsole, nicht über ein Skript!\nSie können auch die Registerkarte “Pakete” in der unteren rechten Box verwenden (Pakete &gt; Installieren)\n\n\n\n\n1.3.1.2 tinytex\n\nwir brauchen auch LaTeX und tinytex (Xie, 2023), um PDF-Dokumente zu erstellen\nführen Sie diesen Code aus, um tinytex zu installieren\n\n\n## run this in the console\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n\n\nSie müssen auch LaTeX installieren, wenn Sie es noch nicht haben: https://www.latex-project.org/get/\n\n\n\n\n1.3.2 Laden eines Pakets\n\ndie Funktion library() lädt ein Paket in Ihre Umgebung\ndies muss zu Beginn jeder Sitzung geschehen, um auf das entsprechende Paket zugreifen zu können\n\n\nlibrary(beepr)\n\n\n1.3.2.1 Verwendung einer Funktion\n\nSobald Sie ein Paket geladen haben, können Sie auf dessen Funktionen zugreifen\nZum Beispiel hat das Paket beepr eine Funktion beep(), probieren wir sie aus\n\n\n\n\nin der Konsole laufen\n\nbeep()\n\n\n\n\n1.3.2.2 Funktionsargumente\n\nArgumente enthalten optionale Informationen, die an eine Funktion übergeben werden\n\nDie Funktion beep() hat das Argument sound, das einen numerischen Wert von 1:11 annimmt.\nVersuchen Sie, den folgenden Code mit anderen Zahlen auszuführen, was passiert?\n\n\n\n\n\nin der Konsole laufen\n\nbeep(sound = 5)\n\n\n\n\nFunktionsargumente\n\n\n\n\n\n\n?help\n\n\n\nSie können mehr über eine Funktion (einschließlich ihrer verfügbaren Argumente) herausfinden, indem Sie ihren Namen nach einem Fragezeichen in die Konsole schreiben (z.B. ?beep). Versuchen Sie, ?beep auszuführen. Kannst du auf der Hilfeseite herausfinden, was du anstelle von sound = 5 schreiben kannst, um denselben Ton zu erzeugen?\n\n\n\n\n\n1.3.3 Aufgabe: Paket-Installation\n\n\n\n\n\n\nAufgabe\n\n\n\nWir brauchen auch das here-Paket. Installieren Sie dieses.\nNachdem Sie das Paket installiert haben, führen Sie den Befehl here() aus. Was geschieht?"
  },
  {
    "objectID": "mats/01-intro_r.html#reproduzierbarkeit",
    "href": "mats/01-intro_r.html#reproduzierbarkeit",
    "title": "1  Einführung in R und RStudio",
    "section": "1.4 Reproduzierbarkeit",
    "text": "1.4 Reproduzierbarkeit\n\nin diesem Kurs werden wir lernen, wie man reproduzierbare Berichte erstellt\n\nDas bedeutet, dass unser Code später noch einmal ausgeführt werden kann und immer noch die gleichen Ergebnisse liefert\n\nwenn Ihre Arbeit reproduzierbar ist, können andere Leute (und Sie selbst) Ihre Arbeit verstehen und überprüfen\n\nFür Kursaufgaben werden Sie Berichte sowie den Quellcode einreichen, die ich auf meinem Rechner ausführen können sollte\n\n\n\n1.4.1 RStudio-Einstellungen\n\nwir wollen immer mit einem freien Arbeitsbereich in RStudio beginnen, um die Reproduzierbarkeit zu gewährleisten\n\nWir wollen auch niemals unseren Arbeitsbereich für später speichern\nwir wollen nur unseren Code (und die Ausgabeberichte) speichern\n\nGehen Sie zu Tools &gt; Global Options\n\nDeaktivieren Sie das Kontrollkästchen Restore .RData into workspace at startup\nSetzen Sie Save workspace to .RData on exit: to Never\n\n\n\n\nRStudio-Einstellungen\n\n\nRStudio: Tools &gt; Global Options:\n\nRestore .RData into workspace at startup\n\nnein\n\nSave workspace to .RData on exit:\n\nNever\n\n\n\n\n\n\n\n\n\nIhre ‘Global Options’ sollten wie folgt aussehen\n\n\n\n\n\n\nRStudio-Einstellungen\n\nKlicken Sie auf Appearance (linke Spalte)\n\nÖffnen Sie die Optionen “Editor Theme” und wählen Sie ein Farbschema, das Ihnen gefällt\nSie können auch die Schriftart/Schriftgröße ändern, wenn Sie dies wünschen\n\n\n\n\n1.4.2 Aufgabe: neues R-Skript\n\n\n\n\n\n\nAufgabe\n\n\n\n\nin RStudio: File &gt; New File &gt; R Script\n\nwenn sich oben links ein neues Fenster öffnet: “Datei &gt; Speichern unter…”.\n\nspeichern Sie es in Ihrem ‘notizen’ Ordner\n\nschreiben Sie oben in das Skript: ## Angewandte Datenverarbeitung und Visualisierung - Woche 1 (17.04.2023)\n\n\n\n\n\n\n\n\n\nIhre Skript (oben links) sollten so aussehen"
  },
  {
    "objectID": "mats/01-intro_r.html#rechnen-in-r",
    "href": "mats/01-intro_r.html#rechnen-in-r",
    "title": "1  Einführung in R und RStudio",
    "section": "1.5 Rechnen in R",
    "text": "1.5 Rechnen in R\n\nkönnen wir Berechnungen in R durchführen\nwir können addieren (+), subtrahieren (-), multiplizieren (*) und dividieren (/)\n\n\n1.5.1 Aufgabe: Berechnungen\n\n\n\n\n\n\nAufgabe\n\n\n\n\nVersuchen Sie, die folgenden Berechnungen in der Konsole auszuführen:\n\n\n# Addition\n16+32\n\n[1] 48\n\n\n\n# Multiplikation\n16*32\n\n[1] 512\n\n\n\n# Subtraktion\n16-32\n\n[1] -16\n\n\n\n# Division\n16/32\n\n[1] 0.5\n\n\n\nschreiben Sie diese Berechnungen in Ihr Skript, und drücken Sie Cmd/Strg-Enter, um sie auszuführen\n\n\nWas passiert?\n\n\n\n\n\n1.5.2 Kommentare\n\nSie haben vielleicht bemerkt, dass in meinen Code-Blöcken z. B. # Subtraktion über dem Code stand\nR ignoriert jeden Text nach # (plus ein Leerzeichen )\nalso können wir Kommentare nach # schreiben\n\n\n# Kommentar zum folgenden Code\n16-32\n\n[1] -16\n\n\n\nWir können auch eine Abschnittsüberschrift erstellen, um unsere R-Skripte zu strukturieren, indem wir vier # nach einem Titel hinzufügen\nDie Struktur des Skripts kann dann durch Klicken auf die Schaltfläche “Gliederung” oberhalb des Skriptfensters angezeigt werden\n\n\n# Rechnen mit R ####\n\n# Subtraction\n16-32\n\n[1] -16\n\n\n\n\n1.5.3 Objekte\n\nwir können auch Werte als Objekte/Variablen speichern, die in der Arbeitsumgebung gespeichert sind\n\n\nx &lt;- 16\ny &lt;- 32\n\n\n\n\n\n\n\nAssignment operator\n\n\n\nDas Symbol &lt;- ist ein sogenannter assignment operator. Es erstellt ein neues Objekt in Ihrer Arbeitsumgebung oder überschreibt ein vorhandenes Objekt mit demselben Namen. Es ist wie ein Pfeil, der sagt: “Nimm das, was rechts steht, und speichere es als den Objektnamen auf der linken Seite”.\n\n\n\n\n1.5.4 Rechnen mit Funktionen\n\nes gibt auch eingebaute Funktionen für komplexere Berechnungen\nz.B., mean() (DE: Durchschnitt), sum() (DE: Summe)\nwas passiert, wenn wir folgendes ausführen?\n\n\nsum(6,10)\n\n[1] 16\n\n\n\n6+10\n\n[1] 16\n\n\n\nmean(6,10)\n\n[1] 6\n\n\n\n(6+10)/2\n\n[1] 8\n\n\n\n\nRechnen mit Funktionen\n\ndie Funktion mean() nimmt nur ein Argument an; alles andere wird ignoriert\n\ndas Komma in 6,10 listet 2 Argumente auf, also wird alles nach dem Komma ignoriert\n\nwenn wir mehr als ein Objekt in ein Argument einschließen wollen, müssen wir die “concatenate”-Funktion c() verwenden\n\n“concatenate” bedeutet zusammenfügen oder kombinieren\n\n\n\nmean(c(6,10))\n\n[1] 8\n\n\n\n\nRechnen mit Funktionen\n\nSie können auch benannte Objekte (d.h. die in Ihrer Arbeitsumgebung) verwenden, die einen numerischen Wert haben\n\n\n\n\n\n\n\nAufgabe: Rechnen mit Funktionen\n\n\n\n\nVersuchen Sie, die Funktion mean() mit Ihren gespeicherten Variablen (x und y) als “verkettete” Argumente auszuführen\nMachen Sie dasselbe mit der Funktion sum(). Was passiert, wenn Sie c() nicht verwenden?"
  },
  {
    "objectID": "mats/01-intro_r.html#vektoren",
    "href": "mats/01-intro_r.html#vektoren",
    "title": "1  Einführung in R und RStudio",
    "section": "1.6 Vektoren",
    "text": "1.6 Vektoren\n\nVektoren sind eine Liste von Elementen desselben Typs (z. B. numerisch, Zeichenkette)\nwir können einen Vektor mit der Verkettungsfunktion c() erstellen\nDer folgende Code speichert in einem Objekt namens ‘vec’ einen Vektor aus mehreren Zahlen\n\n\n# einen Vektor erstellen\nvec &lt;- c(171, 164, 186, 191)\n\n\nder folgende Code ruft das Objekt auf, das wir als ‘vec’ gespeichert haben, und gibt seinen Inhalt aus\n\n\n# print vec\nvec\n\n[1] 171 164 186 191\n\n\n\n1.6.1 Arithmetic mit Vektoren\n\nGrundlegende Arithmetik auf Vektoren wird auf jedes Element angewendet\n\n\n# add 5 to vec\nvec + 5\n\n[1] 176 169 191 196\n\n\n\nkönnen wir auch Funktionen auf Vektoren anwenden\n\n\n# Summe von vec\nsum(vec)\n\n[1] 712\n\n\n\n# Mittelwert von vec\nmean(vec)\n\n[1] 178\n\n\n\n# Quadratwurzel aus vec\nsqrt(vec)\n\n[1] 13.07670 12.80625 13.63818 13.82027\n\n\n\n\n1.6.2 Ausgabe: Vektoren\n\n\n\n\n\n\nAusgabe\n\n\n\n\nErstelle einen Vektor namens vec1, der die Werte 12, 183, 56, 25 und 18 enthält\nErstellen Sie einen Vektor namens vec2, der die Werte 8, 5, 1, 6 und 8 enthält\nCreate a vector called vec3 that contains the values 28, 54, 10, 13, 2, and 81\nFinde die Summe von vec1.\nFinde die Summe von vec1 plus vec2. Wie unterscheidet sich das Ergebnis von dem, das Sie für vec1 allein erhalten haben?\nWas passiert, wenn du versuchst, die Summe von vec1 und vec3 zu finden?"
  },
  {
    "objectID": "mats/01-intro_r.html#endergebnis",
    "href": "mats/01-intro_r.html#endergebnis",
    "title": "1  Einführung in R und RStudio",
    "section": "1.7 Endergebnis",
    "text": "1.7 Endergebnis\n\nSpeichern Sie Ihr R-Skript (File &gt; Save, oder Cmd/Strg-S)\nSie sollten nun einen RProject-Ordner für diesen Kurs, der Folgendes enthält:\n\nr4ling_student.RProj`\neinen Ordner namens Daten\neinen Ordner namens notes, der Folgendes enthält + eine .R-Datei mit der heutigen Arbeit\n\nSie wissen jetzt, wie man\n\neinfache Berechnungen in R durchführen\nObjekte in Ihrer Arbeitsumgebung zu speichern\neinfache mathematische Berechnungen mit Ihren gespeicherten Objekten durchführen"
  },
  {
    "objectID": "mats/01-intro_r.html#session-info",
    "href": "mats/01-intro_r.html#session-info",
    "title": "1  Einführung in R und RStudio",
    "section": "1.8 Session Info",
    "text": "1.8 Session Info\n\nUm die Reproduzierbarkeit zu verbessern, ist es nützlich, die Version von R, RStudio und die verwendeten Pakete zu verfolgen\n\nZu diesem Zweck können Sie die folgenden Befehle ausführen:\n\n\n\n## R version\nR.version.string\n\n[1] \"R version 4.3.0 (2023-04-21)\"\n\n## R version name\nR.version$nickname\n\n[1] \"Already Tomorrow\"\n\n\n\n## RStudio version\nRStudio.Version()$version\n## RStudio version name\nRStudio.Version()$release_name\n\n\n## alle Paketeversionen\nsessionInfo()"
  },
  {
    "objectID": "mats/01-intro_r.html#nächste-woche",
    "href": "mats/01-intro_r.html#nächste-woche",
    "title": "1  Einführung in R und RStudio",
    "section": "1.9 Nächste Woche",
    "text": "1.9 Nächste Woche\nvor nächster Woche, stellen Sie bitte sicher, dass Sie:\n\nR und RStudio installiert/aktualisiert haben\ndie Pakete tidyverse und here installiert haben\nbitte stellen Sie sicher, dass Sie die Übungen des heutigen Kurses in Ihrem R-Skript durcharbeiten\n(optional) speichern Sie das Skript, und laden Sie es auf Moodle hoch, wenn Sie es auf Ihre 6 Skripte für die Teilnahme-LP anrechnen lassen möchten\n\n\nSession Info\nHergestellt mit R version 4.3.0 (2023-04-21) (Already Tomorrow) und RStudioversion 2023.3.0.386 (Cherry Blosson).\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] beepr_1.3    magick_2.7.4\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.33     fastmap_1.1.1     xfun_0.39         magrittr_2.0.3   \n [5] glue_1.6.2        stringr_1.5.0     audio_0.1-10      knitr_1.44       \n [9] htmltools_0.5.5   png_0.1-8         rmarkdown_2.22    lifecycle_1.0.3  \n[13] cli_3.6.1         compiler_4.3.0    rprojroot_2.0.3   here_1.0.1       \n[17] rstudioapi_0.14   tools_4.3.0       evaluate_0.21     Rcpp_1.0.11      \n[21] yaml_2.3.7        rlang_1.1.1       jsonlite_1.8.7    htmlwidgets_1.6.2\n[25] stringi_1.7.12"
  },
  {
    "objectID": "mats/01-intro_r.html#literaturverzeichnis",
    "href": "mats/01-intro_r.html#literaturverzeichnis",
    "title": "1  Einführung in R und RStudio",
    "section": "Literaturverzeichnis",
    "text": "Literaturverzeichnis\n\n\nBaayen, R. H. (2008). Analyzing Linguistic Data:\nA Practical Introduction to Statistics using\nR.\n\n\nBaayen, R. H., & Shafaei-Bajestan, E. (2019). languageR:\nAnalyzing linguistic data: A practical introduction to statistics.\nhttps://CRAN.R-project.org/package=languageR\n\n\nBiondo, N., Soilemezidi, M., & Mancini, S. (2022). Yesterday is\nhistory, tomorrow is a mystery: An eye-tracking\ninvestigation of the processing of past and future time reference during\nsentence reading. Journal of Experimental Psychology: Learning,\nMemory, and Cognition, 48(7), 1001–1018. https://doi.org/10.1037/xlm0001053\n\n\nDavies, R., Locke, S., & D’Agostino McGowan, L. (2022).\ndatasauRus: Datasets from the datasaurus dozen. https://CRAN.R-project.org/package=datasauRus\n\n\nMüller, K. (2020). Here: A simpler way to find your files. https://CRAN.R-project.org/package=here\n\n\nNordmann, E., & DeBruine, L. (2022). Applied data skills.\nZenodo. https://doi.org/10.5281/zenodo.6365078\n\n\nNordmann, E., McAleer, P., Toivo, W., Paterson, H., & DeBruine, L.\nM. (2022). Data Visualization Using R for Researchers\nWho Do Not Use R. Advances in Methods and Practices in\nPsychological Science, 5(2), 251524592210746. https://doi.org/10.1177/25152459221074654\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D.,\nFrançois, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M.,\nPedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J.,\nRobinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to\nthe tidyverse. Journal of Open Source\nSoftware, 4(43), 1686. https://doi.org/10.21105/joss.01686\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for\nData Science (2nd ed.).\n\n\nWinter, B. (2019). Statistics for Linguists: An\nIntroduction Using R. In Statistics for Linguists: An\nIntroduction Using R. Routledge. https://doi.org/10.4324/9781315165547\n\n\nXie, Y. (2023). Tinytex: Helper functions to install and maintain\nTeX live, and compile LaTeX documents. https://github.com/rstudio/tinytex"
  },
  {
    "objectID": "mats/02-dataviz_1.html#wiederholung",
    "href": "mats/02-dataviz_1.html#wiederholung",
    "title": "2  Datenvisualiserung 1",
    "section": "Wiederholung",
    "text": "Wiederholung\nLetzte Woche haben wir…\n\nR und RStudio installiert\nunser erstes R-Skript erstellt\neinfache Arithmetik mit Objekten und Vektoren durchgeführt\n\n\nWiederholung\n\nx &lt;- c(1,2,3)\ny &lt;- sum(1,2,3)\n\n\n\nWas enthalten die Vektoren x und y?\nDas Objekt x enthält 1, 2, 3\nDas Objekt y enthält ` 6 ``"
  },
  {
    "objectID": "mats/02-dataviz_1.html#heutige-ziele",
    "href": "mats/02-dataviz_1.html#heutige-ziele",
    "title": "2  Datenvisualiserung 1",
    "section": "Heutige Ziele",
    "text": "Heutige Ziele\nHeute werden wir lernen…\n\nwas Datenframes sind\nden Unterschied zwischen kategorialen und kontinuierlichen Daten\nwie man Diagramme mit ggplot erstellt\ndie richtige Darstellung für unsere Daten auszuwählen\n\n\nEndgültiges Ziel\n\nUnser heutiges Ziel ist es, die Daten wie folgt zu visualisieren\n\nDas Diagramm zeigt die Verteilung (Anzahl) der Reaktionszeiten und der Muttersprache der Teilnehmer\n\n\n\n\n\n\n\n\n\nLust auf mehr?\n\nKapitel 2 (Datenvisualisierung) in Wickham et al. (2023), bis zum Abschnitt 2.4\nKapitel 3 (Datenvisualisierung) in Nordmann & DeBruine (2022)\n\n\n\nVorbereitung\nIn Ihrem RProject-Ordner…\n\nerstellen Sie einen neuen Ordner mit dem Namen moodle\n\nLaden Sie die Moodle-Materialien von heute herunter und speichern Sie sie dort\n\nErstellen Sie einen neuen Ordner in notes mit dem Namen 02-datenviz1\nöffne ein neues .R Skript\n\nspeichere es in dem neuen Ordner\n\n\n\n2.0.0.1 Pakete\n\nPakete laden (und installieren)\n\ntidyverse\nlanguageR\nggthemes\npatchwork\n\n\n\n## in the CONSOLE: install packages if needed\ninstall.packages(\"tidyverse\")\ninstall.packages(\"languageR\")\ninstall.packages(\"ggthemes\") ## for customising our plots\ninstall.packages(\"patchwork\") ## plot layouts\n\n\n## Pakete laden\nlibrary(tidyverse)\nlibrary(languageR)\nlibrary(ggthemes)\nlibrary(patchwork)"
  },
  {
    "objectID": "mats/02-dataviz_1.html#datenrahmen",
    "href": "mats/02-dataviz_1.html#datenrahmen",
    "title": "2  Datenvisualiserung 1",
    "section": "2.1 Datenrahmen",
    "text": "2.1 Datenrahmen\n\nDatenrahmen sind eine Sammlung von Variablen, wobei\n\njede Variable eine Spalte ist\njede Zeile eine einzelne Beobachtung/ein einzelner Datenpunkt ist\njede Zelle in einer Zeile verknüpft ist\n\nDatenrahmen sind genau wie Tabellenkalkulationen, aber rechteckig\nVerschiedene Wörter für Datenrahmen:\n\nDatenrahmen\nDatensatz\nTibble (im tidyverse)\n\n\n\n2.1.1 Sprechen über Datensätze\n\neine Variable: eine Menge, Qualität oder Eigenschaft, die man messen kann\nein Wert: der Zustand einer Variablen, wenn man sie misst\neine Beobachtung: eine Reihe von Messungen, die unter ähnlichen Bedingungen durchgeführt werden\n\nenthält mehrere Werte, die jeweils mit einer Variablen verbunden sind\neine Beobachtung für eine einzelne Variable wird manchmal als Datenpunkt bezeichnet\n\nTabellendaten sind eine Reihe von Werten, die jeweils mit einer Variablen und einer Beobachtung verbunden sind\n\nTabellarische Daten sind “tidy”, wenn jeder Wert in einer eigenen Zelle, jede Variable in einer eigenen Spalte und jede Beobachtung in einer eigenen Zeile steht\n\n\n\n\n2.1.2 Kategoriale und kontinuierliche Variablen\n\nWie wir die Verteilung einer Variablen darstellen, hängt davon ab, welche Art von Daten sie repräsentiert: kategorisch oder numerisch\nEine Variable ist kategorisch, wenn sie eine kleine Menge von Werten annehmen kann, die sich in Gruppen zusammenfassen lassen\n\n\nB. alt/jung, klein/groß, grammatikalisch/ungrammatikalisch, L1/L2-Sprecher\n\n\neine Variable ist numerisch (d. h. quantitativ), wenn sie eine große Bandbreite an numerischen Werten annehmen kann\n\nund es sinnvoll wäre, zu addieren, zu subtrahieren, den Mittelwert zu berechnen usw.\nkann kontinuierlich sein (Dezimalpunkte sind sinnvoll, z. B. 1,5 cm)\noder diskret (Dezimalpunkte sind nicht sinnvoll, z. B. 1,5 Kinder sind nicht sinnvoll)\n\nwir erstellen verschiedene Diagramme, je nachdem, welche Art von Variablen wir visualisieren wollen"
  },
  {
    "objectID": "mats/02-dataviz_1.html#lexical-decision-task-ldt",
    "href": "mats/02-dataviz_1.html#lexical-decision-task-ldt",
    "title": "2  Datenvisualiserung 1",
    "section": "2.2 Lexical Decision Task (LDT)",
    "text": "2.2 Lexical Decision Task (LDT)\n\nunser erster Datensatz enthält Daten aus einer lexikalischen Entscheidungsaufgabe\nBei der LDT drücken die Teilnehmer eine Taste, um anzugeben, ob ein Wort ein echtes Wort oder ein Pseudowort ist.\n\n\n\n\n\n\n\n\n\n\n\n2.2.1 LDT-Variablen\n\nDie üblichen Variablen, die in einem Experiment zur lexikalischen Entscheidungsaufgabe erhoben werden, sind:\n\nReaktionszeit\nGenauigkeit (richtig/falsch)\nWortkategorie (z. B. real/pseudo, Nomen/Verb)\nWorthäufigkeit\n\nZusätzliche Variablen, die erhoben werden könnten, sind:\n\ndemografische Daten der Teilnehmer (z. B. Alter, L1/L2, Geschlecht)"
  },
  {
    "objectID": "mats/02-dataviz_1.html#lexdec-datensatz",
    "href": "mats/02-dataviz_1.html#lexdec-datensatz",
    "title": "2  Datenvisualiserung 1",
    "section": "2.3 lexdec Datensatz",
    "text": "2.3 lexdec Datensatz\n\nlanguageR ist ein Begleitpaket für das Lehrbuch Baayen (2008)\n\nenthält linguistische Datensätze, z.B. lexdec.\n\nder lexdec-Datensatz enthält Daten für eine lexikalische Entscheidungsaufgabe im Englischen\n\nwir werden mit Variablen wie Reaktionszeiten und Genauigkeit arbeiten\n\n\n\n2.3.1 lexdec-Variablen\n\neine Liste einiger der Variablen ist in Tabelle 2.1 enthalten\n\n\n\n\n\nTabelle 2.1: Datenwörterbuch für df_lexdec: Lexikalische Entscheidungslatenzen, die von 21 Probanden für 79 konkrete englische Substantive erhoben wurden, mit Variablen, die mit dem Subjekt oder dem Wort verknüpft sind.\n\n\nVariable\nBeschreibung\n\n\n\n\nSubject\nein Faktor für die Probanden\n\n\nRT\nein numerischer Vektor für die Reaktionszeit in Millisekunden\n\n\nTrial\nein numerischer Vektor für den Rang des Versuchs in der Versuchsliste\n\n\nSex\nein Faktor mit den Ausprägungen F (weiblich) und M (männlich)\n\n\nNativeLanguage\nein Faktor mit den Niveaus English und Other, der zwischen englischen Muttersprachlern und Nicht-Muttersprachlern unterscheidet\n\n\n\n\n\n\n\n\n\n\n2.3.2 LDT-Forschungsfragen\n\nbevor wir ein Experiment durchführen, haben wir Forschungsfragen, die wir mit den Daten beantworten wollen\n\nWir werden uns heute mit der folgenden Frage beschäftigen:\n\nUnterscheiden sich die Reaktionszeiten zwischen Muttersprachlern und Nicht-Muttersprachlern?\n\n\n\n\n\n2.3.3 Laden der Daten\n\nunsere Daten sind in dem Paket lanaugeR verfügbar, das wir bereits geladen haben\n\num die Daten zu drucken, geben Sie einfach den Namen des Datensatzes ein und führen Sie ihn aus\n\nUnten sehen wir nur ein paar Variablen, aber Sie sollten mehr in Ihrer Konsole sehen\n\n\nlexdec\n\n\n\n  Subject       RT Trial Sex NativeLanguage Correct PrevType PrevCorrect\n1      A1 6.340359    23   F        English correct     word     correct\n2      A1 6.308098    27   F        English correct  nonword     correct\n3      A1 6.349139    29   F        English correct  nonword     correct\n4      A1 6.186209    30   F        English correct     word     correct\n5      A1 6.025866    32   F        English correct  nonword     correct\n6      A1 6.180017    33   F        English correct     word     correct\n\n\n\nWie viele Variablen haben wir? Beobachtungen?\n\n\n2.3.3.1 Daten als Objekt speichern\n\nUm die Daten in unserer Umgebung zu speichern, müssen wir ihnen einen Namen zuweisen\n\nNennen wir es df_lexdec, was soviel bedeutet wie “Datenrahmen lexikalische Entscheidung”.\n\n\n\ndf_lexdec &lt;- lexdec\n\n\njetzt sehen wir es in unserem Enrivonment\n\nDoppelklicken Sie darauf, um es im Editorfenster zu sehen.\n\n\n\n\n\n2.3.4 Relevante Variablen\n\nZu den Variablen, die wir haben, gehören:\n\nSubjekt: Teilnehmer-ID\nRT: protokollierte Reaktionszeiten\nNativeLanguage: die Muttersprache des Teilnehmers\nWord: welches Wort präsentiert wurde\nClass: ob das Wort ein Tier oder eine Pflanze war\n\n\n\n\n\n\n\n\nAufgabe 9.2: ?lexdec\n\n\n\n\nBeispiel 2.1  \n\nUm herauszufinden, wofür die anderen Variablen stehen, führen Sie ?lexdec in der Konsole aus."
  },
  {
    "objectID": "mats/02-dataviz_1.html#erstellen-von-plots-mit-ggplot2",
    "href": "mats/02-dataviz_1.html#erstellen-von-plots-mit-ggplot2",
    "title": "2  Datenvisualiserung 1",
    "section": "2.4 Erstellen von Plots mit ggplot2",
    "text": "2.4 Erstellen von Plots mit ggplot2\n\ndas tidyverse ist eine Sammlung von Paketen, die das Aufräumen und die Visualisierung von Daten erleichtern\n\nwenn wir tidyverse laden, wird diese Sammlung von Paketen automatisch geladen\n\ndas ggplot2-Paket ist ein tidyverse-Paket, das Plots in Schichten aufbaut\n\n\nggplot2 Schichten\n\n\n\n\n\nAbbildung 2.1: Example of layers in a ggplot figure\n\n\n\n\n\n\n2.4.1 Ebene 1: leere Leinwand\n\ndie erste Ebene mit der Funktion ggplot() ist wie eine leere Leinwand\n\n\nggplot(data = df_lexdec)\n\n\n\n\n\n\n2.4.2 Ebene 2: Ästhetik der Darstellung\n\nals nächstes teilen wir ggplot() mit, wie unsere Variablen visuell dargestellt werden sollen\n\nWir fügen das “+” am Ende unserer Codezeile ein und verwenden in einer neuen Codezeile die Funktion “aes()”, um unsere Ästhetik zu definieren.\n\nUnsere erste Ästhetik bildet die Reaktionszeiten (RT) auf der x-Achse ab (der untere Teil der Grafik)\n\nwir wickeln die protokollierte RT in die Funktion exp() ein, um RTs in Millisekunden zu erhalten (aus Gründen, die wir nicht diskutieren werden)\n\n\n\nggplot(data = df_lexdec) +\n  aes(x = exp(RT))\n\n\n\n\n\n\n\n\n\n\nAufgabe 2.2: Ästhetische Kartierung\n\n\n\n\nBeispiel 2.2  \n\nAdd the x-axis aesthetic.\n\n\n\n\n\n\n2.4.3 Schicht 3: Hinzufügen von Beobachtungen\n\nwir sehen keine Beobachtungen (d.h. die Balken) in der Grafik, warum nicht?\n\nwir haben ggplot() nicht gesagt, wie sie dargestellt werden sollen\n\nwir müssen ein Geom definieren: das geometrische Objekt, das ein Diagramm verwendet, um Daten darzustellen\n\nin ggplot2 beginnen die Geom-Funktionen mit geom_\nwir beschreiben Diagramme oft in Bezug auf die Arten von Geomen, die sie verwenden, z.B. verwenden Balkendiagramme Balkengeome (geom_bar()), Liniendiagramme Liniengeome (geom_line()), Punktdiagramme ein Punktgeom (geom_point()), usw.\n\n\n\nErzeugen wir unser Histogramm mit dem Geom geom_histogram()\n\n\nggplot(data = df_lexdec) +\n  aes(x = exp(RT)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir erhielten die folgende Meldung, als wir geom_point() einschlossen:\n\nstat_bin() mit bins = 30. Wählen Sie einen besseren Wert mit binwidth.\n\nDies sagt uns nur etwas über die Breite unserer Balken: jeder Balken repräsentiert einen Bereich möglicher Reaktionszeitwerte + bins = 30 bedeutet einfach, dass es 30 Balken gibt, wir können dies ändern und mehr oder weniger Balken haben, indem wir z.B. bins = 20 oder bins = 100 in geom_histogram() einfügen\n\n\n\n\nCode\nggplot(\n  data = df_lexdec,\n  mapping = aes(x = exp(RT))\n) +\n  labs(title = \"with geom_histogram(bins = 20)\") +\n  geom_histogram(bins = 20) +\n\n  ggplot(\n  data = df_lexdec,\n  mapping = aes(x = exp(RT))\n) +\n  labs(title = \"with geom_histogram(bins = 100)\") +\n  geom_histogram(bins = 100)\n\n\n\n\n\n\n\n2.4.4 Hinzufügen von Ästhetik\n\nEs ist nützlich, die Verteilung der Reaktionszeiten im Allgemeinen zu sehen.\n\naber wir wollen normalerweise Gruppen vergleichen\n\nB. Unterschiede zwischen Muttersprachlern und Nicht-Muttersprachlern oder zwischen verschiedenen Wortarten\n\n\nWir haben auch die Muttersprache als Variable, wie könnten wir diese in unserem Diagramm visualisieren?\n\n\n\nCode\nggplot(\n  data = df_lexdec,\n  aes(x = exp(RT), fill = NativeLanguage)\n) +\n  geom_histogram()\n\n\n\n\n\n\nwir sehen die roten und die blauen Balken, aber ist das blaue Histogramm über das rote geschichtet?\n\noder sind die roten Balken über den blauen Balken gestapelt?\n\nEs ist letzteres\n\nstellen wir es so ein, dass das blaue Histogramm über dem roten liegt\n\n\n\n\nCode\nggplot(\n  data = df_lexdec,\n  aes(x = exp(RT))\n) +\n  labs(title = \"No grouping\") +\n  geom_histogram() + \n\nggplot(\n  data = df_lexdec,\n  aes(x = exp(RT), fill = NativeLanguage)\n) +\n  labs(title = \"Stacked\") +\n  geom_histogram() + \n  \nggplot(\n  data = df_lexdec,\n  aes(x = exp(RT), fill = NativeLanguage)\n) +\n  labs(title = \"Layered: position = \\\"identity\\\"\") +\n  geom_histogram(position = \"identity\") +\n  \n  \n  plot_layout(guides = \"collect\") & theme(legend.position = 'bottom') \n\n\n\n\n\n\n\n2.4.5 Globale und lokale Ästhetik\n\nin unserer endgültigen Darstellung ist die Farbe der Histogramme leicht transparent\n\nWir können dies steuern, indem wir das Argument alpha = 0.3 zu geom_histogram() hinzufügen.\nalpha kann jeden anderen Wert zwischen 0 und 1 annehmen.\n\n\n\n\n\n\n\n\nAufgabe 2.3: Transparenz\n\n\n\n\nBeispiel 2.3  \n\nSpielen Sie mit der Transparenz des Histogramms geom. Wählen Sie den von Ihnen bevorzugten Alpha-Wert. Die Ausgabe sollte in etwa so aussehen:\n\n\n\n\n\n\n\n\n\n\n\n2.4.6 Anpassen unseres Plots\n\nwir können unsere Achsen- und Legendenbeschriftungen verbessern und auch Titel hinzufügen, indem wir die Funktion labs() verwenden\nWir können auch die Funktion scale_fill_colorblind() aus dem Paket ggthemes verwenden.\n\ndies erzeugt farbenblind-sichere Farben\n\nWir werden auch die Funktion theme_minimal() aus dem Paket ggplot2 verwenden; was bewirkt diese Funktion?\nVersuchen Sie, Ihrem Diagramm Folgendes hinzuzufügen\n\nÄndern Sie die Beschriftungen entsprechend\nund fügen Sie dem Code sinnvolle Kommentare mit # hinzu\n\n\n\nlabs(title = \"Plot title\",\n     x = \"x-axis label\",\n     y = \"y-axis label\") +\n  scale_fill_colourblind() +\n  theme_minimal()\n\n\n\n2.4.7 Kommentar\n\nDer Code und die Darstellung sollten in etwa so aussehen:\n\n\n## histogram of reaction times by native language\nggplot(data = df_lexdec) +\n  aes(x = exp(RT), fill = NativeLanguage) + ## set aesthetics\n  labs(title = \"Reaction times by L1\",\n     x = \"Reaction times (ms)\") +\n  geom_histogram(position = \"identity\", alpha = 0.3) +\n  scale_fill_colorblind() + ## make fill colorblind friendly\n  theme_minimal() ## set plot theme\n\n\n\n\n\n\n2.4.8 Speichern von Plots\n\nWir können Diagramme in unserer Umgebung speichern, genau wie wir Zahlen und Daten als Objekte speichern können.\n\nSie können Objekte beliebig benennen\naber es ist ratsam, den Namen sinnvoll zu gestalten (z.B. nicht fig1 oder xyz)\n\nNennen wir diese Grafik fig_lexdec_rt, für “figure lexical decision task reaction times”.\n\n\n\n\n\n\n\nAufgabe 2.4: Figur als Objekt speichern\n\n\n\n\nBeispiel 2.4  \n\n\nSpeichern Sie unsere endgültige Darstellung als Objekt mit dem Namen fig_lexdec_rt.\n\n\n\n\n\n\n\n2.4.9 Balkendiagramme\n\nKopieren Sie den Code für Ihr Histogramm\nNehmen Sie die folgenden Änderungen vor, um unser Balkendiagramm darzustellen\n\nEntfernen Sie die Namenszuweisung (fig_lexdec_rt)\nauf der x-Achse wollen wir NativeLanguage\nErsetzen Sie geom_histogram() durch geom_bar()\n\nEntfernen Sie die Argumente für das Histogramm (kein position oder alpha)\n\nändern Sie die Beschriftungen entsprechend\n\nSpeichern Sie das Diagramm als Objekt mit einem aussagekräftigen Namen (z.B. fig_lexdec_l1)\n\n\n\n\n\nsollte das Diagramm in etwa so aussehen:\n\n\n\n\n\n\n\n\n2.4.10 Kombinieren von Plots\n\nEin Grund, Ihre Darstellung als Objekt zu speichern, ist, dass wir sie später aufrufen können\n\nd.h. Sie können den Plot an einer Stelle in Ihrem Dokument erstellen, sich aber entscheiden, ihn erst im gerenderten Bericht weiter unten zu drucken\n\nein weiterer Grund ist, dass wir mehrere Diagramme kombinieren können\n\nDies kann mit einer Vielzahl von Paketen geschehen\nVersuchen wir es mit dem Paket patchwork\n\nBenutze + um zwei Plots nebeneinander zu verbinden\noder /, um sie übereinander darzustellen\n\n\n\n\n2.4.10.1 Kombinieren von Plots mit +\n\nfig_lexdec_rt + fig_lexdec_l1\n\n\n\n\n\n\n2.4.10.2 Kombinieren von Plots mit /\n\nfig_lexdec_rt / fig_lexdec_l1"
  },
  {
    "objectID": "mats/02-dataviz_1.html#entscheidung-für-ein-geom",
    "href": "mats/02-dataviz_1.html#entscheidung-für-ein-geom",
    "title": "2  Datenvisualiserung 1",
    "section": "2.5 Entscheidung für ein Geom",
    "text": "2.5 Entscheidung für ein Geom\n\nWarum verwenden wir ein Histogramm für die Reaktionszeit und ein Balkendiagramm für die Muttersprache?\nUm welche Arten von Variablen handelt es sich?\n\nReaktionszeit ist kontinuierlich\nMuttersprache ist eine kategoriale Variable\n\nWir verwenden Histogramme, um die Verteilungen von kontinuierlichen Variablen zu visualisieren.\nWir verwenden Balkendiagramme, um Verteilungen von kateogrischen Variablen zu visualisieren.\nWenn wir wissen, was wir visualisieren wollen (z. B. Verteilungen) und welche Art von Variable wir haben (d. h. kontinuierlich, kategorial), können wir entscheiden, welche Art von Diagramm wir erstellen wollen.\nOft ist es eine gute Idee, die Darstellung auf Papier zu zeichnen, bevor man in R beginnt (ich mache das auch oft)."
  },
  {
    "objectID": "mats/02-dataviz_1.html#exercises",
    "href": "mats/02-dataviz_1.html#exercises",
    "title": "2  Datenvisualiserung 1",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises\nDiese Übungen sollten auch in Ihrem Skript enthalten sein, wenn Sie es auf Moodle hochladen. Das Durcharbeiten des Unterrichtsmaterials wird Sie auf diese Aufgaben vorbereiten.\n\nReproduzieren Sie unser Histogramm als Dichte-Diagramm, indem Sie geom_histogram() durch geom_density() ersetzen.\n\nWas zeigt diese Art der Darstellung?\n\nErstellen Sie ein Balkendiagramm, das die Anzahl der Beobachtungen pro Wortklasse zeigt (Hinweis: Sie benötigen die Variable Class aus unserem Datensatz)."
  },
  {
    "objectID": "mats/02-dataviz_1.html#section-2",
    "href": "mats/02-dataviz_1.html#section-2",
    "title": "2  Datenvisualiserung 1",
    "section": "",
    "text": "Drucken Sie Ihren Dichteplot und Ihren Klassen-Balkenplot übereinander mit Hilfe des patchwork Pakets\nReproduzieren Sie die folgenden Diagramme so genau wie möglich (Hinweis: Sie benötigen das Argument position = \"dodge\"):"
  },
  {
    "objectID": "mats/02-dataviz_1.html#heutige-ziele-1",
    "href": "mats/02-dataviz_1.html#heutige-ziele-1",
    "title": "2  Datenvisualiserung 1",
    "section": "Heutige Ziele",
    "text": "Heutige Ziele\nHeute haben wir gelernt…\n\nwas Datenrahmen sind\nden Unterschied zwischen kategorialen und kontinuierlichen Daten\nwie man Diagramme mit ggplot erstellt\ndie richtige Darstellung für unsere Daten auszuwählen"
  },
  {
    "objectID": "mats/02-dataviz_1.html#session-info",
    "href": "mats/02-dataviz_1.html#session-info",
    "title": "2  Datenvisualiserung 1",
    "section": "Session Info",
    "text": "Session Info\nHergestellt mit R version 4.3.0 (2023-04-21) (Already Tomorrow) und RStudioversion 2023.3.0.386 (Cherry Blossom).\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] magick_2.7.4     kableExtra_1.3.4 knitr_1.44       patchwork_1.1.3 \n [5] ggthemes_4.2.4   languageR_1.5.0  lubridate_1.9.2  forcats_1.0.0   \n [9] stringr_1.5.0    dplyr_1.1.3      purrr_1.0.2      readr_2.1.4     \n[13] tidyr_1.3.0      tibble_3.2.1     ggplot2_3.4.3    tidyverse_2.0.0 \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.3        generics_0.1.3    xml2_1.3.4        stringi_1.7.12   \n [5] hms_1.1.3         digest_0.6.33     magrittr_2.0.3    evaluate_0.21    \n [9] grid_4.3.0        timechange_0.2.0  fastmap_1.1.1     rprojroot_2.0.3  \n[13] jsonlite_1.8.7    httr_1.4.6        rvest_1.0.3       fansi_1.0.4      \n[17] viridisLite_0.4.2 scales_1.2.1      cli_3.6.1         rlang_1.1.1      \n[21] munsell_0.5.0     withr_2.5.0       yaml_2.3.7        tools_4.3.0      \n[25] tzdb_0.4.0        colorspace_2.1-0  webshot_0.5.4     here_1.0.1       \n[29] pacman_0.5.1      vctrs_0.6.3       R6_2.5.1          lifecycle_1.0.3  \n[33] htmlwidgets_1.6.2 pkgconfig_2.0.3   pillar_1.9.0      gtable_0.3.4     \n[37] Rcpp_1.0.11       glue_1.6.2        systemfonts_1.0.4 highr_0.10       \n[41] xfun_0.39         tidyselect_1.2.0  rstudioapi_0.14   farver_2.1.1     \n[45] htmltools_0.5.5   svglite_2.1.1     rmarkdown_2.22    labeling_0.4.3   \n[49] compiler_4.3.0"
  },
  {
    "objectID": "mats/02-dataviz_1.html#literaturverzeichnis",
    "href": "mats/02-dataviz_1.html#literaturverzeichnis",
    "title": "2  Datenvisualiserung 1",
    "section": "Literaturverzeichnis",
    "text": "Literaturverzeichnis\n\n\nBaayen, R. H. (2008). Analyzing Linguistic Data: A Practical Introduction to Statistics Using R.\n\n\nNordmann, E., & DeBruine, L. (2022). Applied Data Skills. Zenodo. https://doi.org/10.5281/zenodo.6365078\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for Data Science (2. Aufl.)."
  },
  {
    "objectID": "mats/03-quarto_1.html#lernziele",
    "href": "mats/03-quarto_1.html#lernziele",
    "title": "3  Dynamic reports with Quarto",
    "section": "Lernziele",
    "text": "Lernziele\n\nlernen, was dynamische Berichte sind\nunser eigenes Quarto-Dokument erstellen\nlernen, wie man ein Quarto-Dokument bearbeitet\nlernen, wie man Code in ein Quarto-Dokument einfügt\nein Quarto-Dokument in verschiedenen Formaten wiedergeben"
  },
  {
    "objectID": "mats/03-quarto_1.html#lesungen",
    "href": "mats/03-quarto_1.html#lesungen",
    "title": "3  Dynamic reports with Quarto",
    "section": "Lesungen",
    "text": "Lesungen\nDie Pflichtlektüre zur Vorbereitung auf dieses Thema ist Kap. 29 (Quarto) und Kap. 30 (Quarto formats) in Wickham et al. (2023).\nEine ergänzende Lektüre ist Ch. 2 (Reproducible Workflows) in Nordmann & DeBruine (2022). Nordmann & DeBruine (2022) verwendet Rmarkdown-Skripte, während wir die nächste Generation verwenden werden: Quarto. Wir sollten in Quarto immer noch in der Lage sein, genau die gleichen Dinge zu tun, wie sie in Rmarkdown vorgeschlagen werden."
  },
  {
    "objectID": "mats/03-quarto_1.html#wiederholung",
    "href": "mats/03-quarto_1.html#wiederholung",
    "title": "3  Dynamic reports with Quarto",
    "section": "Wiederholung",
    "text": "Wiederholung\nLetzte Woche haben wir gelernt…\n\nwas Datenrahmen sind\nden Unterschied zwischen kategorialen und kontinuierlichen Daten\nwie man Diagramme mit ggplot erstellt\ndie richtige Darstellung für unsere Daten auszuwählen\n\n\nWiederholung: ggplot()\nSehen Sie sich diesen Code an. Was würde passieren, wenn wir ihn ausführen würden?\n\nlibrary(languageR)\nlibrary(tidyverse)\ndf_lexdec &lt;- lexdec\n\nfig_lexdec &lt;-\n  df_lexdec |&gt; \n  ggplot() +\n  aes(x = RT, colour = Class) +\n  geom_histogram(position = \"identity\", alpha = .5) +\n  theme_bw()\n\nWelche Darstellung in Abbildung 3.1 wird durch den folgenden Code erzeugt?\n\nlibrary(languageR)\nlibrary(tidyverse)\ndf_lexdec &lt;- lexdec\n\nfig_lexdec1 &lt;-\n  df_lexdec |&gt; \n  ggplot() +\n  aes(x = RT, colour = Class) +\n  geom_density(alpha = .5) +\n  theme_bw()\n\n\n\n\n\n\nAbbildung 3.1: Drei aus dem lexdec-Datensatz generierte Diagramme"
  },
  {
    "objectID": "mats/03-quarto_1.html#set-up",
    "href": "mats/03-quarto_1.html#set-up",
    "title": "3  Dynamic reports with Quarto",
    "section": "Set-up",
    "text": "Set-up\n\nwir müssen eine LaTeX-Distribution verwenden, um PDF-Dokumente mit Quarto zu erstellen\n\nLaTeX ist ein Schriftsatzsystem\nTinyTex ist eine eigene LaTeX-Distribution, mit der wir PDFs erstellen können.\nDas Paket tinytex kann uns helfen, TinyTex zu installieren\n\n\n\nInstallation von LaTeX über tinytex\n\nFühren Sie den folgenden Code in der Konsole aus\noder, wenn Sie ihn in einem Skript ausführen wollen, um zu dokumentieren, was Sie getan haben, kommentieren Sie ihn nach der Ausführung aus (d.h. fügen Sie ein # davor)\n\n\n# run this in the console\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n\n\n\nOrdner für Woche 3\n\nFügen Sie einen Unterordner mit dem Namen 03-quarto in Notes hinzu\nGehen Sie zu Moodle und speichern den Materialordner für ‘03 - Einführung in Quarto’ in Ihrem moodle Ordner\nÖffnen Sie das Dokument _blatt.html auf Ihren Computer\n\nSehen Sie das Dokument an; Sie können oben rechts auf verschiedene Schaltflächen klicken. Probieren Sie es.\n\n\n\n\n\n\n\nAbbildung 3.2: Notes folder structure"
  },
  {
    "objectID": "mats/03-quarto_1.html#quarto",
    "href": "mats/03-quarto_1.html#quarto",
    "title": "3  Dynamic reports with Quarto",
    "section": "3.1 Quarto",
    "text": "3.1 Quarto\n\nQuarto ist ein Dateityp, der dynamische Berichte erstellt\nQuarto-Dokumente sehen genauso aus wie ihr Vorgänger, Rmarkdown\n\n\n3.1.1 Dynamische Berichte\n\ndiejenigen, die Text, Code, Codeausgabe enthalten\nQuarto bietet ein “unified authoring framework” für Data Science, das Ihren Text, Ihren Code und Ihre Code-Ausgabe einschließt (Wickham et al., 2023, Kap 29.1)\nQuarto wurde entwickelt, um auf drei Arten verwendet zu werden:\n\n\nFür die Kommunikation mit Entscheidungsträgern, die sich auf die Schlussfolgerungen und nicht auf den Code hinter der Analyse konzentrieren wollen.\nfür die Zusammenarbeit mit anderen Datenwissenschaftlern (einschließlich Ihnen in der Zukunft!), die sich sowohl für Ihre Schlussfolgerungen als auch für die Art und Weise interessieren, wie Sie zu ihnen gekommen sind (d. h. für den Code).\nals eine Umgebung, in der Datenwissenschaft betrieben wird, als ein modernes Labornotizbuch, in dem wir nicht nur aufzeichnen können, was wir getan haben, sondern auch unsere Gedankengänge.\n\n\n\n3.1.2 R v. Rmarkdown v. Quarto\n\n.R -Dateien enthalten nur (R-)Quellcode\n.Rmd dynamische Berichte mit\n\nR-Code (und R-Pakete)\n\n.qmd dynamische Berichte (RStudio v2022.07 oder später) mit\n\nR-Code (und R-Pakete)\nNative Unterstützung für Python (und Jupyter-Notebooks)\nNative Unterstützung für Julia\n\n\n\n\n\n\n\n\nAufgabe 3.1: RStudio version\n\n\n\n\nBeispiel 3.1  \n\n\nFühren den folgenden Code in der Konsole aus: RStudio.Version()$version\n\nwenn die ausgegebene Version 2022.07 oder höher ist, können Sie Quarto benutzen\nwenn nicht:\n\nAktualisieren Sie RStudio: Help &gt; Check for updates\n\n\n\n\n\n\n\n3.1.3 Markdown\n\n.md-Dateien\nein Klartext-Editor-Format, das\n\nFormatierungselemente hinzufügt, die unabhängig von Gerät und Ausgabeformat sind (PDF, Word-Dokument, html…)\nleicht zu lesen ist\n\nMarkdown-Dokumente sind das Bindeglied zwischen unserem Quelldokument (.qmd) und unserer Ausgabe (z.B. PDF)\n\n\n\n3.1.4 Folder structure\n\njede .qmd sollte (normalerweise) in einem eigenen Ordner sein\n\nd.h. es sollten nicht mehrere .qmd Dateien im selben Ordner sein\n\ndies ist nur mein Vorschlag, um die Ordner ordentlich und organisiert zu halten\n\nd.h., es gibt keinen technischen Grund dafür (die Dokumente laufen auch dann, wenn sie sich alle im selben Ordner befinden)\n\nwerfen wir einen Blick auf einige meiner früheren und aktuellen Projektordner"
  },
  {
    "objectID": "mats/03-quarto_1.html#unsere-erstes-quarto-dokument",
    "href": "mats/03-quarto_1.html#unsere-erstes-quarto-dokument",
    "title": "3  Dynamic reports with Quarto",
    "section": "3.2 Unsere erstes Quarto-Dokument",
    "text": "3.2 Unsere erstes Quarto-Dokument\n\nletzte Woche haben wir ein R-Skript erstellt, das wir über Moodle eingereicht haben\nwir werden nun unsere erste .qmd-Datei erstellen\nvon nun an wird dies die Datei sein, die wir in Moodle einreichen (kein R-Skript)\n\n\n\n\n\n\n\nAufgabe 3.2: erste Quarto\n\n\n\n\nBeispiel 3.2  \n\n\nErstellen Sie in Ihrem R-Projekt-Ordner, in dem ihr Ihre Kursunterlagen/Notizen aufbewahren, einen neuen Ordner für Woche 3\nFile &gt; New Document &gt; Quarto Document\n\nGeben Sie ihm einen Titel wie “Quarto - Woche 3”\nDeaktivieren Sie die Option “open with Visual Editor”.\n\nSchauen das neue Skript an, um mehr über Quarto zu erfahren.\nKlicken Sie auf die Schaltfläche “Render” am oberen Rand des Dokuments\n\nSpeichern Sie das Dokument in dem Ordner für Woche 3, den Sie gerade erstellt haben.\nWas geschiehen? Vergleichen die Ausgabe mit dem Quellcode des Dokuments.\n\nGehen Sie zurück zu Ihrem neuen Ordner 03-quarto\n\nWas hat sich geändert?\n\n\n\n\n\n\n\n3.2.1 Quarto-Grundlagen\n\nQuarto-Dokumente (wie Rmarkdown) enthalten drei wichtige Arten von Inhalten:\n\nden YAML-Header, der von --- umgeben ist\nText mit einer einfachen Formatierung oder Strukturierung wie ## Überschrift oder *Kursivschrift*\nR-Code-Chunk, umgeben von ```{r} ```\n\n\n\n```{r}\n#| code-line-numbers: false\n## Dies ist ein Code Chunk\n1 + 1\n```\n\n[1] 2\n\n\n\n\n3.2.2 YAML\n\nstand ursprünglich für Yet Another Markup Language\n\nwurde aber in YAML Ain’t Markup Language umbenannt, um den Zweck der Sprache als datenorientiert und nicht als Dokumentauszeichnung zu betonen (laut Wikipedia)\n\nenthält alle Metainformationen zu Ihrem Dokument\n\nz.B. Titel, Autorenname\n\nauch Formatierungsinformationen\n\nz.B. Typ der Ausgabedatei\n\nes gibt viele Möglichkeiten der Dokumentformatierung und -anpassung, die wir in diesem Kurs nicht behandeln werden\n\naber ich habe zum Beispiel viele YAML-Formatierungsoptionen im Quellcode meiner Folien\n\n\n\n\n\n\n\n\nAufgabe 3.3: YAML\n\n\n\n\nBeispiel 3.3  \n\n\nÄndern Sie den Titel, wenn Sie das tun möchten.\nRaten Sie, wie man einen “Untertitel” (EN: subtitle) hinzufügen könnte (Hinweis: es ist ähnlich wie beim Hinzufügen eines title)\nFügen Sie einen Autor hinzu, Autor: \"vorname nachname\" (siehe Beispiel unten)\nFüge ein Inhaltsverzeichnis hinzu (EN: Table of Contents, toc), indem du format so änderst, dass es wie folgt aussieht:\n\n\n---\ntitle: \"Quarto - Woche 3\"\nauthor: \"Vorname Nachname\"\nformat:\n  html:\n    toc: true\n---\n\n\nRendern nun das Dokument. Sehen Sie Ihre Änderungen?\n\n\n\n\n\n\n\n3.2.3 Strukturierung Ihres Dokuments\n\nwir können unser Dokument strukturieren mit\n\n## Überschriften\n### Zwischenüberschriften\n#### Unter-Zwischenüberschriften, usw.\n\n\n\n---\ntitle: \"Quarto - Woche 3\"\nauthor: \"Vorname Nachname\"\nformat:\n  html:\n    toc: true\n---\n\n## Überschrift 1\n\nHier ist ein Text über das Thema, das mit dieser Überschrift verbunden ist.\n\n## Überschrift 2\n\nHier ist ein weiterer Text zu einem anderen Thema.\n\n### Unterüberschrift 2.1\n\nDies ist ein Text über das Unterthema.\n\n\n\n\n\n\n\nDie Bedeutung der Formatierung\n\n\n\n\nZwischenüberschriften benötigen ein Leerzeichen nach dem letzten Hashtag (##Zwischenüberschrift anstelle von ##Zwischenüberschrift), um als Überschrift gelesen zu werden. YAML erfordert außerdem einen sehr präzisen Schriftsatz. Da die Abstände in der YAML (und anderswo) so wichtig sind, möchte ich die Leerzeichen sehen und zählen können. Um dies zu tun, geht in RStudio:\n\ngehen zu Ihren Globalen Einstellungen (Werkzeuge &gt; Globale Einstellungen)\nunter Code (linke Spalte) &gt; Display (Tab), markieren das Kästchen &gt; Show whitespace character\n\n\n\n\n\n\n\n\n\n\nAufgabe 3.4: Überschriften\n\n\n\n\nBeispiel 3.4  \n\n\nKopiern den obigen Code (Überschriften und Unterüberschriften) und ersetzen den Text in der Quarto-Vorlage.\nErsetzen die erste Überschrift durch den Titel Quarto\n\nSchreiben einen Text, der Quarto beschreibt, unter die Überschrift\n\nSchreiben eine Unterüberschrift namens YAML\n\nSchreiben einen Text, der die YAML-Struktur beschreibt, die wir besprochen haben\n\nErstellen eine Unterüberschrift mit dem Namen Quarto-Struktur.\n\nSchreiben einige Notizen darüber, wie wir ein Quarto-Dokument strukturieren können (z.B. durch das Erstellen von Überschriften)\n\nFinden Sie in RStudio die Schaltfläche Outline oben links im .qmd Text Editor Fenster\n\nWas sehent Sie, wenn Sie darauf klicken?\n\n\n\n\n\n\n\n\n3.2.4 Textformatierung\n\nzum Formatieren von Text müssen wir die Markdown-Syntax verwenden\n\n\n\n\n\n\n\n  \n    \n    \n      Format\n      Markdown\n      Ausgabe\n    \n  \n  \n    Kursivschrift\nDieser Text ist *kursiv*\n\nDieser Text ist kursiv\n\n    Fett\nDieser Text ist **fett**\n\nDieser Text ist fett\n\n    Subskription\nDieser Text ist ~tiefgestellt~\n\nDieser Text isttiefgestellt\n\n    Hochgestelt\nDieser Text ist ^hochgestellt^\n\nDieser Text ist hochgestellt\n\n  \n  \n  \n\n\n\n\n\n\n3.2.5 Aufzählungen\n\nwir können Aufzählungslisten mit Bindestrichen erstellen.\n\nUnteraufzählungen müssen eingerückt werden (drückt die Tabulatortaste)\n\nnummerierte Listen können durch einfaches Schreiben einer nummerierten Liste erstellt werden\n\nUnteraufzählungen müssen in nummerierten Listen doppelt eingerückt werden\n\n\n\n- dies ist ein Aufzählungszeichen\n  + dies ist ein Unterpunkt\n\n1. Dies ist ein nummerierter Punkt\n    a. dies ist ein unternummerierter Punkt (beachtt den doppelten Einzug)\n2. dies ist der zweite nummerierte Punkt\n\n\ndies ist ein Aufzählungszeichen\n\ndies ist ein Unterpunkt\n\n\n\nDies ist ein nummerierter Punkt\n\ndies ist ein unternummerierter Punkt (beachtt den doppelten Einzug)\n\ndies ist der zweite nummerierte Punkt\n\n\n\n\n\n\n\nAufgabe 3.5: Aufzählungen\n\n\n\n\nBeispiel 3.5  \n\n\nFügen Ihrem .qmd Dokumententext eine Textformatierung hinzu.\nFügen eine Aufzählungsliste hinzu\nFügen eine nummerierte Liste hinzu\nRendern Sie das Dokument. Hat es geklappt?"
  },
  {
    "objectID": "mats/03-quarto_1.html#codierung-in-quarto",
    "href": "mats/03-quarto_1.html#codierung-in-quarto",
    "title": "3  Dynamic reports with Quarto",
    "section": "3.3 Codierung in Quarto",
    "text": "3.3 Codierung in Quarto\n\nDer große Vorteil von dynamischen Berichten ist die Integration von Text und Code\nVorletzte Woche haben wir gelernt, wie man einfache mathematische Berechnungen in R durchführt.\nwie würden wir R-Befehle in ein .qmd-Dokument einfügen?\n\nInline-Code (Code, der innerhalb einer Textzeile ausgeführt wird)\nCode-Chunke (ein Code-Chunk, der nicht in Text enthalten ist)\n\n\n\n3.3.1 Code-Chunks\n\nCode Chunks sind zwischen ```{r} und ``` eingebettet.\neine schöne Tastenkombination:Cmd-Option-I (Mac) oder Strg-Alt-I (PC)\n\n\n```{r}\n#| eval: false\n\n## Addition\n4+6\n```\n\n\nihr könnt den Code in Ihrer RStudio-Sitzung ausführen, indem ihr:\n\nauf das kleine grüne Dreieck oben rechts im Chunk klickt\ndie Tastenkombination Cmd/Strg-Enter verwendt, um eine einzelne Code-Zeile auszuführen (je nachdem, worauf der Cursor steht)\nder Tastenkombination Cmd/Strg-Shift-Enter benutzt, um den gesamten Code-Chunk auszuführen (falls es mehrere Befehle innerhalb eines einzelnen Abschnitts gibt)\n\n\n\n\n\n\n\n\nAufgabe 3.6: Code-Chunks\n\n\n\n\nBeispiel 3.6  \n\n\nFüge einen Code Chunk zu deiner .qmd Datei hinzu\n\nFüge einige mathematische Operationen ein (Addition, Subtraktion, etc)\nFügt informative Anmerkungen zu Ihrem Code hinzu (z.B. ## Addition)\n\nFüge einen Text unter deinem Code-Chunk hinzu, der beschreibt, was der obige Code erreicht hat.\nRendern Sie das Dokument. Hat es geklappt?\n\n\n\n\n\n\n\n\n\n\n\nErinnerung! Überschriften und Code-Anmerkungen\n\n\n\n\nDenken Sie beim Schreiben von Notizen/bei der Bearbeitung von Übungen im Unterricht daran, informative Überschriften/Unterüberschriften zu erstellen! Auf diese Weise wird das Dokument strukturiert und übersichtlich, wenn ihr-in-der-Zukunft (oder ich) darauf zurückblickt.\nÜberschriften/Zwischenüberschriften strukturieren das gesamte Dokument. Code-Anmerkungen beschreiben, was bestimmte Teile des Codes bewirken (und warum). Beide beginnen mit einem Hashtag + Leerzeichen (# ), aber Überschriften stehen außerhalb eines Codeabschnitts, während Codeanmerkungen innerhalb eines Codeabschnitts erscheinen.\nTipp: Klicken Sie auf die Schaltfläche “Outline” oben rechts im Texteditor-Fenster. Was zeigt sie an?\n\n\n\n\n\n3.3.2 Code-Chunk-Optionen\n\nwir können die Ausführung von Code-Chunken steuern\nwir wollen nicht immer unseren Code in einem Bericht wiederholen\n\nwir können dies in jedem Code-Chunk mit #| echo: true oder false steuern\n\nwir wollen nicht immer unseren Code in einem Bericht ausführen lassen\n\nwir können dies in jedem Code-Chunk mit #| eval: true oder false steuern\n\n\n\nDies würde wie folgt aussehen:\n\n\n```{r}\n#| eval: true\n\n## Addition\n4+6\n```\n\n[1] 10\n\n\n\nWichtig ist, dass die Codechunk-Optionen:\n\nmit #| beginnen, mit einem Leerzeichen dahinter und keinem Leerzeichen davor\ndirekt unter ```{r} platziert werden\n\n\n\n\n\n\n\n\nAufgabe 3.7: c()\n\n\n\n\nBeispiel 3.7  \n\n\nErinnern Sie sich, dass wir letzte Woche die Funktion c() (EN: concatenate) gesehen haben, die mehrere Werte kombiniert (z.B. mean(c(3,4,25)) ergibt den Mittelwert von 3,4 und 25)\nIn einem Code-Stück: Erstellen sie ein Objekt, das eine Liste von Zahlen enthält (z.B. Objektname &lt;- c(...))\nBerechnen Sie den Mittelwert dieser Zahlen, indem Sie nur den Objektnamen verwendt.\nSpeichern Sie den Mittelwert dieser Zahlen als ein Objekt\nRendern Sie das Dokument und seht sich den Abschnitt mit Ihrem Code-Chunk an.\n\nÄndern Sie nun im Quellcode die Chunk-Einstellungen auf echo: false und rendern das Dokument. Was ändert sich?\nSetzen nun echo: true, aber eval: false. Rendern das Dokument. Was ändert sich?"
  },
  {
    "objectID": "mats/03-quarto_1.html#plots-in-quarto",
    "href": "mats/03-quarto_1.html#plots-in-quarto",
    "title": "3  Dynamic reports with Quarto",
    "section": "3.4 Plots in Quarto",
    "text": "3.4 Plots in Quarto\n\nEin großer Vorteil der gerenderten Quarto-Dokumente besteht darin, dass wir unsere Abbildungen zusammen mit den Textbeschreibungen anzeigen können\nLassen Sie uns versuchen, eine Handlung von letzter Woche in unserem neuen Quarto-Dokument zu reproduzieren\n\n\n3.4.1 Set-up\n\nunsere Pakete in einen Codechunk laden: tidyverse, languageR, und ggthemes\n\n\n```{r}\n## Pakete laden\nlibrary(tidyverse)\nlibrary(languageR)\nlibrary(ggthemes)\n```\n\n\nunsere Daten in einen separaten Codechunk laden (am besten ist es, einen einzigen Codechunk für einen einzigen Zweck zu verwenden)\n\n\n```{r}\n## Daten laden\ndf_lexdec &lt;- lexdec\n```\n\n\n\n3.4.2 Plots in Quarto\n\nErstellen Sie jetzt einfach einen neuen Codechunk, der einen Code von letzter Woche enthält\nwir speichern es als Objekt mit dem Namen fig_lexdec_hist:\n\n\n### histogram of reaction times by native language\n  ggplot(data = df_lexdec) +\n  aes(x = exp(RT), fill = NativeLanguage) + ### set aesthetics\n  geom_histogram(position = \"identity\", alpha = 0.3) +\n  scale_fill_colorblind() + ### make fill colorblind friendly\n  theme_minimal() ### set plot theme\n\n\n\n\nAbbildung 3.3: Histogram of reactiontimes per native language from lexdec\n\n\n\n\n\n\n3.4.3 Plots drucken\n\nErinnern Sie sich an die letzte Woche: Wenn Sie einen Plot benennen, wird er nur gedruckt, wenn Sie den Namen des Objekts eingeben\nwenn Sie den Plot nicht als Objekt speichern, wird er gedruckt, wenn Sie den Code ausführen, der den Plot erzeugt\nWenn Sie den Plot als Objekt speichern, wird er nicht gedruckt, wenn Sie den Code ausführen.\n\nIn diesem Fall müssen Sie den Objektnamen ausführen, um zu sehen, was unter diesem Namen gespeichert ist\nDies gilt für alle Arten von Objekten, nicht nur für Diagramme!\n\n\n\n\n\n\n\n\nAufgabe 3.8: Plots in Quarto\n\n\n\n\nBeispiel 3.8  \n\n\nEinen neuen Codeabschnitt erstellen und das Balkendiagramm von letzter Woche erzeugen, aber als Objekt speichern\nIn einem separaten Codechunk nur den Objektnamen dieses Diagramms angeben\nRendern Sie das Dokument, um zu sehen, wo die Abbildung gedruckt wurde.\n\n\n\n\n\n\nfig_lexdec_l1 &lt;-\n  ggplot(data = df_lexdec) +\n  aes(x = NativeLanguage, fill = NativeLanguage) +\n  ## add the geom:\n  geom_bar() +\n  scale_fill_colorblind() + ## add colourblind colours\n  theme_minimal()\n\n\nfig_lexdec_l1\n\n\n\n\nAbbildung 3.4: Barplot of observations per native language"
  },
  {
    "objectID": "mats/03-quarto_1.html#ausgabeformate",
    "href": "mats/03-quarto_1.html#ausgabeformate",
    "title": "3  Dynamic reports with Quarto",
    "section": "3.5 Ausgabeformate",
    "text": "3.5 Ausgabeformate\n\nes gibt mehrere Ausgabeformate, die wahrscheinlich nützlichsten sind:\n\nhtml (default)\npdf\nrevealjs (Folien)\ndocx\n\n\n\n3.5.1 Ausgabeformate\n\nwenn wir das Dokument rendern:\n\nQuarto sendet die .qmd-Datei an knitr (ein R-Paket für dynamische Berichte mit R)\nknitr führt die Code-Chunke aus und erstellt ein neues .md Dokument mit Code und Ausgabe\ndie .md-Datei wird von pandoc verarbeitet, das .md-Dateien in die fertige Datei konvertieren kann, mit vielen Ausgabeformaten\n\n\n\n\n\n\n\nDiagramm des Quarto-Workflows von qmd, zu knitr, zu md, zu pandoc, zur Ausgabe im PDF-, MS Word- oder HTML-Format. (Quelle: Wickham et al. (2023))\n\n\n\n\n\n\n\n\n\n\nAndere Verwendungen\n\n\n\n\nQuarto kann für eine Vielzahl von Zwecken verwendet werden, wie z. B.:\n\nWebsites/Blogs\nNotizen machen\nDokumentieren von allem, was mit Code zu tun hat, um die Reproduzierbarkeit zu verbessern\n\nTipps zum Arbeitsablauf\nBearbeitung von csv-Dateien (z. B. Stimuluslisten)\n\n\n\n\n\n\n\n\n\n\n\nAufgabe 3.9: Ausgabeformate\n\n\n\n\nBeispiel 3.9  \n\n\nErsetzt html in der YAML durch revealjs. Rendert das Dokument.\n\nSchauen Sie den Ordner für die Notizen dieser Woche an. Welche Dateien seht?\n\nSetzt nun format auf pdf. Rendert das Dokument.\n\nLäuft es?\nVersuche, pdf durch den Buchstaben l zu ersetzen. R schlägt eine Vervollständigung vor, welche ist es? Wähle sie aus und rendere das Dokument.\n\nSetzt das Format wieder auf html. Rendert das Dokument.\nGeht zurück zu Ihrem Ordner mit den Notizen dieser Woche. Welche Dateien seht?\n\nIst die Ausgabe von revealjs dort?"
  },
  {
    "objectID": "mats/03-quarto_1.html#lernziele-1",
    "href": "mats/03-quarto_1.html#lernziele-1",
    "title": "3  Dynamic reports with Quarto",
    "section": "Lernziele 🏁",
    "text": "Lernziele 🏁\nWir haben…\n\ngelernt, was dynamische Berichte sind ✅\nunser eigenes Quarto-Dokument erstellt ✅\ngelernt, wie man ein Quarto-Dokument bearbeitet ✅\ngelernt, wie man Code in ein Quarto-Dokument einfügt ✅\nein Quarto-Dokument in verschiedenen Formaten wiedergebt ✅"
  },
  {
    "objectID": "mats/03-quarto_1.html#extra-reproduzierbarkeit-in-quarto",
    "href": "mats/03-quarto_1.html#extra-reproduzierbarkeit-in-quarto",
    "title": "3  Dynamic reports with Quarto",
    "section": "3.6 Extra: Reproduzierbarkeit in Quarto",
    "text": "3.6 Extra: Reproduzierbarkeit in Quarto\n\ndie Paketversionen mit sessionInfo() ausgeben\n\nwenn ich ein neues Dokument beginne, ist eines der ersten Dinge, die ich tue, eine Kopfzeile ## Session Info am unteren Ende hinzuzufügen, mit dem folgenden:\n\n\n\nsessionInfo()\n\n\n\n\n\n\n\nAufgabe 3.10: Session Info\n\n\n\n\nBeispiel 3.10  \n\nfügt eine “Session Info” Abschnitt am Ende des Dokuments hin"
  },
  {
    "objectID": "mats/03-quarto_1.html#session-info",
    "href": "mats/03-quarto_1.html#session-info",
    "title": "3  Dynamic reports with Quarto",
    "section": "Session Info",
    "text": "Session Info\nHergestellt mit R version 4.3.0 (2023-04-21) (Already Tomorrow) und RStudioversion 2023.3.0.386 (Cherry Blossom).\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ggthemes_4.2.4  magick_2.7.4    patchwork_1.1.3 lubridate_1.9.2\n [5] forcats_1.0.0   stringr_1.5.0   dplyr_1.1.3     purrr_1.0.2    \n [9] readr_2.1.4     tidyr_1.3.0     tibble_3.2.1    ggplot2_3.4.3  \n[13] tidyverse_2.0.0 languageR_1.5.0\n\nloaded via a namespace (and not attached):\n [1] gt_0.9.0          sass_0.4.6        utf8_1.2.3        generics_0.1.3   \n [5] xml2_1.3.4        stringi_1.7.12    hms_1.1.3         digest_0.6.33    \n [9] magrittr_2.0.3    evaluate_0.21     grid_4.3.0        timechange_0.2.0 \n[13] fastmap_1.1.1     rprojroot_2.0.3   jsonlite_1.8.7    fansi_1.0.4      \n[17] scales_1.2.1      cli_3.6.1         rlang_1.1.1       commonmark_1.9.0 \n[21] munsell_0.5.0     withr_2.5.0       yaml_2.3.7        tools_4.3.0      \n[25] tzdb_0.4.0        colorspace_2.1-0  here_1.0.1        png_0.1-8        \n[29] vctrs_0.6.3       R6_2.5.1          lifecycle_1.0.3   htmlwidgets_1.6.2\n[33] pkgconfig_2.0.3   pillar_1.9.0      gtable_0.3.4      glue_1.6.2       \n[37] Rcpp_1.0.11       xfun_0.39         tidyselect_1.2.0  rstudioapi_0.14  \n[41] knitr_1.44        farver_2.1.1      htmltools_0.5.5   rmarkdown_2.22   \n[45] labeling_0.4.3    compiler_4.3.0    markdown_1.7"
  },
  {
    "objectID": "mats/03-quarto_1.html#literaturverzeichnis",
    "href": "mats/03-quarto_1.html#literaturverzeichnis",
    "title": "3  Dynamic reports with Quarto",
    "section": "Literaturverzeichnis",
    "text": "Literaturverzeichnis\n\n\nNordmann, E., & DeBruine, L. (2022). Applied Data Skills. Zenodo. https://doi.org/10.5281/zenodo.6365078\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for Data Science (2. Aufl.)."
  },
  {
    "objectID": "mats/04-wrangling_1.html#wiederholung",
    "href": "mats/04-wrangling_1.html#wiederholung",
    "title": "4  Data Wrangling 1: Transformation",
    "section": "Wiederholung",
    "text": "Wiederholung\nLetze Woche haben wir…\n\ngelernt, was dynamische Berichte sind\nunser eigenes Quarto-Dokument erstellt\ngelernt, wie man ein Quarto-Dokument bearbeitet\ngelernt, wie man Code in ein Quarto-Dokument einfügt\nein Quarto-Dokument in verschiedenen Formaten wiedergebt"
  },
  {
    "objectID": "mats/04-wrangling_1.html#heutige-ziele",
    "href": "mats/04-wrangling_1.html#heutige-ziele",
    "title": "4  Data Wrangling 1: Transformation",
    "section": "Heutige Ziele",
    "text": "Heutige Ziele\nHeute werden wir…\n\nlernen, wie man Daten mit dem Paket dplyr aus dem tidyverse verarbeitet\nlernen, wie man die pipe (|&gt;) verwendet, um das Ergebnis einer Funktion in eine andere Funktion einzuspeisen\nFunktionen kennenlernen, die auf Zeilen operieren\nFunktionen kennenlernen, die mit Spalten arbeiten\nlernen, wie man dplyr-Funktionen mit Plots von ggplot2 kombiniert\n\n\nLust auf mehr?\n\nKapital 4 (Data transformation) in (wickham_r_nodate?)\nKapital 9 (Data wrangling) in Nordmann & DeBruine (2022)"
  },
  {
    "objectID": "mats/04-wrangling_1.html#voraussetzungen",
    "href": "mats/04-wrangling_1.html#voraussetzungen",
    "title": "4  Data Wrangling 1: Transformation",
    "section": "4.1 Voraussetzungen",
    "text": "4.1 Voraussetzungen\n\nFrisches Quarto-Dokument\n\nErstellen Sie ein neues Quarto-Dokument für den heutigen Unterricht\n\nDatei &gt; Neues Dokument &gt; Quarto Dokument, mit dem Namen 04-wrangling\n\nYAML einrichten: Titel, Ihr Name, ein toc hinzufügen\n\n\n\ntitle: \"Data wrangling\"\nsubtitle: \"Transforming data\"\nauthor: \"Your name here\"\nlang: de\ndate: \"11/08/2023\"\nformat: \n  html:\n    toc: true\n\n\nPakete\n\nDie heutigen Pakete sind:\n\ntidyverse: zum Verarbeiten (dplyr) und Plotten (ggplot2)\nlanguageR: für linguistische Datensätze\n\n\n\n\nlibrary(tidyverse)\nlibrary(languageR)\n\n\nDaten\n\nwir arbeiten wieder mit dem lexdec-Datensatz aus dem languageR-Paket (Baayen & Shafaei-Bajestan, 2019)\nwir speichern ihn als Objekt mit dem Namen df_lexdec\nwir wandeln auch die Variable RT um, so dass sie in Millisekunden angegeben wird (vorher war sie in log Millisekunden angegeben, aber machen Sie sich keine Gedanken darüber, was das bedeutet)\nund wir wählen 10 Variablen aus, die für uns heute relevant sind\n\n\n\ndf_lexdec &lt;- lexdec |&gt; \n  mutate(RT = exp(RT)) |&gt; \n  select(Subject, RT, Trial, Sex, NativeLanguage, Correct, Word, Frequency, Class, Length)"
  },
  {
    "objectID": "mats/04-wrangling_1.html#data-wrangling",
    "href": "mats/04-wrangling_1.html#data-wrangling",
    "title": "4  Data Wrangling 1: Transformation",
    "section": "4.2 Data Wrangling",
    "text": "4.2 Data Wrangling\n\nIm Englischen bezieht sich “wrangling” auf einen langen, schwierigen Prozess\n\n\nB. treiben Cowboys ihre Rinder oder Herden zusammen (sammeln, sammeln ihre Tiere)\n\n\nEs gibt zwei Hauptbestandteile des Wrangling\n\nTransformieren: Sortieren oder Erstellen neuer Variablen (was wir heute tun werden)\nAufräumen: Umformung oder Strukturierung Ihrer Daten (dies werden wir in einigen Wochen tun)\n\nSowohl das Aufräumen als auch das Transformieren von Daten erfordern das Paket dplyr aus dem tidyverse.\n\ndplyr Funktionen werden oft als Verben bezeichnet, weil sie etwas tun\n\n\n\n\n\n\n\n\nDer Name dplyr\n\n\n\n\nDer Name dplyr kommt von einem früheren Paket, plyr, das dazu verwendet wird, Daten zu zerlegen, Funktionen darauf anzuwenden und zu kombinieren\n\nIm Englischen klingt plyr wie das Wort für Zangen (“pliers”), die benutzt werden, um Dinge auseinander zu nehmen, wie das, was plyr mit Daten macht\ndas “d” in “dplyr” wurde hinzugefügt, weil das Paket speziell für die Arbeit mit Datenrahmen gedacht ist\n\n\n\n\n\n4.2.1 lexdec\n\nder lexdec-Datensatz enthält Daten für eine lexikalische Entscheidungsaufgabe im Englischen\n\nSchauen wir uns den Datensatz mit der Funktion head() an, die nur die ersten 6 Zeilen ausgibt\n\nhier geben wir die ersten 10 Zeilen aus\n\n\n\n\nIn meinen Materialien verwende ich oft die Funktion “head()”, um zu vermeiden, dass der gesamte Datensatz in der Ausgabe gedruckt wird, aber Sie würden im Allgemeinen nicht “head()” verwenden wollen, wenn Sie Ihre Daten betrachten, sondern Ihren gesamten Datensatz betrachten wollen\n\n\n\n\n\n\n\nAufgabe 4.1: df_lexdec\n\n\n\n\nBeispiel 4.1  \n\n\nBetrachten Sie den Datensatz\n\nwie viele Beobachtungen gibt es?\nWie viele Variablen gibt es?\n\nGeben Sie den Datensatz in die Funktion glimpse() ein.\n\nWas zeigt Ihnen das?\nWie sieht es im Vergleich zu dem aus, was Sie sehen, wenn Sie summary() verwenden?\n\n\n\n\n\n\n\n\n4.2.2 dplyr-Grundlagen\n\nheute lernen wir einige der wichtigsten dplyr-Verben (Funktionen) kennen, mit denen wir die meisten unserer Datenmanipulationsprobleme lösen können\n\nIch verwende diese Verben mehrfach in wahrscheinlich jedem Analyseskript\n\nDie dplyr-Verben haben einige Dinge gemeinsam:\n\ndas erste Argument ist immer ein Datenrahmen\ndie folgenden Argumente beschreiben in der Regel die zu bearbeitenden Spalten, wobei der Variablenname (ohne Anführungszeichen) verwendet wird\ndie Ausgabe ist immer ein neuer Datenrahmen\n\n\n\nDie Verben sind alle für eine Sache gut geeignet, so dass wir oft mehrere Verben auf einmal verwenden wollen.\n\nWir verwenden dazu die Pipe (|&gt; oder |&gt;)\nWir haben diese Pipe bereits gesehen, als wir einen Datenrahmen in ggplot() einspeisten.\nwir können die Pipe als und dann lesen\n\n\n\nIn dem folgenden Code identifizieren\n\nden Datenrahmen\ndplyr-Verben\nVariablennamen\n\nKannst du versuchen, herauszulesen (zu erraten), was der folgende Code macht?\n\n\ndf_lexdec |&gt; \n  filter(Subject == \"A1\") |&gt; \n  select(Subject, Trial, RT, NativeLanguage, Word) |&gt; \n  relocate(NativeLanguage, .after = Trial)\n\n\n\n\n\n\n\nKorrekte Syntax\n\n\n\n.Beachten Sie, dass A1 mit Anführungszeichen geschrieben wird, aber keiner der anderen Codes. Wenn wir ein Objekt (z.B. df_lexdec) oder seine Variablen (z.B. Subject) aufrufen, setzen wir sie nicht in Anführungszeichen. Wenn wir einen bestimmten Wert einer Variablen aufrufen, der nicht numerisch ist, müssen wir diesen Wert in Anführungszeichen setzen, weil die Subject ID A1 ein Wert der Variablen Subject ist, müssen wir sie in Anführungszeichen setzen.\nVersuchen Sie, die Anführungszeichen zu entfernen. Welche Fehlermeldung erhalten Sie?\nVersuchen Sie, einen Variablennamen in Anführungszeichen zu setzen, welche Fehlermeldung erhalten Sie?\nDies ist eine wichtige Übung, denn Sie werden oft feststellen, dass Ihr Code nicht läuft, aber die Lösung ist oft etwas so Einfaches wie fehlende oder zusätzliche Anführungszeichen oder Interpunktion."
  },
  {
    "objectID": "mats/04-wrangling_1.html#zeilen",
    "href": "mats/04-wrangling_1.html#zeilen",
    "title": "4  Data Wrangling 1: Transformation",
    "section": "4.3 Zeilen",
    "text": "4.3 Zeilen\n\nIn aufgeräumten Daten stellen die Zeilen Beobachtungen dar.\ndie wichtigsten Verben für Zeilen sind:\n\nfilter(): ändert, welche Zeilen vorhanden sind\narrange(): ändert die Reihenfolge der Zeilen\n\nWir besprechen auch\n\ndistinct(): findet Zeilen mit unterschiedlichen Werten basierend auf einer Variablen (Spalte)\n\n\n\n4.3.1 filter()\n\nändert, welche Zeilen vorhanden sind, ohne ihre Reihenfolge zu ändern\nnimmt den Datenrahmen als erstes Argument\n\nDie folgenden Argumente sind Bedingungen, die TRUE sein müssen, damit die Zeile erhalten bleibt\n\n\n\nfindet alle Reaktionszeiten, die länger als 450 Millisekunden waren:\n\n\ndf_lexdec |&gt; \n  filter(RT &gt; 450) |&gt; \n  head()\n\n  Subject       RT Trial Sex NativeLanguage Correct       Word Frequency  Class\n1      A1 566.9998    23   F        English correct        owl  4.859812 animal\n2      A1 548.9998    27   F        English correct       mole  4.605170 animal\n3      A1 572.0000    29   F        English correct     cherry  4.997212  plant\n4      A1 486.0002    30   F        English correct       pear  4.727388  plant\n6      A1 483.0002    33   F        English correct blackberry  4.060443  plant\n8      A1 524.9999    38   F        English correct   squirrel  4.709530 animal\n  Length\n1      3\n2      4\n3      6\n4      4\n6     10\n8      8\n\n\n\nBeachten Sie, dass wir den Wert der Reaktionszeit nicht in Anführungszeichen setzen, da er numerisch ist\n\n\nwenn Sie die gefilterten Daten speichern wollen, ist es in der Regel ratsam, sie unter einem neuen Objektnamen zu speichern\n\nwenn Sie die vorgefilterte Version nicht überschreiben wollen, ist ein neuer Name erforderlich\n\n\n\ndf_lexdec_450 &lt;- \n  df_lexdec |&gt; \n  filter(RT &gt; 450)\n\n\n\n\n\n\n\nLogische Operatoren\n\n\n\n\n\nSymbole, die zur Beschreibung einer logischen Bedingung verwendet werden\n\n== ist identisch (1 == 1)\n!= ist nicht identisch (1 != 2)\n&gt; ist größer als (2 &gt; 1)\n&lt; ist kleiner als (1 &lt; 2)\n\num Bedingungen zu kombinieren\n\n& oder , und auch (für mehrere Bedingungen)\n| oder (für mehrere Bedingungen)\n\nes gibt eine nette Abkürzung für die Kombination von == und |: %in%\n\nbehält Zeilen, in denen die Variable gleich einem der Werte auf der rechten Seite ist\n\n\n\n== und |%in%\n\n\n\ndf_lexdec |&gt; \n  filter(Trial == 30 | Trial == 23) |&gt; \n  head()\n\n    Subject       RT Trial Sex NativeLanguage Correct    Word Frequency  Class\n1        A1 566.9998    23   F        English correct     owl  4.859812 animal\n4        A1 486.0002    30   F        English correct    pear  4.727388  plant\n475      A2 561.0001    23   M        English correct     dog  7.667626 animal\n949       C 688.0001    23   F        English correct vulture  4.248495 animal\n83        D 553.0000    30   M          Other correct  walnut  4.499810  plant\n317       J 824.0004    23   F          Other correct  beaver  3.951244 animal\n    Length\n1        3\n4        4\n475      3\n949      7\n83       6\n317      6\n\n\n\n\n\ndf_lexdec |&gt; \n  filter(Trial %in% c(30, 23)) |&gt; \n  head()\n\n    Subject       RT Trial Sex NativeLanguage Correct    Word Frequency  Class\n1        A1 566.9998    23   F        English correct     owl  4.859812 animal\n4        A1 486.0002    30   F        English correct    pear  4.727388  plant\n475      A2 561.0001    23   M        English correct     dog  7.667626 animal\n949       C 688.0001    23   F        English correct vulture  4.248495 animal\n83        D 553.0000    30   M          Other correct  walnut  4.499810  plant\n317       J 824.0004    23   F          Other correct  beaver  3.951244 animal\n    Length\n1        3\n4        4\n475      3\n949      7\n83       6\n317      6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAufgabe 4.2: filter()\n\n\n\n\nBeispiel 4.2  \n\n\nFiltern Sie die Daten, um Zeilen aus Versuch 25 und Nicht-Muttersprachler (andere) einzuschließen.\nWie viele Zeilen gibt es?\n\n\n\n\n\n\n\n4.3.2 arrange()\n\nändert die Reihenfolge der Zeilen auf der Grundlage eines Wertes in einer oder mehreren Spalten\n\n\ndf_lexdec |&gt; \n  arrange(RT) |&gt; \n  head()\n\n     Subject       RT Trial Sex NativeLanguage   Correct    Word Frequency\n542       A2 340.0001   159   M        English incorrect     pig  6.660575\n815        K 347.9998    83   F        English incorrect   lemon  5.631212\n822        K 363.0001    99   F        English incorrect  potato  6.461468\n73        A1 364.9999   174   F        English   correct chicken  6.599870\n524       A2 365.9999   117   M        English   correct   goose  5.267858\n1516       I 367.0001    51   F          Other   correct  carrot  4.976734\n      Class Length\n542  animal      3\n815   plant      5\n822   plant      6\n73   animal      7\n524  animal      5\n1516  plant      6\n\n\n\nwenn Sie mehr als einen Spaltennamen verwenden, wird jede zusätzliche Spalte verwendet, um die Verbindung zwischen den Werten der vorangegangenen Spalten zu lösen\n\n\ndf_lexdec |&gt; \n  arrange(Length,Sex) |&gt; \n  head(10)\n\n    Subject       RT Trial Sex NativeLanguage   Correct Word Frequency  Class\n1        A1 566.9998    23   F        English   correct  owl  4.859812 animal\n5        A1 414.0000    32   F        English   correct  dog  7.667626 animal\n15       A1 556.9999    53   F        English   correct  bee  5.700444 animal\n20       A1 456.9998    61   F        English incorrect  bat  5.918894 animal\n31       A1 581.9997    88   F        English   correct  fox  5.652489 animal\n44       A1 494.0002   113   F        English   correct  pig  6.660575 animal\n62       A1 467.9999   152   F        English   correct  cat  7.086738 animal\n64       A1 875.9999   157   F        English   correct  ant  5.347108 animal\n719      A3 607.0001    41   F          Other   correct  ant  5.347108 animal\n720      A3 562.0001    44   F          Other   correct  pig  6.660575 animal\n    Length\n1        3\n5        3\n15       3\n20       3\n31       3\n44       3\n62       3\n64       3\n719      3\n720      3\n\n\n\nwir können desc() innerhalb von arrange() hinzufügen, um eine absteigende Reihenfolge (groß-klein) anstelle der standardmäßigen aufsteigenden Reihenfolge zu verwenden\n\n\ndf_lexdec |&gt; \n  arrange(desc(Length)) |&gt; \n  head()\n\n    Subject       RT Trial Sex NativeLanguage Correct       Word Frequency\n6        A1 483.0002    33   F        English correct blackberry  4.060443\n7        A1 417.9998    34   F        English correct strawberry  4.753590\n69       A1 540.9998   168   F        English correct woodpecker  2.890372\n505      A2 503.9999    87   M        English correct woodpecker  2.890372\n516      A2 400.9998   105   M        English correct strawberry  4.753590\n518      A2 517.0001   108   M        English correct blackberry  4.060443\n     Class Length\n6    plant     10\n7    plant     10\n69  animal     10\n505 animal     10\n516  plant     10\n518  plant     10\n\n\n\n\n\n\n\n\nAufgabe 4.3: arrange()\n\n\n\n\nBeispiel 4.3  \n\n\nFiltere die Daten so, dass sie nur Beobachtungen der “Probanden” M1 und W2 enthalten, und dann\nOrdnen Sie die Daten nach absteigender Reaktionszeit"
  },
  {
    "objectID": "mats/04-wrangling_1.html#spalten",
    "href": "mats/04-wrangling_1.html#spalten",
    "title": "4  Data Wrangling 1: Transformation",
    "section": "4.4 Spalten",
    "text": "4.4 Spalten\n\nIn Tidy Data stellen die Spalten Variablen dar.\ndie wichtigsten Verben für Spalten sind:\n\nrename(): ändert die Namen der Spalten\nmutate(): erzeugt neue Spalten, die von den vorhandenen Spalten abgeleitet werden\nselect(): ändert, welche Spalten vorhanden sind\nrelocate(): ändert die Position der Spalten\n\n\n\n4.4.1 rename()\n\nMit rename() können wir den Namen von Spalten ändern\n\ndie Reihenfolge der Argumente ist neuer_name = alter_name\n\nVersuchen wir, einige der Variablennamen auf Deutsch zu ändern\n\nIch neige dazu, Variablennamen in Kleinbuchstaben zu schreiben, als Kodierungskonvention\n\n\n\n## single variable\ndf_lexent &lt;- \n  df_lexdec |&gt;\n  rename(teilnehmer = Subject)\n\n## or multiple variables at once\ndf_lexent &lt;- \n  df_lexdec |&gt; \n rename(teilnehmer = Subject,\n        rz_ms = RT,\n        geschlect = Sex,\n        laenge = Length)\n\n\n\n4.4.2 mutate()\n\nMit mutate() werden neue Spalten aus vorhandenen Spalten erzeugt.\n\nSo können wir z.B. einfache Algebra mit den Werten in jeder Spalte durchführen\n\n\n\ndf_lexent |&gt; \n  mutate(\n    rz_laenge = rz_ms / laenge,\n  ) |&gt; \n  head()\n\n  teilnehmer    rz_ms Trial geschlect NativeLanguage Correct       Word\n1         A1 566.9998    23         F        English correct        owl\n2         A1 548.9998    27         F        English correct       mole\n3         A1 572.0000    29         F        English correct     cherry\n4         A1 486.0002    30         F        English correct       pear\n5         A1 414.0000    32         F        English correct        dog\n6         A1 483.0002    33         F        English correct blackberry\n  Frequency  Class laenge rz_laenge\n1  4.859812 animal      3 188.99994\n2  4.605170 animal      4 137.24994\n3  4.997212  plant      6  95.33333\n4  4.727388  plant      4 121.50005\n5  7.667626 animal      3 138.00000\n6  4.060443  plant     10  48.30002\n\n\n\nMit mutate() werden diese neuen Spalten auf der rechten Seite des Datensatzes hinzugefügt.\n\nDas macht es schwierig zu sehen, was passiert.\n\num zu kontrollieren, wo die neue Spalte hinzugefügt wird, können wir .before oder .after verwenden\n\n\ndf_lexent |&gt; \n  mutate(\n    rz_laenge = rz_ms / laenge,\n    .after = rz_ms\n  ) |&gt; \n  head()\n\n  teilnehmer    rz_ms rz_laenge Trial geschlect NativeLanguage Correct\n1         A1 566.9998 188.99994    23         F        English correct\n2         A1 548.9998 137.24994    27         F        English correct\n3         A1 572.0000  95.33333    29         F        English correct\n4         A1 486.0002 121.50005    30         F        English correct\n5         A1 414.0000 138.00000    32         F        English correct\n6         A1 483.0002  48.30002    33         F        English correct\n        Word Frequency  Class laenge\n1        owl  4.859812 animal      3\n2       mole  4.605170 animal      4\n3     cherry  4.997212  plant      6\n4       pear  4.727388  plant      4\n5        dog  7.667626 animal      3\n6 blackberry  4.060443  plant     10\n\n\n\n\n\n\n\n\nRendernpause!\n\n\n\n\nNehmen Sie sich einen Moment Zeit, um Ihr Dokument zu rendern. Wird es gerendert?\nKönnen Sie das Dokument besser strukturieren? Z. B. durch Hinzufügen von mehr Überschriften, Text?\n\n\n\n\n\n\n\n\n\nAufgabe 4.4: mutate()\n\n\n\n\nBeispiel 4.4  \n\n\nCreate a new variable called rz_s in df_lexent:\n\nequals rz_ms divided by 1000 (i.e., converts milliseconds to seconds)\nappears after rz_ms\n\nRender your document\n\n\n\n\n\n\n\n4.4.3 select()\n\nselect() fasst die Daten so zusammen, dass sie nur die gewünschten Spalten enthalten\nSpalten nach Namen auswählen\n\n\ndf_lexent |&gt; \n  select(teilnehmer, rz_ms, Word) |&gt; \n  head()\n\n  teilnehmer    rz_ms       Word\n1         A1 566.9998        owl\n2         A1 548.9998       mole\n3         A1 572.0000     cherry\n4         A1 486.0002       pear\n5         A1 414.0000        dog\n6         A1 483.0002 blackberry\n\n\n\nselect alle Spalten zwischen rz_ms und geschlecht\n\n\ndf_lexent |&gt; \n  select(rz_ms:geschlect) |&gt; \n  head()\n\n     rz_ms      rz_s Trial geschlect\n1 566.9998 0.5669998    23         F\n2 548.9998 0.5489998    27         F\n3 572.0000 0.5720000    29         F\n4 486.0002 0.4860002    30         F\n5 414.0000 0.4140000    32         F\n6 483.0002 0.4830002    33         F\n\n\n\nalle Spalten außer rz_s auswählen (! wird als “nicht” gelesen)\n\n\ndf_lexent |&gt; \n  select(!rz_s) |&gt; \n  head()\n\n  teilnehmer    rz_ms Trial geschlect NativeLanguage Correct       Word\n1         A1 566.9998    23         F        English correct        owl\n2         A1 548.9998    27         F        English correct       mole\n3         A1 572.0000    29         F        English correct     cherry\n4         A1 486.0002    30         F        English correct       pear\n5         A1 414.0000    32         F        English correct        dog\n6         A1 483.0002    33         F        English correct blackberry\n  Frequency  Class laenge\n1  4.859812 animal      3\n2  4.605170 animal      4\n3  4.997212  plant      6\n4  4.727388  plant      4\n5  7.667626 animal      3\n6  4.060443  plant     10\n\n\n\n4.4.3.1 select()-Hilfsfunktionen\n\neinige Hilfsfunktionen, die das Leben bei der Arbeit mit select() erleichtern:\n\nstarts_with(\"abc\"): wählt Spalten aus, die mit einer bestimmten Zeichenkette beginnen\nends_with(\"xyz\"): wählt Spalten aus, die mit einer bestimmten Zeichenkette enden\ncontains(\"ijk\"): wählt Spalten aus, die eine bestimmte Zeichenkette enthalten\nwhere(is.character): wählt Spalten aus, die einem logischen Kriterium entsprechen\n\nz.B. gibt die Funktion is.character() den Wert TRUE zurück, wenn eine Variable Zeichenketten enthält, nicht numerische Werte oder Kategorien\n\n\n\n\n\n\ndf_lexent |&gt; \n  select(starts_with(\"w\")) |&gt; \n  head()\n\n        Word\n1        owl\n2       mole\n3     cherry\n4       pear\n5        dog\n6 blackberry\n\n\n\n\ndf_lexent |&gt; \n  select(ends_with(\"er\")) |&gt; \n  head()\n\n  teilnehmer\n1         A1\n2         A1\n3         A1\n4         A1\n5         A1\n6         A1\n\n\n\n\n\n\n\n\n\n\nAufgabe 4.5: select()\n\n\n\n\nBeispiel 4.5  \n\n\nDrucke die Spalten in df_lexent, die mit “t” beginnen\nDrucke die Spalten in df_lexent, die “ge” enthalten\nDrucke die Spalten in df_lexent, die\n\nmit mit “r” beginnen, und\nmit “s” enden\n\n\n\n\n\n\n\n\n\n4.4.4 relocate()\n\nrelocate() verschiebt Variablen\n\nstandardmäßig werden sie nach vorne verschoben\n\n\n\ndf_lexent |&gt; relocate(Trial) |&gt; \n  head()\n\n  Trial teilnehmer    rz_ms      rz_s geschlect NativeLanguage Correct\n1    23         A1 566.9998 0.5669998         F        English correct\n2    27         A1 548.9998 0.5489998         F        English correct\n3    29         A1 572.0000 0.5720000         F        English correct\n4    30         A1 486.0002 0.4860002         F        English correct\n5    32         A1 414.0000 0.4140000         F        English correct\n6    33         A1 483.0002 0.4830002         F        English correct\n        Word Frequency  Class laenge\n1        owl  4.859812 animal      3\n2       mole  4.605170 animal      4\n3     cherry  4.997212  plant      6\n4       pear  4.727388  plant      4\n5        dog  7.667626 animal      3\n6 blackberry  4.060443  plant     10\n\n\n\naber wir können auch .before oder .after verwenden, um eine Variable zu platzieren\n\n\ndf_lexent |&gt; \n  relocate(Trial, .after = teilnehmer) |&gt; \n  head()\n\n  teilnehmer Trial    rz_ms      rz_s geschlect NativeLanguage Correct\n1         A1    23 566.9998 0.5669998         F        English correct\n2         A1    27 548.9998 0.5489998         F        English correct\n3         A1    29 572.0000 0.5720000         F        English correct\n4         A1    30 486.0002 0.4860002         F        English correct\n5         A1    32 414.0000 0.4140000         F        English correct\n6         A1    33 483.0002 0.4830002         F        English correct\n        Word Frequency  Class laenge\n1        owl  4.859812 animal      3\n2       mole  4.605170 animal      4\n3     cherry  4.997212  plant      6\n4       pear  4.727388  plant      4\n5        dog  7.667626 animal      3\n6 blackberry  4.060443  plant     10"
  },
  {
    "objectID": "mats/04-wrangling_1.html#dplyr-und-ggplot2",
    "href": "mats/04-wrangling_1.html#dplyr-und-ggplot2",
    "title": "4  Data Wrangling 1: Transformation",
    "section": "4.5 dplyr und ggplot2",
    "text": "4.5 dplyr und ggplot2\n\nwir können einen Datensatz mit den dplyr-Verben ändern und diese Änderungen dann in ggplot2 einspeisen\nWas wird der folgende Code ergeben?\n\n\ndf_lexent |&gt; \n  ## filter the data\n  filter(rz_ms &gt; 120,\n         rz_ms &gt; 500) |&gt; \n  ## plot the filtered data\n  ggplot(aes(x = fct_infreq(Correct))) +\n  geom_bar() +\n  theme_minimal()\n\n\n4.5.1 Pipe versus plus (|&gt; vs. +)\n\nwichtig: wir können Pipes (|&gt;) verwenden, um zusätzliche Verben/Funktionen mit dem Ergebnis einer vorherigen Codezeile auszuführen\n\nDie Funktion ggplot() verwendet jedoch +, um neue Ebenen zur Darstellung hinzuzufügen\n\n\n\n\n\n\n\n\nRendernpause!\n\n\n\n\nNehmen Sie sich einen Moment Zeit, um Ihr Dokument zu rendern. Wird es gerendert?\nKönnen Sie das Dokument besser strukturieren? Z. B. durch Hinzufügen von mehr Überschriften, Text?"
  },
  {
    "objectID": "mats/04-wrangling_1.html#aufgaben",
    "href": "mats/04-wrangling_1.html#aufgaben",
    "title": "4  Data Wrangling 1: Transformation",
    "section": "Aufgaben",
    "text": "Aufgaben\n\n\nDrucken Sie in einer einzigen Pipeline df_lexent, wobei Sie nur die Spalten Reaktionszeiten (in Millisekunden), NativeLanguage und Word für Zeilen auswählen, die jede der folgenden Bedingungen erfüllen, sie in der Reihenfolge der Reaktionszeiten anordnen und so filtern, dass nur diese Zeilen berücksichtigt werden:\n\ndie Reaktionszeiten waren größer als 500ms und kleiner als 550ms\naus den Wörtern “pear”, “elephant” oder “tortoise” stammen\n\n\n\nSortiere (arrange()) df_lexent in absteigender Reihenfolge, um die Versuche mit den längsten Reaktionszeiten zu finden.\n\n\n\n\nSpeichern Sie in einer einzigen Pipeline ein neues Objekt namens df_rz, das df_lexent enthält, und dann:\n\nSelektieren (select()) Sie die Variablen Teilnehmer, NativeLanguage, Word, rz_s, laenge, und Frequency\nErstelle eine neue Variable rz_s_laenge (mutate()), die rz_s geteilt durch laenge ist\n\nund wird vor Laenge gesetzt\n\nBenennen (rename()`) Sie diese Variablen in Englisch um, so dass sie in Deutsch (und mit Kleinbuchstaben) sind."
  },
  {
    "objectID": "mats/04-wrangling_1.html#heutige-ziele-1",
    "href": "mats/04-wrangling_1.html#heutige-ziele-1",
    "title": "4  Data Wrangling 1: Transformation",
    "section": "Heutige Ziele 🏁",
    "text": "Heutige Ziele 🏁\nHeute haben wir gelernt…\n\nwie man Daten mit dem Paket dplyr aus dem tidyverse verarbeitet ✅\nwie man die pipe (|&gt;) verwendet, um das Ergebnis einer Funktion in eine andere Funktion einzuspeisen ✅\nüber Funktionen, die auf Zeilen operieren ✅\nüber Funktionen, die auf Spalten operieren ✅\nwie man dplyr-Funktionen mit Plots von ggplot2 kombiniert ✅"
  },
  {
    "objectID": "mats/04-wrangling_1.html#session-info",
    "href": "mats/04-wrangling_1.html#session-info",
    "title": "4  Data Wrangling 1: Transformation",
    "section": "Session Info",
    "text": "Session Info\nHergestellt mit R version 4.3.0 (2023-04-21) (Already Tomorrow) und RStudioversion 2023.9.0.463 (Desert Sunflower).\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] languageR_1.5.0 lubridate_1.9.2 forcats_1.0.0   stringr_1.5.0  \n [5] dplyr_1.1.3     purrr_1.0.2     readr_2.1.4     tidyr_1.3.0    \n [9] tibble_3.2.1    ggplot2_3.4.3   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4      jsonlite_1.8.7    compiler_4.3.0    tidyselect_1.2.0 \n [5] scales_1.2.1      yaml_2.3.7        fastmap_1.1.1     R6_2.5.1         \n [9] generics_0.1.3    knitr_1.44        htmlwidgets_1.6.2 munsell_0.5.0    \n[13] pillar_1.9.0      tzdb_0.4.0        rlang_1.1.1       utf8_1.2.3       \n[17] stringi_1.7.12    xfun_0.39         timechange_0.2.0  cli_3.6.1        \n[21] withr_2.5.0       magrittr_2.0.3    digest_0.6.33     grid_4.3.0       \n[25] rstudioapi_0.14   hms_1.1.3         lifecycle_1.0.3   vctrs_0.6.3      \n[29] evaluate_0.21     glue_1.6.2        fansi_1.0.4       colorspace_2.1-0 \n[33] rmarkdown_2.22    tools_4.3.0       pkgconfig_2.0.3   htmltools_0.5.5"
  },
  {
    "objectID": "mats/04-wrangling_1.html#literaturverzeichnis",
    "href": "mats/04-wrangling_1.html#literaturverzeichnis",
    "title": "4  Data Wrangling 1: Transformation",
    "section": "Literaturverzeichnis",
    "text": "Literaturverzeichnis\n\n\nBaayen, R. H., & Shafaei-Bajestan, E. (2019). languageR: Analyzing Linguistic Data: A Practical Introduction to Statistics. https://CRAN.R-project.org/package=languageR\n\n\nNordmann, E., & DeBruine, L. (2022). Applied Data Skills. Zenodo. https://doi.org/10.5281/zenodo.6365078\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for Data Science (2. Aufl.)."
  },
  {
    "objectID": "mats/05-dataviz_2.html#wiederholung",
    "href": "mats/05-dataviz_2.html#wiederholung",
    "title": "5  Datenvisualisierung 2",
    "section": "Wiederholung",
    "text": "Wiederholung\nLetzte Woche haben wir gelernt…\n\nwie man Daten mit dem Paket dplyr aus dem tidyverse verarbeitet\ngelernt, wie man die pipe (|&gt;) verwendet, um das Ergebnis einer Funktion in eine andere Funktion einzuspeisen\nüber Funktionen, die auf Zeilen operieren\n\nfilter(), arrange()\n\nüber Funktionen, die auf Spalten operieren\n\nrename(), mutate(), select(), relocate()\n\nwie man dplyr-Funktionen mit Plots von ggplot2 kombiniert"
  },
  {
    "objectID": "mats/05-dataviz_2.html#lernziele",
    "href": "mats/05-dataviz_2.html#lernziele",
    "title": "5  Datenvisualisierung 2",
    "section": "Lernziele",
    "text": "Lernziele\nHeute werden wir lernen…\n\nwie man zwei oder mehr Variablen darstellt\n\nmit Ästhetik und mit Facettenrastern\n\nwie man Codechunk-Optionen verwendet\nwie man Plots als Dateien speichert\n\n\nLesungen\nDie Pflichtlektüre zur Vorbereitung auf dieses Thema ist Kap. 2 (Datenvisualisierung) aus Abschnitt 2.5 in Wickham et al. (2023).\nEine ergänzende Lektüre ist Ch. 3 (Data visualtion) in Nordmann & DeBruine (2022)."
  },
  {
    "objectID": "mats/05-dataviz_2.html#set-up",
    "href": "mats/05-dataviz_2.html#set-up",
    "title": "5  Datenvisualisierung 2",
    "section": "Set-up",
    "text": "Set-up\n\nPackages\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggthemes)\nlibrary(languageR)\n\n\ntidyverse Familie von Paketen\n\nggplot2 für Diagramme\ndplyr für die Datenverarbeitung\n\nggthemes für farbenblindenfreundliche Farbpaletten\npatchwork für Plot-Layouts\nlanguageR für linguistische Datensätze\n\n\n\nggplot theme\nIch habe mein bevorzugtes ggplot-Thema global festgelegt. Das bedeutet, dass nach dem Ausführen dieses Codes alle Diagramme dieses Thema verwenden werden.\n\ntheme_set(theme_bw())\n\n\n\nData\nWir verwenden den english-Datensatz aus dem Baayen & Shafaei-Bajestan (2019).\n\nenthält Daten aus einer lexikalischen Entscheidungsaufgabe in Englisch\nDie logarithmisch transformierten Reaktionszeiten werden zurücktransformiert, so dass sie in Millisekunden angegeben werden.\n\nWir verwenden dazu die Funktion exp().\n\n\n\ndf_english &lt;- \n  english |&gt; \n  mutate(RTlexdec = exp(RTlexdec),\n         RTnaming = exp(RTnaming))\n\n\nenglish dataset\nUnsere Variablen von Interesse sind:\n\n\n\n\nTabelle 5.1: english dataset variables of interest\n\n\nvariable\ndescription\ntype\n\n\n\n\nRTlexdec\nReaktionszeiten für eine visuelle lexikalische Entscheidung (Millisekunden)\nkontinuierlich\n\n\nRTnaming\nReaktionszeiten für den Beginn einer verbalen Wortbenennungsaufgabe (Millisekunden)\nkontinuierlich\n\n\nWrittenFrequency\nnumerischer Vektor mit der logarithmischen Häufigkeit in der lexikalischen Datenbank von CELEX\nkontinuierlich\n\n\nWort\nein Faktor mit 2284 Wörtern\nkategorisch\n\n\nAgeSubject\nein Faktor mit der Altersgruppe des Probanden als Level: jung versus alt\nkategorisch\n\n\nWordCategory\nein Faktor mit den Wortkategorien N (Substantiv) und V (Verb) als Ebenen\nkategorisch\n\n\nCV\nFaktor, der angibt, ob das Anfangsphonem des Wortes ein Konsonant (C) oder ein Vokal (V) ist.\nkategorisch\n\n\nCorrectLexdec\nnumerischer Vektor mit dem Anteil der Probanden, die das Item bei der lexikalischen Entscheidung als Wort akzeptiert haben.\nkontinuierlich\n\n\n\n\n\n\n\n\n\n\n\nHypotheses\n\nWelche Arten von Hypothesen könnten Sie für solche Daten aufstellen?\n\nUnsere Reaktionszeitdaten sind unsere Messvariablen.\n\nd.h. das, was wir messen\n\nAlle anderen Variablen sind mögliche Vorhersagevariablen.\n\nd.h. wir könnten vorhersagen, dass ihr Wert unsere Messvariablen beeinflussen würde\n\n\nWelche Auswirkung (wenn überhaupt) könnte zum Beispiel die Worthäufigkeit auf die Reaktionszeiten bei lexikalischen Entscheidungsaufgaben haben? auf die Benennungszeiten?\n\nWie sieht es mit Unterschieden in den Reaktionszeiten zwischen jüngeren und älteren Teilnehmern aus?\n\nWelchen Effekt (wenn überhaupt) könnte die Wortkategorie auf die Reaktionszeiten haben?"
  },
  {
    "objectID": "mats/05-dataviz_2.html#datenvisualisierung",
    "href": "mats/05-dataviz_2.html#datenvisualisierung",
    "title": "5  Datenvisualisierung 2",
    "section": "5.1 Datenvisualisierung",
    "text": "5.1 Datenvisualisierung\n\nDie Visualisierung unserer Daten hilft uns, die Beziehung zwischen den Variablen zu veranschaulichen, um eine Geschichte zu erzählen.\nIn der Regel visualisieren wir Variablen, für die wir eine bestimmte Hypothese haben: Prädiktor- und Messvariable(n)\n\n\n5.1.1 Visualisierung von Verteilungen\n\nHistogramme, Dichtediagramme und Balkendiagramme für Zählwerte visualisieren die Verteilung von Beobachtungen\n\nSie geben Aufschluss darüber, wie oft wir bestimmte Werte einer Variablen beobachtet haben.\nIn der Regel tun wir dies, um ein Gefühl dafür zu bekommen, wie unsere Daten aussehen\n\nWas ist der Bereich unserer Daten, der Modus, die Gesamtverteilung der Werte?\n\n\n\n\n\n\n\n\n\nAufgabe: Beziehungen visualisieren\n\n\n\n\nErstellen Sie ein Diagramm, das die Verteilung der Häufigkeit der geschriebenen Wörter visualisiert.\nErstellen Sie ein Diagramm, das die Verteilung von Substantiven und Verben visualisiert."
  },
  {
    "objectID": "mats/05-dataviz_2.html#visualisierung-von-beziehungen",
    "href": "mats/05-dataviz_2.html#visualisierung-von-beziehungen",
    "title": "5  Datenvisualisierung 2",
    "section": "5.2 Visualisierung von Beziehungen",
    "text": "5.2 Visualisierung von Beziehungen\n\nUm Beziehungen zwischen Variablen zu visualisieren, müssen wir mindestens zwei Variablen auf die Ästhetik eines Diagramms abbilden\nWir haben dies bereits getan, indem wir Farbe oder Füllung einer kategorischen Variable zugeordnet haben, während wir eine\n\neine kontinuierliche Variable auf die x-Achse für Histogramme/Dichte-Diagramme, oder\neine kategoriale Variable auf die y-Achse für ein Balkendiagramm\n\n\n\n\n\n\n\n\nAufgabe: Visualisierung von Beziehungen in Verteilungen\n\n\n\n\nFügen Sie den soeben erstellten Diagrammen eine weitere Ästhetik hinzu, um sie darzustellen:\n\ndie Verteilung der WrittenFrequency-Werte für Wörter mit Anfangskonsonanten und Vokalen\ndie Verteilung der Substantive und Verben für Wörter mit Anfangskonsonanten und Vokalen\n\n\n\n\n\n5.2.1 Gruppierte kontinuierliche Variable\n\nUnsere Histogramme, Dichtediagramme und Balkendiagramme zeigen die Verteilung der Werte einer kontinuierlichen Variable nach verschiedenen Stufen einer kategorischen Variable\n\n\n5.2.1.1 Gestapelt\n\nBeachten Sie, dass diese Kategorien standardmäßig übereinander gestapelt sind.\n\n\n\n\n\n\nAbbildung 5.1: Visualising relationships in distributions\n\n\n\n\n\n\n5.2.1.2 Dodged (Ausgewiche)\n\naber dass wir sie nebeneinander haben können, indem wir identity auf dodge setzen\n\nIch finde, dass dies für Balkenplots nützlicher ist\n\n\n\n\n\n\n\nAbbildung 5.2: Visualising relationships in distributions\n\n\n\n\n\n\n\n5.2.2 Zwei kontinuierliche Variablen\n\nWir wollen oft die Auswirkungen einer kontinuierlichen Variable auf eine andere sehen.\nIn unserem Datensatz english haben wir zum Beispiel die Variablen WrittenFreuqency und RTlexdec\n\nWelche Art von Beziehung werden diese beiden Variablen Ihrer Meinung nach haben?\nDenken Sie z.B., dass Wörter mit einer niedrigeren WrittenFrequency in einer lexikalischen Entscheidungsaufgabe tendenziell längere oder kürzere Reaktionszeiten haben werden?\nWie könnte man sich eine solche Beziehung vorstellen?\n\n\n\n\n\n\n## + geom_?\ndf_english |&gt; \n  ggplot() +\n  aes(x = WrittenFrequency, y = RTlexdec) \n\n\n\n\n\n\n\n\ndf_english |&gt; \n  ggplot() +\n  aes(x = WrittenFrequency, y = RTlexdec) +\n  geom_point()\n\n\n\n\n\nNehmen Sie sich einen Moment Zeit, um diese Grafik zu betrachten und eine Interpretation zu finden\n\nWelchen Einfluss hat die Schrifthäufigkeit eines Wortes auf die Reaktionszeit bei einer lexikalischen Entscheidungsaufgabe?\nVervollständigen Sie den Satz: “Wörter mit einer höheren Worthäufigkeit lösten ___________ Reaktionszeiten aus”\n\nWo gab es mehr Variation in den Reaktionszeiten? Wo gab es weniger Variation?\n\n\n\n5.2.3 Hinzufügen weiterer Variablen\n\nErinnern Sie sich daran, dass wir andere Ästhetiken wie fill oder colour verwenden können\n\nfür geom_point() ist es auch hilfreich, shape zu verwenden\n\n\n\ndf_english |&gt; \n  ggplot() +\n  aes(x = WrittenFrequency, y = RTlexdec,\n      colour = AgeSubject,\n      shape = AgeSubject) +\n  geom_point()\n\n\n\n\n\nIn der Mitte des Diagramms gibt es viele Überschneidungen.\n\nWie können wir die Deckkraft der Punkte ändern?\n\n\n\ndf_english |&gt; \n  ggplot() +\n  aes(x = WrittenFrequency, y = RTlexdec,\n      colour = AgeSubject,\n      shape = AgeSubject) +\n  geom_point(alpha = .5)\n\n\n\n\n\nden Zusammenhang zwischen Altersgruppe und Reaktionszeit beschreiben\n\n\n\n\n\n\n\nAufgabe 5.1: Adding another variable\n\n\n\n\nBeispiel 5.1  \n\nWie könnten Sie eine vierte Variable in die obige Darstellung einfügen? Versuchen Sie, CV hinzuzufügen. Ergibt die Darstellung immer noch eine klare Geschichte?\n\n\n\n\n\n\n5.2.4 Facet grids\n\nWenn Sie mehr als drei Variablen darstellen wollen, ist es im Allgemeinen eine gute Idee, kategorische Variablen in Facetten aufzuteilen.\n\nFacetten sind Teilplots, die Teilmengen der Daten anzeigen\n\nwir können facet_wrap() verwenden, das eine Formel als Argument annimmt\n\nDiese Formel enthält ~ und den Namen einer kategorialen Variable, z. B. ~CV\n\n\n\n\n\n\n## + geom_?\ndf_english |&gt; \n  ggplot() +\n  aes(x = WrittenFrequency, y = RTlexdec,\n      colour = AgeSubject,\n      shape = AgeSubject) +\n  facet_wrap(~CV) \n\n\n\n\n\n\n\n\ndf_english |&gt; \n  ggplot() +\n  aes(x = WrittenFrequency, y = RTlexdec,\n      colour = AgeSubject,\n      shape = AgeSubject) +\n  facet_wrap(~CV) +\n  geom_point(alpha = .5)"
  },
  {
    "objectID": "mats/05-dataviz_2.html#bearbeitete-daten",
    "href": "mats/05-dataviz_2.html#bearbeitete-daten",
    "title": "5  Datenvisualisierung 2",
    "section": "5.3 Bearbeitete Daten",
    "text": "5.3 Bearbeitete Daten\n\nWir können unsere Daten auch bearbeiten, bevor wir sie in ggplot() eingeben.\n\nDies ist nützlich, wenn wir keine permanenten Änderungen an den Daten vornehmen wollen, sondern nur eine Teilmenge der Daten darstellen wollen\n\nVielleicht wollen wir nur die Wörter betrachten, die mit einem Vokal beginnen. Wie könnten wir das mit einem dplyr-Verb machen?\n\n\n\n\ndf_english |&gt; \n  filter(CV == \"V\") |&gt; \n  ggplot() +\n  aes(x = WrittenFrequency, y = RTlexdec,\n      colour = AgeSubject,\n      shape = AgeSubject) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nAufgabe 5.2: Plot-Anmerkung\n\n\n\n\nBeispiel 5.2  \n\n\nVergessen Sie nicht, Ihre Diagramme mit nützlichen Beschriftungen zu versehen, um dem Leser die Interpretation des Diagramms zu erleichtern\nFügen wir einen Titel und Beschriftungen für die x- und y-Achse hinzu\n\n\ndf_english |&gt; \n  filter(CV == \"V\") |&gt; \n  ggplot() +\n  aes(x = WrittenFrequency, y = RTlexdec,\n      colour = AgeSubject,\n      shape = AgeSubject) +\n  labs(title = \"WrittenFrequency scores by reaction time\",\n       x = \"WrittenFrequency score\",\n       y = \"Reaction time (ms)\",\n       colour = \"Age group\",\n       shape = \"Age group\") +\n  geom_point()"
  },
  {
    "objectID": "mats/05-dataviz_2.html#quarto-code-chunk-einstellungen",
    "href": "mats/05-dataviz_2.html#quarto-code-chunk-einstellungen",
    "title": "5  Datenvisualisierung 2",
    "section": "5.4 Quarto Code Chunk Einstellungen",
    "text": "5.4 Quarto Code Chunk Einstellungen\n\nlange Codeabschnitte können zu sehr unübersichtlichen Ausgabedokumenten führen\nnormalerweise ist nur die Darstellung für den Leser wichtig, nicht der Code, der sie erzeugt hat\nwir können die Darstellung und Auswertung von Code Chunks durch Code Chunk Optionen steuern\n\ndiese beginnen mit #|\nund befinden sich direkt unter ```{r}```\n\n\n\nwichtige Code-Chunk-Optionen:\n\n\n\n\n\nTabelle 5.2: Most common chunk options\n\n\noption\nvalues\nfunction\n\n\n\n\n#| echo:\ntrue/false\nshould this code chunk be printed when rendering?\n\n\n#| eval:\ntrue/false\nshould this code chunk be run when rendering?\n\n\n\n\n\n\n\n\n\n5.4.1 Verwendung von Code-Bausteinen\n\nwarum sehen wir das Ergebnis dieser Darstellung nicht?\n\n\n```{r}\n#| eval: false\ndf_english |&gt; \n  ggplot() +\n  aes(x = RTlexdec, y = RTnaming,\n      colour = AgeSubject,\n      shape = AgeSubject) +\n  geom_point()\n```"
  },
  {
    "objectID": "mats/05-dataviz_2.html#plots-speichern",
    "href": "mats/05-dataviz_2.html#plots-speichern",
    "title": "5  Datenvisualisierung 2",
    "section": "5.5 Plots speichern",
    "text": "5.5 Plots speichern\n\noft wollen wir unsere Plots in einem Dokument verwenden, das nicht in RStudio erstellt wurde\n\nzum Beispiel in einer Dissertation oder einem in LaTeX geschriebenen Papier\n\num dies zu tun, müssen wir unsere Zahlen als einen akzeptierten Dateityp laden, wie jpeg oder png\nDas können wir mit der Funktion ggsave() machen.\nKönnen Sie erraten, welche Arten von Argumenten ggsave() benötigt, um unsere Diagramme zu speichern? Einige sind erforderlich, einige sind optional.\n\n\n5.5.1 ggsave()\nAls Minimum benötigt ggsave() Argumente:\n\nden Namen des Plots in Ihrer Umgebung, den Sie speichern möchten\nden Dateinamen, unter dem Sie Ihre Darstellung speichern möchten\n\nEs ist eine gute Idee, einen Ordner zu erstellen, in dem Sie Ihre Plots speichern, und den Dateipfad in den Namen aufzunehmen\n\n\n\n5.5.1.1 ggsave() optionale Argumente\n\neinige optionale Argumente sind:\n\nwidth = wie breit soll der Plot in cm, mm, Zoll oder Pixel sein?\nheight = wie hoch soll der gespeichert Plot in cm, mm, Zoll oder Pixel sein?\ndpi = gewünschte Auflösung (numerisch, oder eine Reihe von Strings: “retina” = 320, “print” = 300 oder “screen” = 72)\n\n\n\n\n\n\n\n\nWarnung\n\n\n\nSetzen Sie Code-Chunks, die Dateien auf Ihrem Rechner speichern, immer auf eval: false!!! Andernfalls wird jedes Mal, wenn Sie Ihr Skript ausführen, die Datei lokal neu geschrieben.\n\n\n\n\n\n\n\n\nAufgabe 5.3: ggsave()\n\n\n\n\nBeispiel 5.3  \n\n\nKopieren Sie den unten stehenden Code in einen Codechunk und führen Sie ihn aus. Schauen Sie sich Ihre “Files”-Tab an, was hat sich geändert?\n\n\n```{r}\n#| eval: false\nggsave(\n  ## required:\n  \"figures/04-dataviz2/fig_lexdec_rt.png\", \n  plot = fig_lexdec_rt,\n  ## optional:\n  width = 2000,\n  height = 1000,\n  units = \"px\",\n  scale = 1,\n  dpi = \"print\")\n```\n\n\nVersuchen Sie, mit dem Maßstab und den dpi zu spielen. Was ändert sich?\nVersuchen Sie, die Werte für Einheiten, Breite und Höhe zu ändern. Was ändert sich?"
  },
  {
    "objectID": "mats/05-dataviz_2.html#übungen",
    "href": "mats/05-dataviz_2.html#übungen",
    "title": "5  Datenvisualisierung 2",
    "section": "5.6 Übungen",
    "text": "5.6 Übungen\n\n\nZeichnen Sie abweichende Balkenplots von AgeSubject (x-Achse) nach CV (Facetten).\nÄndern Sie Ihre Code-Chunk-Optionen für den letzten Plot so, dass der Code, aber nicht der Plot, in der Ausgabe gedruckt wird.\n\n\nFiltern Sie die Daten, um nur ältere Teilnehmer einzuschließen, und stellen Sie RTlexdec (x-Achse) durch RTnaming (y-Achse) dar. Übertragen Sie CV auf Farbe und Form. Fügen Sie geeignete Beschriftungen hinzu.\nÄndern Sie die Code-Chunk-Optionen für den letzten Plot so, dass der Plot, aber nicht der Code, in der Ausgabe gedruckt wird.\n\nSpeichern Sie den letzten Plot lokal und stellen Sie den Code Chunk so ein, dass er beim Rendern nicht ausgeführt wird."
  },
  {
    "objectID": "mats/05-dataviz_2.html#session-info",
    "href": "mats/05-dataviz_2.html#session-info",
    "title": "5  Datenvisualisierung 2",
    "section": "Session Info",
    "text": "Session Info\nHergestellt mit R version 4.3.0 (2023-04-21) (Already Tomorrow) und RStudioversion 2023.9.0.463 (Desert Sunflower).\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] kableExtra_1.3.4 knitr_1.44       languageR_1.5.0  ggthemes_4.2.4  \n [5] patchwork_1.1.3  lubridate_1.9.2  forcats_1.0.0    stringr_1.5.0   \n [9] dplyr_1.1.3      purrr_1.0.2      readr_2.1.4      tidyr_1.3.0     \n[13] tibble_3.2.1     ggplot2_3.4.3    tidyverse_2.0.0 \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.3        generics_0.1.3    xml2_1.3.4        stringi_1.7.12   \n [5] hms_1.1.3         digest_0.6.33     magrittr_2.0.3    evaluate_0.21    \n [9] grid_4.3.0        timechange_0.2.0  fastmap_1.1.1     jsonlite_1.8.7   \n[13] httr_1.4.6        rvest_1.0.3       fansi_1.0.4       viridisLite_0.4.2\n[17] scales_1.2.1      cli_3.6.1         rlang_1.1.1       munsell_0.5.0    \n[21] withr_2.5.0       yaml_2.3.7        tools_4.3.0       tzdb_0.4.0       \n[25] colorspace_2.1-0  webshot_0.5.4     pacman_0.5.1      vctrs_0.6.3      \n[29] R6_2.5.1          lifecycle_1.0.3   htmlwidgets_1.6.2 pkgconfig_2.0.3  \n[33] pillar_1.9.0      gtable_0.3.4      glue_1.6.2        systemfonts_1.0.4\n[37] highr_0.10        xfun_0.39         tidyselect_1.2.0  rstudioapi_0.14  \n[41] farver_2.1.1      htmltools_0.5.5   labeling_0.4.3    rmarkdown_2.22   \n[45] svglite_2.1.1     compiler_4.3.0"
  },
  {
    "objectID": "mats/05-dataviz_2.html#literaturverzeichnis",
    "href": "mats/05-dataviz_2.html#literaturverzeichnis",
    "title": "5  Datenvisualisierung 2",
    "section": "Literaturverzeichnis",
    "text": "Literaturverzeichnis\n\n\nBaayen, R. H., & Shafaei-Bajestan, E. (2019). languageR: Analyzing Linguistic Data: A Practical Introduction to Statistics. https://CRAN.R-project.org/package=languageR\n\n\nNordmann, E., & DeBruine, L. (2022). Applied Data Skills. Zenodo. https://doi.org/10.5281/zenodo.6365078\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for Data Science (2. Aufl.)."
  },
  {
    "objectID": "mats/06-bericht_1.html#einrichtung",
    "href": "mats/06-bericht_1.html#einrichtung",
    "title": "6  Bericht 1",
    "section": "6.1 Einrichtung",
    "text": "6.1 Einrichtung\n\n6.1.1 Quarto\nÖffnen Sie ein neues Quarto-Skript und speichern Sie es als nachname_vorname_bericht1.qmd. Ändern Sie das YAML so, dass es einen:\n\neinen aussagekräftigen Titel\nIhren Namen als Autor\nein Inhaltsverzeichnis\n\nAchten Sie darauf, Code Chunks, Prosa und Überschriften zu verwenden, um Ihre Aufgaben angemessen zu dokumentieren. Eine gute Faustregel ist, für jede (Unter-)Überschrift in diesem Dokument eine Überschrift hinzuzufügen.\n\n\n6.1.2 Pakete\nLaden Sie die Pakete tidyverse und languageR ein.\n\n\n6.1.3 Daten\nDer Datensatz durationsGe aus dem languageR-Paket (Baayen & Shafaei-Bajestan, 2019) enthält Dauermessungen zur niederländischen Vorsilbe ge. Eine Beschreibung aller Variablen des Datensatzes findet sich in Tabelle 6.1. Ihre Aufgabe ist es:\n\nSpeichern Sie den Datensatz als Objekt df_ge in Ihrer Umgebung (dies kann auf die gleiche Weise geschehen wie bei allen Datensätzen, die wir bisher verwendet haben)\nDrucken Sie die ersten 10 Zeilen des Datensatzes mit der Funktion “head()” aus.\n\n\n\n\n\nTabelle 6.1: ‘Data dictionary’ für ‘durationsGe’ aus dem languageR-Paket\n\n\nVariable\nBeschreibung\n\n\n\n\nWord\nein Faktor mit den Wörtern als Ebenen\n\n\nFrequency\nein numerischer Vektor mit der absoluten Häufigkeit des Wortes im Spoken Dutch Corpus\n\n\nSpeaker\nein numerischer Vektor mit der absoluten Häufigkeit des Wortes im Spoken Dutch Corpus\n\n\nSex\nein Faktor mit den Lautsprechern als Ebenen\n\n\nYearOfBirth\nein numerischer Vektor mit Geburtsjahren\n\n\nDurationOfPrefix\nein numerischer Vektor mit der Dauer des Präfixes -ge in Sekunden.\n\n\nSpeechRate\nein numerischer Vektor, der die Sprechgeschwindigkeit in Anzahl der Silben pro Sekunde kodiert\n\n\nNumberSegmentsOnset\nein numerischer Vektor, der die Sprechgeschwindigkeit in Anzahl der Silben pro Sekunde kodiert"
  },
  {
    "objectID": "mats/06-bericht_1.html#sec-wrangle",
    "href": "mats/06-bericht_1.html#sec-wrangle",
    "title": "6  Bericht 1",
    "section": "6.2 Data wrangling",
    "text": "6.2 Data wrangling\nHier werden Sie die dplyr-Verben aus Woche 4 verwenden. Denken Sie daran, dass Sie den Zuweisungsoperator (&lt;-) nur verwenden müssen, wenn Sie die Änderungen, die Sie vornehmen, als Objekt in der Umgebung speichern wollen. Wenn Sie diese Änderungen nur ausdrucken wollen, brauchen Sie den Zuweisungsoperator nicht.\n\n6.2.1 Subsetting\nDrucken (aber nicht in Ihrer Umgebung speichern) Sie die Zeilen von df_ge, in denen SpeechRate über 9 liegt, nur mit den Spalten word, speaker und SpeechRate. Es sollten 5 Zeilen sein.\n\n\n6.2.2 mutate()\nFügen Sie eine neue Variable hinzu, duration_ms, die DauerVonPräfix multipliziert mit 1000 (DurationOfPrefix*1000) entspricht. Dies entspricht der Dauer von ge in Millisekunden, statt in Sekunden. Stellen Sie sicher, dass Sie diese neue Variable in Ihrem Datenrahmen speichern (Hinweis: Sie müssen den Zuweisungsoperator &lt;- und das dplyr-Verb mutate() verwenden).\n\n\n6.2.3 Fehlersuche\nWarum läuft dieser Code nicht? Es gibt zwei Probleme mit dem Code, identifizieren und beheben Sie sie.\n\n## Troubleshooting\ndf_ge  |&gt; \n  filter(YearOfBirth == 1978) +\n  select(Frequency, word)"
  },
  {
    "objectID": "mats/06-bericht_1.html#sec-dataviz",
    "href": "mats/06-bericht_1.html#sec-dataviz",
    "title": "6  Bericht 1",
    "section": "6.3 Datenvisualisierung",
    "text": "6.3 Datenvisualisierung\nVerwenden Sie für alle Diagramme labs(title = \"...\"), um entsprechende Diagrammtitel hinzuzufügen.\nOptional: Ändern Sie die x und y Achsenbeschriftungen, wenn Sie wollen, mit labs(x = \"...\", y = \"...\"). Vielleicht möchten Sie auch ein Thema hinzufügen (z.B. theme_minimal()).\n\n6.3.1 Scatterplot\nErstellen Sie ein Streudiagramm mit SpeechRate (x-Achse) und DurationOfPrefix (y-Achse), mit YearOfBirth als Farbe (colour). Ändern Sie die Einstellungen für den Codechunk so, dass das Diagramm beim Rendern des Skripts nicht gedruckt wird, der Code aber schon. Tipp: Sie müssen #| eval: verwenden.\n\n\n6.3.2 Facetten\nFügen Sie Facetten für Sex hinzu (denken Sie daran, die Tilde ~ einzufügen). Ändern Sie die Code-Chunk-Einstellungen so, dass die Darstellung gedruckt wird, wenn das Skript gerendert wird, aber der Code nicht (Sie benötigen echo anstelle von eval).\n\n\n6.3.3 Reproduzieren eines Plots\nReproduzieren Sie die Abbildung 6.1 (es muss keine exakte Kopie sein, aber kommen Sie ihr so nahe wie möglich). Stellen Sie sicher, dass sowohl der Code als auch die Darstellung beim Rendern gedruckt werden. Hinweis: Sie müssen filter() sowohl für Frequency als auch für Sex verwenden. Ich würde mich darauf konzentrieren, zuerst das Diagramm zu erstellen und dann zu versuchen, die Daten zu filtern.\n\n\n\n\n\nAbbildung 6.1: Eine zu reproduzierende Figur"
  },
  {
    "objectID": "mats/06-bericht_1.html#sec-interpret",
    "href": "mats/06-bericht_1.html#sec-interpret",
    "title": "6  Bericht 1",
    "section": "6.4 Interpretation",
    "text": "6.4 Interpretation\nBeschreiben Sie die Beziehung zwischen den beiden Variablen, die Sie in Abbildung 6.1 sehen.\n\n\n\n\nBaayen, R. H., & Shafaei-Bajestan, E. (2019). languageR: Analyzing Linguistic Data: A Practical Introduction to Statistics. https://CRAN.R-project.org/package=languageR"
  },
  {
    "objectID": "mats/07-dateneinlesung.html#lernziele",
    "href": "mats/07-dateneinlesung.html#lernziele",
    "title": "7  Einlesen von Daten",
    "section": "Lernziele",
    "text": "Lernziele\nIn diesem Kapitel werden wir lernen, wie man:\n\nlokale Datendateien mit dem Paket readr zu importieren\nmit fehlenden Werten umzugehen\nVariablen in Faktoren umwandeln\n\n\nLesungen\nDie Pflichtlektüre zur Vorbereitung auf dieses Thema ist Kap. 8 (Data Import) in Wickham et al. (2023).\nEine ergänzende Lektüre ist Ch. 4 (Data Import) in Nordmann & DeBruine (2022)."
  },
  {
    "objectID": "mats/07-dateneinlesung.html#wiederholung",
    "href": "mats/07-dateneinlesung.html#wiederholung",
    "title": "7  Einlesen von Daten",
    "section": "Wiederholung",
    "text": "Wiederholung\nIm letzten Kapitel haben wir das Gelernte in die Praxis umgesetzt. Wir haben einen Datensatz aus dem languageR-Paket (Baayen & Shafaei-Bajestan, 2019) eingelesen, ihn mit dem dplyr-Paket aus dem tidyverse verarbeitet und mehrere Diagramme mit dem ggplot2-Paket aus dem tidyverse erstellt. All dies wurde mit einem Quarto-Skript durchgeführt."
  },
  {
    "objectID": "mats/07-dateneinlesung.html#einrichtung",
    "href": "mats/07-dateneinlesung.html#einrichtung",
    "title": "7  Einlesen von Daten",
    "section": "7.1 Einrichtung",
    "text": "7.1 Einrichtung\n\n7.1.1 Pakete mit pacman\nZu Beginn werden wir mit dem Paket pacman beginnen. Die Funktion p_load() nimmt Paketnamen als Argumente und prüft dann, ob Sie das Paket installiert haben. Wenn ja, dann lädt sie das Paket (genau wie library()). Wenn Sie das Paket nicht installiert haben, wird das Paket installiert und geladen (wie mit install.packages(), library()). Das erspart uns, neue Pakete einzeln zu installieren, und bedeutet auch, dass, wenn wir unser Skript mit anderen teilen, sie einfach pacman::p_load() ausführen können.\n\n## install new packages IN THE CONSOLE!\ninstall.packages(\"pacman\")\n\n\n## load packages\npacman::p_load(tidyverse, ## wrangling\n               janitor, ## wrangling\n               here ## relative file paths\n               )\n\nWir haben nun tidyverse geladen, und die neuen Pakete janitor und here installiert und geladen. Um mehr über diese Pakete herauszufinden, versuchen Sie ?janitor und ?here in der Konsole einzugeben.\n\n\n7.1.2 RProjects\nBevor wir mit unserer ersten Datei beginnen, müssen wir sicherstellen, dass wir innerhalb unseres RProjekts arbeiten. Zu Beginn des Kurses haben Sie eine ZIP-Datei von GitHub (https://github.com/daniela-palleschi/r4ling_student) heruntergeladen, die einige Ordner und eine .RProj-Datei enthielt. Hoffentlich haben Sie bis jetzt innerhalb dieses RProjekts gearbeitet und Ihre Skripte im Ordner notizen gespeichert. Von nun an wird es notwendig sein, innerhalb dieses RProjekts zu arbeiten, damit wir immer auf unsere relevanten Datendateien zugreifen können, die in einem Ordner namens daten gespeichert werden sollten.\nUm ein RProjekt zu öffnen, navigieren Sie einfach zu dem Ordner auf Ihrem Rechner und doppelklicken Sie auf die .RProj-Datei. Wenn Sie sich bereits in RStudio befinden, können Sie auch überprüfen, ob Sie im richtigen RProjekt arbeiten, indem Sie oben im Fenster nachsehen.\n\n\n\n\n\n\nAufgabe\n\n\n\n\nÜberprüfen Sie, ob Sie tatsächlich in Ihrem RProjekt arbeiten. Wenn dies der Fall ist, sehen Sie r4ling_student-main oben in Ihrem RStudio (Abbildung 7.1).\n\n\nWenn dies nicht der Fall ist (Abbildung 7.2), können Sie zum RProjekt wechseln, indem Sie auf die Schaltfläche “Projekt” oben rechts im RStudio klicken (Abbildung 7.3; Hinweis: Die Screenshots stammen von einem Mac, auf einem Windows-Rechner sieht es etwas anders aus).\n\n\nFügen Sie Ihrem RProject-Ordner einen Ordner namens daten hinzu.\n\n\n\n\n\n\nAbbildung 7.1: RStudio will display the RProject name if you are working in an RProject (here: r4ling_student-main).\n\n\n\n\n\n\n\n\n\nAbbildung 7.2: RStudio will display the RProject name if you are working in an RProject.\n\n\n\n\n\n\n\n\n\nAbbildung 7.3: RStudio will say ‘RStudio’ and ‘Project (none)’ if you are not working in an RProject."
  },
  {
    "objectID": "mats/07-dateneinlesung.html#csv-komma-getrennter-wert",
    "href": "mats/07-dateneinlesung.html#csv-komma-getrennter-wert",
    "title": "7  Einlesen von Daten",
    "section": "7.2 CSV: Komma getrennter Wert",
    "text": "7.2 CSV: Komma getrennter Wert\nBisher haben wir mit Daten aus dem R-Paket languageR gearbeitet. Daten aus Paketen sind eine großartige Möglichkeit, die Werkzeuge der Datenwissenschaft zu erlernen, aber normalerweise wollen wir mit unseren eigenen Daten arbeiten, nicht mit eingebauten Spielzeugdaten. Wir werden uns nur auf rechteckige Daten (d. h. aufgeräumte Daten) konzentrieren, obwohl Ihre Daten zu Beginn oft nicht aufgeräumt sind. Es gibt viele verschiedene Dateitypen, die Daten annehmen können, z. B. .xlsx, .txt, .csv, .tsv. Der Dateityp “csv” ist der häufigste Dateityp und steht für: Comma Separated Values.\nSo sieht eine einfache CSV-Datei aus:\n\n\nStudent ID,Full Name,favourite.food,mealPlan,AGE\n1,Sunil Huffmann,Strawberry yoghurt,Lunch only,4\n2,Barclay Lynn,French fries,Lunch only,5\n3,Jayendra Lyne,N/A,Breakfast and lunch,7\n4,Leon Rossini,Anchovies,Lunch only,\n5,Chidiegwu Dunkel,Pizza,Breakfast and lunch,five\n6,Güvenç Attila,Ice cream,Lunch only,6\n\n\nDie erste Zeile (die “Kopfzeile”) enthält die Spaltennamen. Die folgenden Zeilen enthalten die Daten. Wie viele Variablen gibt es? Wie viele Beobachtungen?\nWir lernen jetzt etwas über aufgeräumte Daten und sehen uns ein Beispiel an. Anschließend werden wir eine CSV-Datei in R laden.\n\n\n\n\n\n\nMicrosoft Excel\n\n\n\nVersuchen Sie, .xlsx-Dateien im Allgemeinen zu vermeiden, vor allem aber, wenn Sie Ihre Daten in R laden wollen. Der Grund dafür ist, dass Excel viele Formatierungsprobleme hat, die für R problematisch sind. Wenn Sie einen Excel-Datensatz haben, versuchen Sie, ihn als .csv zu speichern, bevor Sie ihn in R einlesen (Datei &gt; Speichern unter &gt; Dateiformat &gt; Komma-getrennter Wert).\n\n\n\n7.2.1 Tidydaten\nUnabhängig davon, in welchem Format Ihre Daten vorliegen, sollten sie aufgeräumt sein. Das bedeutet erstens, dass die Daten rechteckig sein sollten und dass jede Spalte eine Variable, jede Zeile eine Beobachtung und jede Zelle einen Datenpunkt darstellt (Abbildung 7.4).\n\n\n\n\n\nAbbildung 7.4: Source: Wickham et al. (2023) (all rights reserved)"
  },
  {
    "objectID": "mats/07-dateneinlesung.html#tabelle-zu-csv",
    "href": "mats/07-dateneinlesung.html#tabelle-zu-csv",
    "title": "7  Einlesen von Daten",
    "section": "7.3 Tabelle zu csv",
    "text": "7.3 Tabelle zu csv\nLassen Sie uns einige Spielzeugdaten in einem Arbeitsblatt sammeln, das wir dann als CSV-Datei speichern und in R laden werden. Klicken Sie hier, um zu einem bearbeitbaren Arbeitsblatt zu gelangen. Geben Sie die relevanten Informationen über sich selbst ein, oder erfinden Sie einige Daten: den Namen eines Haustiers, das Sie haben/hatten, Größe, Geburtsmonat und -tag sowie Ihre erste Sprache. Wenn Sie kein Haustier haben, lassen Sie die Zelle leer.\n\n\n\n\n\nOur spreadsheet\n\n\n\n\n\n7.3.1 CSV speichern\nJetzt müssen wir unser Arbeitsblatt als CSV-Datei auf unserem Computer speichern. Solange wir in unserem RProjekt arbeiten, wird R immer nach Dateien aus dem Ordner suchen, der unser RProjekt enthält. Stellen wir also zunächst sicher, dass unser Ordner einen Unterordner namens daten enthält. Darin werden wir alle unsere Daten speichern.\n\n\n\n\n\n\nAufgabe 7.1: Speichern einer CSV\n\n\n\n\nBeispiel 7.1  \n\n\nErstellen Sie einen neuen Ordner mit dem Namen daten in Ihrem Projektordner (falls Sie das nicht schon getan haben).\nLaden Sie das Google Sheet herunter und speichern Sie es in Ihrem daten-Ordner als groesse_geburtstag.csv.\nGehen Sie zu Ihrem daten-Ordner und überprüfen Sie, ob die CSV-Datei dort ist.\n\n\n\n\n\n\nDownload a Google Sheet as a CSV.\n\n\n\n\n\n\n\n\n\nFind the CSV file in your file manager."
  },
  {
    "objectID": "mats/07-dateneinlesung.html#das-readr-paket",
    "href": "mats/07-dateneinlesung.html#das-readr-paket",
    "title": "7  Einlesen von Daten",
    "section": "7.4 Das readr-Paket",
    "text": "7.4 Das readr-Paket\nUnsere Daten können als Tabelle angezeigt werden, genau wie unsere eingebauten Datensätze aus dem languageR-Paket (Baayen & Shafaei-Bajestan, 2019). Genau wie bei den eingebauten Datensätzen müssen wir zuerst die Daten einlesen, aber anstatt nur den Namen des eingebauten Datensatzes anzugeben, müssen wir eine Funktion verwenden, die CSV-Daten liest. Wir müssen auch angeben, wo sich die Daten in unserem RProject-Ordner befinden.\nDas Paket readr (Teil von tidyverse) kann die meisten Datentypen einlesen und hat mehrere Funktionen für verschiedene Datentypen.\n\nread_csv(here::here(\"daten\", \"groesse_geburtstag.csv\"))\n\n\n\n\n\nTabelle 7.1: Data from the students.csv file as a table.\n\n\nHaustier\nGröße\nMonat der Geburt\nTag\nL1\n\n\n\n\nLola\n171\n5\n7\nEnglisch\n\n\nNA\n168\n11\n26\nDeutsch\n\n\nN/A\n182\n4\n15\nDeutsch\n\n\n\n\n\n\n\n\n\n\n\n\nAufgabe 7.2: df_groesse\n\n\n\n\nBeispiel 7.2  \n\n\nImportieren Sie den Datensatz “groesse_geburtstag.csv” und speichern Sie ihn als Objekt mit dem Namen “df_groesse”.\n\ndf_ ist die Abkürzung für DataFrame; es ist eine gute Idee, ein Präfix vor Objektnamen zu verwenden, damit wir wissen, was jedes Objekt enthält.\n\nWenn Daten mit read_csv importiert werden, werden einige Informationen in der Konsole ausgegeben. Was wird gedruckt?\nUntersuche den Datensatz mit Funktionen wie summary() oder head()\nSehen Sie etwas Ungewöhnliches?"
  },
  {
    "objectID": "mats/07-dateneinlesung.html#das-here-paket",
    "href": "mats/07-dateneinlesung.html#das-here-paket",
    "title": "7  Einlesen von Daten",
    "section": "7.5 Das here-Paket",
    "text": "7.5 Das here-Paket\nAber woher weiß R genau, wo der Ordner daten zu finden ist? Unser Arbeitsverzeichnis ist auf den Ort unseres RProjekts auf unserem Computer festgelegt. Wann immer wir auf Daten in unserem RProjekt zugreifen wollen, sollten wir here() verwenden (vorausgesetzt, wir haben das here-Paket bereits geladen). Um zu sehen, von wo aus here() startet, führen Sie here() aus. Wie sieht die Ausgabe im Vergleich zu der von getwd() (für ‘get working directory’)?\n\nhere()\n\n[1] \"/Users/danielapalleschi/Documents/IdSL/Teaching/WiSe2324/B.A./r4ling\"\n\ngetwd()\n\n[1] \"/Users/danielapalleschi/Documents/IdSL/Teaching/WiSe2324/B.A./r4ling/mats\"\n\n\nDie Ausgabe wird auf allen unseren Rechnern anders aussehen, aber was gleich sein sollte, ist unsere Ordnerstruktur innerhalb unserer Projekte (z. B. data/groesse_geburtstag.csv).\n\n\n\n\n\nImage source: Allison Horst (all rights reserved)\n\n\n\n\n\n\n\n\n\n\nhere-Paket\n\n\n\n\nVor dem here-Paket mussten wir R explizit mitteilen, wo sich eine Datei auf unserem Computer befindet (z.B., /Users/danielapalleschi/Documents/IdSL/Teaching/SoSe23/BA/ba_daten/daten/students.csv), oder die Funktion setwd() (set Working Directory) benutzen, um R mitzuteilen, wo alle Dateien zu finden sind (z.B. setwd(\"/Users/danielapalleschi/Documents/IdSL/Teaching/SoSe23/BA/ba_daten\")). Glücklicherweise brauchen Sie diese absoluten Dateipfade oder setwd() nie zu benutzen!\nAus der hier-Paketdokumentation:\n\nThe goal of the here package is to enable easy file referencing in project-oriented workflows. In contrast to using setwd(), which is fragile and dependent on the way you organize your files, here uses the top-level directory of a project to easily build paths to files.\n\nDas bedeutet, dass wir nun den großen Vorteil haben, dass wir unseren Projektordner überall hin verschieben können und unser Dateipfad immer noch relativ zu dem Ort ist, an den wir unseren Projektordner verschoben haben. Das bedeutet, dass das Projekt unabhängig davon läuft, wo es sich auf Ihrem Computer befindet. Sie können auch jemandem den Projektordner schicken, und alles sollte auf dessen Rechner laufen!"
  },
  {
    "objectID": "mats/07-dateneinlesung.html#arbeit-mit-daten",
    "href": "mats/07-dateneinlesung.html#arbeit-mit-daten",
    "title": "7  Einlesen von Daten",
    "section": "7.6 Arbeit mit Daten",
    "text": "7.6 Arbeit mit Daten\nDaten sind chaotisch, aber mit Erfahrung können wir lernen, sie zu bändigen. Im Folgenden finden Sie einige Tipps, die das Gelernte über die Datenverarbeitung erweitern.\n\n7.6.1 Fehlende Werte\nBei der Datentransformation geht es darum, unsere Daten zu “reparieren”, wenn sie nicht “in Ordnung” sind. In unserem df_groesse Datenrahmen haben Sie vielleicht einige NA oder N/A Werte bemerkt. N/A” wurde in einer unserer Beobachtungen als Text geschrieben und wird von R als solcher gelesen. N/A” in R bezieht sich auf fehlende Daten (“Nicht verfügbar”). Echte fehlende Werte sind komplett leer, so dass N/A in unseren df_groesse-Daten nicht wirklich als fehlender Wert gelesen wird, obwohl wir möchten, dass R weiß, dass dies als fehlende Daten zählt und nicht das Haustier von jemandem namens “NA” (Menschen tun seltsame Dinge!). Um dies zu beheben, können wir das Argument na = für die Funktion read_csv() verwenden, das der Funktion read_csv() mitteilt, welche Werte sie mit fehlenden Werten gleichsetzen soll.\n\n# force \"N/A\" to missing values\ndf_groesse &lt;- read_csv(here::here(\"daten\", \"groesse_geburtstag.csv\"),\n                        na = \"N/A\")\n# print the head of the data set\nhead(df_groesse)\n\n# A tibble: 3 × 5\n  Haustier Größe `Monat der Geburt`   Tag L1      \n  &lt;chr&gt;    &lt;dbl&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n1 \"Lola\"     171                  5     7 Englisch\n2 \"\"         168                 11    26 Deutsch \n3  &lt;NA&gt;      182                  4    15 Deutsch \n\n\nJetzt wird der Wert, der vorher \"\" war, als NA gelesen. Aber was ist mit der leeren Zelle? Wir haben jetzt überschrieben, dass read_csv() leere Zellen als NA liest. Jetzt wollen wir read_csv() anweisen, mehr als eine Art von Eingabe als NA zu lesen, d.h. wir wollen es anweisen, \"\" und \"N/A\" als NA zu lesen. Dafür verwenden wir unsere immer nützliche Verkettungsfunktion: c().\n\n# force \"N/A\" and empty cells to missing values\ndf_groesse &lt;- read_csv(here::here(\"daten\", \"groesse_geburtstag.csv\"),\n                        na = c(\"N/A\",\"\"))\n# print the head of the data set\nhead(df_groesse)\n\n# A tibble: 3 × 5\n  Haustier Größe `Monat der Geburt`   Tag L1      \n  &lt;chr&gt;    &lt;dbl&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n1 Lola       171                  5     7 Englisch\n2 &lt;NA&gt;       168                 11    26 Deutsch \n3 &lt;NA&gt;       182                  4    15 Deutsch \n\n\n\n\n7.6.2 Spaltennamen\nWenn wir df_groesse in der Konsole ausdrucken, werden wir sehen, dass ein Spaltenname von Backticks umgeben ist (z.B. `Monat der Geburt). Das liegt daran, dass er ein Leerzeichen enthält, das syntaktisch nicht gültig ist (Variablennamen müssen mit einem Buchstaben beginnen und dürfen keine Leerzeichen oder Sonderzeichen enthalten). Eine schnelle Lösung ist die Funktion clean_names() aus dem Paket janitor, das wir bereits geladen haben.\n\nclean_names(df_groesse)\n\n# A tibble: 3 × 5\n  haustier grosse monat_der_geburt   tag l1      \n  &lt;chr&gt;     &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n1 Lola        171                5     7 Englisch\n2 &lt;NA&gt;        168               11    26 Deutsch \n3 &lt;NA&gt;        182                4    15 Deutsch \n\n\nDas sieht besser aus! Aber wenn Sie jetzt head(df_groesse) ausführen, sehen Sie dann die bereinigten Spaltennamen?\nDas sollten Sie nicht, denn wenn wir ein Objekt durch eine Funktion übergeben, wird das Objekt nicht ‘aktualisiert’, so dass wir das Objekt erneut mit dem Zuweisungsoperator &lt;- zuweisen müssen.\n\ndf_groesse &lt;- janitor::clean_names(df_groesse)\n\nAber wir wissen oft, dass wir mehrere Funktionen (read_csv(), clean_names()) auf demselben Objekt ausführen wollen, denken Sie daran, dass wir das mit Pipes tun können.\n\n\n7.6.3 Pipes\nPipes werden am Ende eines Funktionsaufrufs eingefügt, wenn das Ergebnis dieser Funktion durch eine nachfolgende Funktion weitergegeben werden soll. Pipes können als “und dann…” gelesen werden.\n\nread_csv(here::here(\"daten\", \"groesse_geburtstag.csv\")) |&gt;\n  head()\n\n# A tibble: 3 × 5\n  Haustier Größe `Monat der Geburt`   Tag L1      \n  &lt;chr&gt;    &lt;dbl&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n1 Lola       171                  5     7 Englisch\n2 &lt;NA&gt;       168                 11    26 Deutsch \n3 N/A        182                  4    15 Deutsch \n\n\nDerzeit gibt es 2 Pipes, die in R verwendet werden können.\n\ndie magrittr Paket-Pipe: %&gt;%\ndie neue native R-Pipe: |&gt;\n\nEs gibt keine großen Unterschiede, die für unsere aktuellen Anwendungen wichtig sind, also benutzen wir die neue |&gt;. Sie können die Tastenkombination Cmd/Ctrl + Shift/Strg + M verwenden, um eine Pipe zu erzeugen. Dies könnte die “Magrittr”-Paket-Pipe erzeugen, was in Ordnung ist, aber wenn Sie das ändern möchten, können Sie das unter Werkzeuge &gt; Globale Optionen &gt; Code &gt; Native Pipe-Operator verwenden tun.\n\n\n\n\n\n\nAufgabe 7.3: pipes\n\n\n\n\nBeispiel 7.3  \n\n\nLaden Sie den Datensatz groesse_geburtstag.csv erneut mit festen NAs und dann\n\nBenutze eine Pipe, um clean_names() auf dem Datensatz aufzurufen, und dann\nrufen Sie die Funktion “head()” auf\nÜberprüfen Sie die Anzahl der Beobachtungen und Variablen, gibt es ein Problem?\n\nLaden Sie den Datensatz groesse_geburtstag.csv erneut mit festen NAs, speichern Sie ihn als Objekt df_groesse, und dann\n\nVerwenden Sie eine Pipe, um clean_names() auf den Datensatz anzuwenden.\n\nWarum sollte man nicht eine Pipe und die Funktion head() verwenden, wenn man den Datensatz als Objekt speichert?\n\n\n\n\n\n\n\n7.6.4 Variablentypen\nDas Paket readr errät den Typ der Daten, die jede Spalte enthält. Die wichtigsten Spaltentypen, die man kennen muss, sind numerisch und Faktor (kategorisch). Faktoren enthalten Kategorien oder Gruppen von Daten, können aber manchmal aussehen wie numerische Daten. Zum Beispiel enthält unsere Spalte “Monat” Zahlen, aber sie könnte auch den Namen jedes Monats enthalten. Ein guter Weg, um zu wissen, was was ist: Es ist sinnvoll, den Mittelwert einer “numerischen” Variablen zu berechnen, aber nicht den eines “Faktors”. Zum Beispiel ist es sinnvoll, den Mittelwert der Körpergröße zu berechnen, aber nicht den Mittelwert des Geburtsmonats.\nUm sicherzustellen, dass eine Variable als Faktor gespeichert wird, können wir die Funktion as_factor() verwenden. Wir können entweder die R-Basissyntax verwenden, um dies zu tun, indem wir ein $ verwenden, um eine Spalte in einem Datenrahmen zu indizieren:\n\ndf_groesse$monat_der_geburt &lt;- as_factor(df_groesse$monat_der_geburt)\n\nOr we can use tidyverse syntax and the mutate() function.\n\ndf_groesse &lt;-\n  df_groesse |&gt; \n  mutate(monat_der_geburt = as_factor(monat_der_geburt))"
  },
  {
    "objectID": "mats/07-dateneinlesung.html#andere-dateitypen-und-begrenzungszeichen",
    "href": "mats/07-dateneinlesung.html#andere-dateitypen-und-begrenzungszeichen",
    "title": "7  Einlesen von Daten",
    "section": "7.7 Andere Dateitypen und Begrenzungszeichen",
    "text": "7.7 Andere Dateitypen und Begrenzungszeichen\nSobald Sie mit read_csv() vertraut sind, sind die anderen Funktionen von readr einfach zu benutzen, Sie müssen nur wissen, wann Sie welche benutzen.\nDie Funktion read_csv2() liest Semikolon-separierte Dateien. Diese verwenden Semikolons (;) anstelle von Kommas (,), um Felder zu trennen und sind in Ländern üblich, die , als Dezimaltrennzeichen verwenden (wie Deutschland).\nDie Funktion read_tsv() liest Tabulator-getrennte Dateien. Die Funktion read_delim() liest Dateien mit beliebigen Trennzeichen ein und versucht, das Trennzeichen zu erraten, es sei denn, Sie geben es mit dem Argument delim = an (z.B. read_delim(students.csv, delim = \",\")).\nreadr hat mehrere andere Funktionen, die ich persönlich noch nicht gebraucht habe, wie zum Beispiel:\n\nread_fwf() liest Dateien mit fester Breite\nread_table() liest eine gängige Variante von Dateien mit fester Breite, bei der die Spalten durch Leerzeichen getrennt sind\nread_log() liest Log-Dateien im Apache-Stil"
  },
  {
    "objectID": "mats/07-dateneinlesung.html#übungen",
    "href": "mats/07-dateneinlesung.html#übungen",
    "title": "7  Einlesen von Daten",
    "section": "7.8 Übungen",
    "text": "7.8 Übungen\nNun wollen wir üben, das Paket readr zu benutzen und mit unseren Daten zu arbeiten.\n\nreadr Funktionen\n\nWelche Funktion würdest du benutzen, um eine Datei zu lesen, in der die Felder mit “|” getrennt sind?\nWelche Argumente haben read_csv() und read_tsv() gemeinsam?\nWelche Funktion(en) könnten Sie verwenden, um einen Datensatz mit einem Semikolon (;) als Trennzeichen einzulesen?\n\n\n\nData wrangling\nLaden Sie die Datei groesse_geburtstag.csv erneut. Benutzen Sie Pipes, um auch die Funktion clean_names zu benutzen, und um die folgenden Änderungen im Objekt df_groesse vorzunehmen.\n\nUmwandlung der Variablen l1 in einen Faktor.\nUmbenennen von\n\n\ngrosse in groesse\nmonat_der_geburt in geburtsmonat\n\n\n\nPlots\nErstelle ein Streudiagramm mit unserem df_groesse-Datensatz, das die Beziehung zwischen unserem Geburtsdatum und unseren Geburtstagen visualisiert (es macht keinen Sinn, dies zu vergleichen, aber es ist nur eine Übung). Suchen Sie Ihren Geburtstag in der Grafik. Stellen Sie die Farbe und die Form so ein, dass sie “L1” entsprechen. Fügen Sie einen Titel für die Grafik hinzu."
  },
  {
    "objectID": "mats/07-dateneinlesung.html#lernziele-1",
    "href": "mats/07-dateneinlesung.html#lernziele-1",
    "title": "7  Einlesen von Daten",
    "section": "Lernziele 🏁",
    "text": "Lernziele 🏁\nHeute haben wir gelernt, wie man…\n\nlokale Datendateien mit dem Paket readr importiert ✅\nfehlende Werte behandeln ✅\nVariablen in Faktoren umwandeln ✅\n\nLassen Sie uns nun dieses neue Wissen anwenden."
  },
  {
    "objectID": "mats/07-dateneinlesung.html#session-info",
    "href": "mats/07-dateneinlesung.html#session-info",
    "title": "7  Einlesen von Daten",
    "section": "Session Info",
    "text": "Session Info\nHergestellt mit R version 4.3.0 (2023-04-21) (Already Tomorrow) und RStudioversion 2023.9.0.463 (Desert Sunflower).\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] magick_2.7.4    here_1.0.1      janitor_2.2.0   lubridate_1.9.2\n [5] forcats_1.0.0   stringr_1.5.0   dplyr_1.1.3     purrr_1.0.2    \n [9] readr_2.1.4     tidyr_1.3.0     tibble_3.2.1    ggplot2_3.4.3  \n[13] tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.3        generics_0.1.3    stringi_1.7.12    hms_1.1.3        \n [5] digest_0.6.33     magrittr_2.0.3    evaluate_0.21     grid_4.3.0       \n [9] timechange_0.2.0  fastmap_1.1.1     rprojroot_2.0.3   jsonlite_1.8.7   \n[13] fansi_1.0.4       scales_1.2.1      cli_3.6.1         crayon_1.5.2     \n[17] rlang_1.1.1       bit64_4.0.5       munsell_0.5.0     withr_2.5.0      \n[21] yaml_2.3.7        parallel_4.3.0    tools_4.3.0       tzdb_0.4.0       \n[25] colorspace_2.1-0  pacman_0.5.1      vctrs_0.6.3       R6_2.5.1         \n[29] lifecycle_1.0.3   snakecase_0.11.0  htmlwidgets_1.6.2 bit_4.0.5        \n[33] vroom_1.6.3       pkgconfig_2.0.3   pillar_1.9.0      gtable_0.3.4     \n[37] glue_1.6.2        Rcpp_1.0.11       xfun_0.39         tidyselect_1.2.0 \n[41] rstudioapi_0.14   knitr_1.44        htmltools_0.5.5   rmarkdown_2.22   \n[45] compiler_4.3.0"
  },
  {
    "objectID": "mats/07-dateneinlesung.html#literaturverzeichnis",
    "href": "mats/07-dateneinlesung.html#literaturverzeichnis",
    "title": "7  Einlesen von Daten",
    "section": "Literaturverzeichnis",
    "text": "Literaturverzeichnis\n\n\nBaayen, R. H., & Shafaei-Bajestan, E. (2019). languageR: Analyzing Linguistic Data: A Practical Introduction to Statistics. https://CRAN.R-project.org/package=languageR\n\n\nNordmann, E., & DeBruine, L. (2022). Applied Data Skills. Zenodo. https://doi.org/10.5281/zenodo.6365078\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for Data Science (2. Aufl.)."
  },
  {
    "objectID": "mats/08-desc_stats.html#lernziele",
    "href": "mats/08-desc_stats.html#lernziele",
    "title": "8  Deskriptive Statistik",
    "section": "Lernziele",
    "text": "Lernziele\nIn diesem Kapitel werden wir lernen…\n\nüber Maße der zentralen Tendenz (Mittelwert, Median, Modus)\nüber Streuungsmaße (Bereich, Standardabweichung)\nwie man die Funktion summarise() von dplyr benutzt\nwie man Zusammenfassungen .by Gruppe erstellt"
  },
  {
    "objectID": "mats/08-desc_stats.html#lesungen",
    "href": "mats/08-desc_stats.html#lesungen",
    "title": "8  Deskriptive Statistik",
    "section": "Lesungen",
    "text": "Lesungen\nDie Pflichtlektüre zur Vorbereitungen auf dieses Thema sind\n\nKap. 3, Abschnitt 3.4-3.9 (Descriptive statistics, models, and distributions) in Winter (2019) (online verfügbar über das HU Grimm Zentrum.\nBereich 4.5 (Groups) in Kapital 4 (Data Transformation) in Wickham et al. (2023)."
  },
  {
    "objectID": "mats/08-desc_stats.html#einrichten",
    "href": "mats/08-desc_stats.html#einrichten",
    "title": "8  Deskriptive Statistik",
    "section": "8.1 Einrichten",
    "text": "8.1 Einrichten\n\n8.1.1 Umgebung löschen\nEin wichtiger Schritt, über den wir noch nicht viel gesprochen haben, ist sicherzustellen, dass Sie ein neues Skript immer mit einer leeren R-Umgebung starten. Das bedeutet, dass wir keine Objekte in der Umgebung gespeichert haben sollten, aber auch keine Pakete geladen haben sollten. Wir wollen nämlich sicherstellen, dass alles, was wir tun, ausschließlich in diesem Skript ausgeführt wird und nicht von einem Paket oder Daten abhängt, die wir aus einem anderen Skript geladen haben. Um dies zu erreichen, können Sie auf Sitzung &gt; R neu starten klicken, um mit einer neuen Umgebung zu beginnen, oder die Tastenkombination Cmd/Strg+Strg+0 verwenden.\n\n\n8.1.2 Pakete\nWir müssen die Pakete tidyverse, here und janitor laden. Die letzten beiden brauchen wir, weil wir lokale CSV-Datensätze laden werden.\n\npacman::p_load(tidyverse,\n               here,\n               janitor)\n\n\n\n8.1.3 Daten laden\nWir werden heute zwei Datensätze verwenden: eine leicht veränderte Version des groesse_geburtstag-Datensatzes aus dem letzten Abschnitt (groesse_geburtstag_ws2324.csv) und languageR_english.csv, das eine kürzere Version des english-Datensatzes aus dem languageR-Paket ist. Wenn Sie diese Daten noch nicht haben, laden Sie sie direkt in Ihren Daten-Ordner vom GitHub-Kurs herunter (klicken Sie auf “Download raw file” neben dem “Raw”-Button):\n\nlanguageR_english.csv\ngroesse_geburtstag_ws2324.csv\n\n\ndf_groesse &lt;- read_csv(here(\"daten\", \"groesse_geburtstag_ws2324.csv\"))\n\n\ndf_eng &lt;- read_csv(here(\"daten\", \"languageR_english.csv\")) |&gt; \n  clean_names() |&gt; \n  # fix some wonky variable names:\n  rename(rt_lexdec = r_tlexdec,\n         rt_naming = r_tnaming)"
  },
  {
    "objectID": "mats/08-desc_stats.html#deskriptive-statistik",
    "href": "mats/08-desc_stats.html#deskriptive-statistik",
    "title": "8  Deskriptive Statistik",
    "section": "8.2 Deskriptive Statistik",
    "text": "8.2 Deskriptive Statistik\nDeskriptive Statistiken beschreiben quantitativ die zentrale Tendenz, die Variabilität und die Verteilung von Daten. Sie werden manchmal auch als zusammenfassende Statistiken bezeichnet, weil wir die beobachteten Daten zusammenfassen. Zu den gängigen zusammenfassenden Statistiken gehören der Wertebereich (Minimum, Maximum), der Mittelwert und die Standardabweichung. Deskriptive Statistiken helfen uns, unsere Daten in vollem Umfang zu verstehen, und sind ein wichtiger Schritt bei der Untersuchung unseres Datensatzes, bevor wir fortgeschrittenere Inferenzstatistiken durchführen (die wir in diesem Kurs nicht behandeln werden).\n\n8.2.1 Anzahl der Beobachtungen (\\(n\\))\nDie Anzahl der Beobachtungen in einem Datensatz ist keine statistische Größe, sondern eine wichtige Information bei der Zusammenfassung oder Beschreibung von Daten. Wenn wir mehr Daten haben (höher \\(n\\)), können wir den Schlussfolgerungen, die wir aus unseren Daten ziehen, mehr Vertrauen schenken, da wir mehr Beweise haben. Umgekehrt kann es sein, dass bei weniger Daten (niedriger \\(n\\)) unsere zusammenfassende Statistik nicht auf die Grundgesamtheit verallgemeinerbar ist. Wir können die Anzahl der Beobachtungen in einem Datensatz mit der R-eigenen Funktion nrow() überprüfen:\n\nnrow(df_groesse)\n\n[1] 9\n\n\n\n\n\n\n\n\nlength() gegenüber nrow()\n\n\n\nDie Funktion length() sagt uns, wie viele (horizontale) Werte in einem Objekt enthalten sind. Wenn das Objekt ein Datenrahmen (statt eines Vektors) ist, sagt sie uns, wie viele Spalten wir haben.\n\nlength(df_groesse)\n\n[1] 5\n\n\nWenn es sich bei dem Objekt jedoch um einen Vektor handelt, dann gibt uns length() die Anzahl der Beobachtungen an.\n\nvector &lt;- c(1,5,2,6,8,4,7,8,3)\nlength(vector)\n\n[1] 9\n\n\n\n\n\n\n8.2.2 Maße der zentralen Tendenz (Lagemaße)\nMaße der zentralen Tendenz beschreiben quantitativ die Mitte unserer Daten. Wahrscheinlich haben Sie schon einmal drei Maße der zentralen Tendenz kennengelernt: den Mittelwert, den Median und den Modus.\n\n8.2.2.1 Mittelwert (\\(\\mu\\) oder \\(\\bar{x}\\))\nDer Mittelwert oder Durchschnitt ist die Summe aller Werte geteilt durch die Anzahl der Werte (wie in Gleichung \\(\\ref{eq-mean}\\)). In der mathematischen Notation wird sum mit dem großen griechischen Sigma (\\(\\sum\\)) geschrieben, wie in der Gleichung \\(\\ref{eq-sigma}\\).\n\\[\\begin{align}\n\\mu &= \\frac{Summe\\;der\\;Werte}\n           {n} \\label{eq-mean} \\\\\n\\bar{x} &= \\frac{\\sum{x}}      \n           {n} \\label{eq-sigma}\n\\end{align}\\]\n\n\n8.2.2.2 Populationsmittelwert (\\(\\mu\\)) versus Stichprobenmittelwert (\\(\\bar{x}\\))\nBeide Gleichungen bedeuten dasselbe, verwenden aber unterschiedliche Schreibweisen, um dieselbe Gleichung darzustellen. Während \\(\\mu\\) den Populationsmittelwert darstellt, repräsentiert \\(\\bar{x}\\) den Stichprobenmittelwert. Der Populationsmittelwert ist der wahre Mittelwert einer Messung in einer gesamten Population (z. B. die Körpergröße aller Studenten an der Humboldt-Universität zu Berlin). Ein Stichprobenmittel ist der Mittelwert einer Stichprobenpopulation, aus der wir unsere Daten erhoben haben. Wir haben zum Beispiel 9 Beobachtungen in df_groesse. Diese Daten stellen eine Stichprobe von Daten aus einer größeren Grundgesamtheit dar.\n\nWir können den Mittelwert leicht von Hand berechnen, wenn wir nur ein paar Werte haben. Erinnern Sie sich an unseren Datensatz von letzter Woche, in dem wir unsere Höhen in Zentimetern gesammelt haben (171, 168, 182, 190, 170, 163, 164, 167, 189). Es gibt 9 Werte, also müssen wir diese Höhen addieren und die Summe durch 9 teilen.\n\n171+ 168+ 182+ 190+ 170+ 163+ 164+ 167+ 189 / 9\n\n[1] 1396\n\n\nDaraus ergibt sich eine durchschnittliche Körpergröße von 1396 cm. Das kann nicht richtig sein, was ist also schief gelaufen? Wir können die obige Gleichung korrigieren, indem wir die Höhen in Klammern setzen (()), bevor wir durch \\(n\\) dividieren.\n\n(171+ 168+ 182+ 190+ 170+ 163+ 164+ 167+ 189) / 9\n\n[1] 173.7778\n\n\nDieses Problem wurde durch die Reihenfolge der Operationen verursacht, die im Folgenden näher beschrieben wird. Das Wichtigste ist, dass Sie sicher sein können, dass das Ergebnis einer bestimmten Operation vor allen anderen Operationen ausgeführt wird, wenn Sie es in Paranthesen einschließen.\n\n\n\n\n\n\nOperatorrangfolge: KEMDAS\n\n\n\nVielleicht erinnern Sie sich, dass Sie als Kind im Mathematikunterricht etwas über die Reihenfolge der Operationen gelernt haben. Dies bezieht sich auf die Reihenfolge der Ausführung, wenn wir eine mathematische Gleichung mit mehreren Operatoren wie Division, Addition und Multiplikation haben. R folgt auf KEMDAS (das ich von PEMDAS im Englischen übernommen habe), was für:\n\n\n\n\nTabelle 8.1: KEMDAS\n\n\nletter\noperation\nR\n\n\n\n\nK\nKlammern\n(x + y)\n\n\nE\nExponenten\nx^y\n\n\nM\nMultiplikation\nx*y\n\n\nD\nDivision\nx/y\n\n\nA\nAddierung\nx + y\n\n\nS\nSubtraktion\nx - y\n\n\n\n\n\n\n\n\nMultiplikation und Division werden jedoch von links nach rechts ausgeführt, ebenso wie Addition und Subtraktion.\n\n\nWir können auch die Ergebnisse einer Gleichung als Objekt oder mehrere Werte als Vektor (eine Liste von Werten der gleichen Klasse) speichern. Wir könnten dann die Funktionen sum() und length() verwenden, um den Mittelwert zu berechnen, oder einfach die Funktion mean() benutzen.\n\n# save groesse as a vector\ngroesse &lt;- c(171, 168, 182, 190, 170, 163, 164, 167, 189)\n# divide the sum of groesse by the n of groesse\nsum(groesse)/length(groesse)\n\n[1] 173.7778\n\n\n\n# or use the mean() function\nmean(groesse)\n\n[1] 173.7778\n\n\nUnsere Daten sind oft nicht in einem einzelnen Vektor gespeichert, sondern in einem Datensatz. Wir können die Funktion mean() auf eine Variable in einem Datenrahmen anwenden, indem wir den Operator $ verwenden, um anzugeben, dass wir eine Spalte aus einem Datenrahmen auswählen wollen (datenrahmen$variable).\n\nmean(df_groesse$groesse)\n\n[1] 173.6667\n\n\nDer $-Operator ist Teil der nativen R-Syntax und ähnelt dem Operator pdf_groesse |&gt;select(groesse) in der dplyr-Syntax.\n\n8.2.2.3 Median\nEin weiteres Maß für die zentrale Tendenz ist der Median, d. h. der Wert in der Mitte des Datensatzes. Wenn Sie alle Ihre Werte in aufsteigender (oder absteigender) Reihenfolge anordnen, ist der mittlere Wert der Median. Wenn Sie zum Beispiel 5 Werte haben, ist der 3. Bei 6 Werten ist der Mittelwert des 3. und 4. Wertes der Median. Die Hälfte der Daten liegt unter dem Median, die andere Hälfte über dem Median.\nUm unsere Daten in aufsteigender Reihenfolge zu sortieren, können wir die Funktion sort() verwenden. Wir können dann einfach zählen, welches der mittlere Wert ist:\n\nsort(df_groesse$groesse)\n\n[1] 163 164 167 167 170 171 182 189 190\n\n\nDas ist einfach, wenn wir nur ein paar Beobachtungen haben. Wir könnten alternativ einfach die Funktion Median() verwenden.\n\nmedian(df_groesse$groesse)\n\n[1] 170\n\n\nEin wichtiges Merkmal des Medians ist, dass er nicht von Ausreißern oder Extremwerten beeinflusst wird. Schauen wir uns an, was passiert, wenn wir unsere größte Körpergröße (190 cm) so ändern, dass sie der Größe der derzeit größten Person der Welt entspricht: 251 cm.\n\ndf_groesste &lt;- df_groesse |&gt; mutate(groesse = ifelse(groesse == 190, 251, groesse))\n\n\nsort(df_groesste$groesse)\n\n[1] 163 164 167 167 170 171 182 189 251\n\n\n\nmedian(df_groesste$groesse)\n\n[1] 170\n\n\n\nmean(df_groesste$groesse)\n\n[1] 180.4444\n\n\nWir sehen, dass sich der Mittelwert von ungefähr 174cm auf 180cm geändert hat. Der Median blieb jedoch gleich (170 cm), weil der Mittelwert unabhängig von den anderen Werten in einem Datensatz ist. Aus diesem Grund wird der Median häufig anstelle des Mittelwerts angegeben, wenn die Daten stark zu extremeren Werten neigen, wie z. B. bei der Angabe der Einkommen in einer Bevölkerung. Durchschnittseinkommen können aufgrund einer kleinen Gruppe von extrem gut Verdienenden stark verzerrt sein und sind in der Regel nicht repräsentativ für das Einkommen der Mehrheit der Bürger.\n\n\n8.2.2.4 Modus\nDer Modus ist der Wert, der in einem Datensatz am häufigsten vorkommt, und ist ein weiteres Maß für die zentrale Tendenz. Es gibt keine R-Funktion, um den Modus zu bestimmen, aber wir haben bereits einige gängige Möglichkeiten gesehen, ihn zu visualisieren: mit einem Histogramm oder einem Dichteplot.\n\ndf_groesse |&gt;\n  ggplot(aes(x = groesse)) +\n  geom_histogram(binwidth = .5) +\n  theme_minimal() \n\n\n\n\n\n\n\n8.2.3 Streuungsmaße\nMaße der zentralen Tendenz beschreiben (normalerweise) die Mitte der Daten. Streuungsmaße beschreiben die Streuung der Datenpunkte und sagen etwas darüber aus, wie die Daten insgesamt verteilt sind.\n\n8.2.3.1 Bereich\nDer “Bereich” von Werten kann sich auf den höchsten (maximalen) und den niedrigsten (minimalen) Wert oder auf die Differenz zwischen höchstem und niedrigstem Wert beziehen. Die R-Basisfunktionen max() und min() geben die höchsten und niedrigsten Werte aus.\n\nmax(groesse)\n\n[1] 190\n\n\n\nmin(groesse)\n\n[1] 163\n\n\nOder wir können einfach die Funktion range() verwenden, die diese beiden Zahlen nebeneinander ausgibt.\n\nrange(groesse)\n\n[1] 163 190\n\n\nWir können die Differenz zwischen diesen Werten ermitteln, indem wir den Minimalwert vom Maximalwert subtrahieren.\n\nmax(groesse) - min(groesse)\n\n[1] 27\n\n\nIn einem Histogramm oder Dichteplot werden diese Werte durch den niedrigsten und den höchsten Wert auf der x-Achse dargestellt.\n\n\n\n\n\n\n\n8.2.3.2 Standardabweichung (sd oder \\(\\sigma\\))\nDie Standardabweichung ist ein Maß dafür, wie weit die Daten im Verhältnis zum Mittelwert gestreut sind. Eine niedrige Standardabweichung bedeutet, dass die Daten um den Mittelwert herum gruppiert sind (d. h. es gibt weniger Streuung), während eine hohe Standardabweichung bedeutet, dass die Daten stärker gestreut sind. Ob eine Standardabweichung hoch oder niedrig ist, hängt von der Skala und der Maßeinheit ab, in der die Daten vorliegen. Die Standardabweichung wird sehr oft angegeben, wenn der Mittelwert berichtet wird.\nDie Standardabweichung (sd) ist gleich der Quadratwurzel (\\(\\sqrt{}\\) oder sqrt() in R) der Summe der quadrierten Wertabweichungen vom Mittelwert (\\((x - \\mu)^2\\)) geteilt durch die Anzahl der Beobachtungen minus 1 (\\(n-1\\)), angegeben in Gleichung \\(\\ref{eq-sd}\\).\n\\[\\begin{align}\n\\sigma & = \\sqrt{\\frac{(x_1-\\mu)^2 + (x_2-\\mu)^2 + ... + (x_N-\\mu)^2}{N-1}} \\label{eq-sd}\n\\end{align}\\]\nDas sieht einschüchternd aus, aber wir können die Standardabweichung in R mit der Funktion sd() berechnen.\n\nsd(groesse)\n\n[1] 10.46157\n\n\nWenn man jedoch weiß, wie man die Standardabweichung von Hand berechnen kann, versteht man, was die Zahl bedeutet. Lassen Sie uns die Berechnung der Standardabweichung für eine kleine Gruppe von Werten üben. Unter Berücksichtigung der Gleichung für die Standardabweichung in \\(\\ref{eq-sd}\\) können wir die Standardabweichung von Hand berechnen, wenn wir den Wert jeder Beobachtung, den Mittelwert dieser Werte und die Anzahl dieser Werte kennen. In einem Vektor mit 3 Beobachtungen (3, 5, 9) sind unsere Werte (\\(x\\)) zum Beispiel folgende:\n\nvalues &lt;- c(3,5,16)\nvalues\n\n[1]  3  5 16\n\n\nSetzt man diese in die Gleichung für die Standardabweichung ein, erhält man Gleichung \\(\\ref{eq-sd1}\\).\n\\[\\begin{align}\n\\sigma & = \\sqrt{\\frac{(3-\\mu)^2 + (5-\\mu)^2 + (16-\\mu)^2}{N-1}} \\label{eq-sd1}\n\\end{align}\\]\nUnser Mittelwert (\\(\\mu\\)) ist:\n\nmean(values)\n\n[1] 8\n\n\nWenn wir dies zu Gleichung \\(\\ref{eq-sd1}\\) hinzufügen, erhalten wir Gleichung \\(\\ref{eq-sd2}\\).\n\\[\\begin{align}\n\\sigma & = \\sqrt{\\frac{(3-8)^2 + (5-8)^2 + (16-8)^2}{N-1}} \\label{eq-sd2}\n\\end{align}\\]\nDie Anzahl der Werte (\\(n\\)) ist:\n\nlength(values)\n\n[1] 3\n\n\nWenn wir dies zu Gleichung \\(\\ref{eq-sd2}\\) hinzufügen, erhalten wir Gleichung \\(\\ref{eq-sd3}\\).\n\\[\\begin{align}\n\\sigma & = \\sqrt{\\frac{(3-8)^2 + (5-8)^2 + (16-8)^2}{3-1}} \\label{eq-sd3}\n\\end{align}\\]\nIf we carry out all of the operations following PEDMAS, then we get Equations \\(\\ref{eq-sd4}\\) through \\(\\ref{eq-sd}\\):\n\\[\\begin{align}\n\\sigma & = \\sqrt{\\frac{(-5)^2 + (-3)^2 + (8)^2}{3-1}} \\\\ \\label{eq-sd4}\n\\\\\n& = \\sqrt{\\frac{25 + 9 + 64}{3-1}}\n\\\\\n& = \\sqrt{\\frac{98}{2}} \\\\\n& = \\sqrt{49} \\\\\n& = 7\n\\end{align}\\]\nUm unsere Arbeit zu überprüfen, berechnen wir die Standardabweichung (\\(\\sigma\\)) in “R”:\n\nsd(values)\n\n[1] 7\n\n\n\n\n8.2.3.3 Warum Standardabweichung?\nDie Standardabweichung ist ein Maß dafür, wie “eng” die beobachteten Werte am Mittelwert liegen. Wenn die meisten Beobachtungen sehr nahe am Mittelwert liegen, ist die Standardabweichung im Verhältnis zum Mittelwert eine kleine Zahl. Wenn es viele Beobachtungen mit großen Abweichungen vom Mittelwert gibt, wird die Standardabweichung tendenziell eine große Zahl sein (relativ zum Mittelwert).\nVerschiedene Datensätze können denselben Mittelwert, aber sehr unterschiedliche Standardabweichungen aufweisen. Ein Beispiel:\n\nvalues2 &lt;- c(55,55,55,55,55,57,57,57,57,57)\nvalues3 &lt;- c(1,1,1,1,100,100,100,100,100)\n\n\nmean(values2)\n\n[1] 56\n\n\n\nmean(values3)\n\n[1] 56\n\n\nWir sehen, dass values2 und values3 den gleichen Mittelwert haben. Daraus könnte man schließen, dass die Daten ähnlich sind. Aber ihre Standardabweichungen werden sich unterscheiden, weil ihre jeweiligen beobachteten Werte alle unterschiedlich weit vom Mittelwert abweichen. Welcher Vektor wird Ihrer Meinung nach die geringste Standardabweichung haben? Und warum?\n\nsd(values2)\n\n[1] 1.054093\n\n\n\nsd(values3)\n\n[1] 52.17758\n\n\nDie größere Standardabweichung für Werte3 spiegelt die Tatsache wider, dass die Werte tendenziell sehr weit vom Mittelwert entfernt sind. Die kleinere Standardabweichung für Werte2 spiegelt die Tatsache wider, dass der Wert für diese Variable tendenziell recht nahe am Mittelwert liegt.\n\n\n\n\n\n\nQuadrat und Quadratwurzel\n\n\n\nWarum quadrieren wir die Abweichung jeder Beobachtung vom Mittelwert, um dann später die Quadratwurzel aus ihrer Summe geteilt durch \\(N-1\\) zu berechnen? Da die Hälfte unserer Beobachtungen unterhalb und die Hälfte oberhalb des Mittelwerts liegen wird, sind die resultierenden Differenzen, wenn wir den Mittelwert von den Werten abziehen, zur Hälfte negativ und zur Hälfte positiv. Wenn wir positive und negative Werte zusammenzählen, heben sie sich gegenseitig auf. Wenn wir also alle diese Abweichungen vom Mittelwert quadrieren, werden alle Werte positiv sein (eine positive Zahl multipliziert mit einer positiven Zahl ist eine positive Zahl, während eine negative Zahl multipliziert mit sich selbst ebenfalls eine positive Zahl ergibt). Wenn wir dann die Quadratwurzel dieser Werte berechnen, erhalten wir die ursprüngliche Größe der Abweichung, aber immer als positiven Wert.\n\n\n\n\n\n\n\n\nEigenschaften der Grundgesamtheit\n\n\n\nSowohl der Mittelwert als auch die Standardabweichung sagen etwas über die Grundgesamtheit aus, aus der unsere Datenstichprobe stammt. Je mehr Beobachtungen wir sammeln, desto genauer werden diese Maße im Durchschnitt sein."
  },
  {
    "objectID": "mats/08-desc_stats.html#zusammenfassende-statistiken-mit-r",
    "href": "mats/08-desc_stats.html#zusammenfassende-statistiken-mit-r",
    "title": "8  Deskriptive Statistik",
    "section": "8.3 Zusammenfassende Statistiken mit R",
    "text": "8.3 Zusammenfassende Statistiken mit R\nWir haben bereits einige nützliche Funktionen zur Berechnung von zusammenfassenden Statistiken gesehen (z.B. mean(), median(), sd()). In der Regel möchten wir jedoch mehrere zusammenfassende Statistiken auf einmal erstellen und zusammenfassende Statistiken zwischen Gruppen vergleichen. Um dies zu erreichen, bietet das Paket dplyr aus dem tidyverse einige hilfreiche Funktionen. Lassen Sie uns nun den df_eng-Datensatz verwenden, um diese dplyr-Verben kennenzulernen.\n\n8.3.1 dplyr::summarise\nDie Funktion summarise() von dplyr berechnet Zusammenfassungen von Daten, aber wir müssen ihr sagen, was sie berechnen soll, und für welche Variable(n). Die Funktion n() liefert zum Beispiel die Anzahl der Beobachtungen (nur wenn sie innerhalb von summarise() oder mutate() verwendet wird). Lassen Sie uns zunächst prüfen, wie viele Beobachtungen wir im Datensatz df_eng haben:\n\ndf_eng |&gt;\n  summarise(N = n())\n\n# A tibble: 1 × 1\n      N\n  &lt;int&gt;\n1  4568\n\n\nWerfen wir nun einen Blick auf das Histogramm von rt_lexdec, der Variable, die die lexikalische Entscheidungsantwortzeit in Millisekunden enthält:\n\ndf_eng |&gt; \n  ggplot() +\n  aes(x = rt_lexdec) +\n  geom_histogram()\n\n\n\n\nWir sehen, dass die Antwortzeit zwischen 500 ms und 1320 ms liegt, wobei die meisten Antworten zwischen 550 ms und 900 ms liegen. Wir sehen auch eine bimodale Verteilung, d. h. es gibt zwei Modi (zwei Spitzen). Der allgemeine Modus liegt bei 700 ms (500 Beobachtungen), mit einer zweiten Spitze bei 600 ms (~420 Beobachtungen).\nWir können auch mehrere Berechnungen auf einmal durchführen. Lassen Sie uns auch den Mittelwert und die Standardabweichung der lexikalischen Entscheidungsaufgabe (rt_lexdec, in Millisekunden) berechnen.\n\ndf_eng |&gt;\n  summarise(mean_lexdec = mean(rt_lexdec, na.rm=T),\n            sd_lexdec = sd(rt_lexdec, na.rm = T),\n            N = n()) \n\n# A tibble: 1 × 3\n  mean_lexdec sd_lexdec     N\n        &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n1        708.      115.  4568\n\n\nJetzt sehen wir, dass die durchschnittliche lexikalische Entscheidungsantwortzeit 708.1 ms betrug, mit einer Standardabweichung von 114.9.\nUnd wir können Berechnungen mit typischen mathematischen Operatoren (z.B. +, -, /, *, ^ …) und/oder Funktionen angeben. Was war der Unterschied zwischen der längsten und der kürzesten lexikalischen Entscheidungsantwortzeit?\n\ndf_eng |&gt;\n  summarise(range_lexdec = max(rt_lexdec) - min(rt_lexdec))\n\n# A tibble: 1 × 1\n  range_lexdec\n         &lt;dbl&gt;\n1         828.\n\n\n\n\n\n\n\n\nFehlende Werte\n\n\n\nEinige Berechnungen sind nicht möglich, wenn Werte fehlen. Die Variable rt_naming hat einen fehlenden Wert. Dies ist in der Ausgabe der Funktion summary() zu sehen, die vor der Berechnung der zusammenfassenden Statistik alle NA-Werte löscht.\n\ndf_eng |&gt;\n  select(rt_lexdec, rt_naming) |&gt;\n  summary()\n\n   rt_lexdec        rt_naming    \n Min.   : 495.4   Min.   :412.3  \n 1st Qu.: 617.4   1st Qu.:468.1  \n Median : 699.6   Median :570.6  \n Mean   : 708.1   Mean   :565.9  \n 3rd Qu.: 775.3   3rd Qu.:658.4  \n Max.   :1323.2   Max.   :808.9  \n                  NA's   :1      \n\n\nDie Funktion mean() entfernt jedoch nicht die NA-Werte.\n\ndf_eng |&gt;\n  summarise(mean_naming = mean(rt_naming))\n\n# A tibble: 1 × 1\n  mean_naming\n        &lt;dbl&gt;\n1          NA\n\n\nWas tun wir mit fehlenden Werten? Bei der Arbeit mit realen Daten ist es nicht trivial, wie wir mit fehlenden Werten umgehen. Wir könnten z. B. alle NA-Werte in 0 umwandeln, wenn wir wollen, dass sie zur Berechnung des Mittelwerts beitragen. Meistens wollen wir sie jedoch einfach entfernen.\nWir können dies leicht mit dem dplyr-Verb drop_na() tun:\n\ndf_eng |&gt;\n  drop_na() |&gt;\n  summarise(mean_naming = mean(rt_naming))\n\n# A tibble: 1 × 1\n  mean_naming\n        &lt;dbl&gt;\n1        566."
  },
  {
    "objectID": "mats/08-desc_stats.html#gruppierung-von-variablen",
    "href": "mats/08-desc_stats.html#gruppierung-von-variablen",
    "title": "8  Deskriptive Statistik",
    "section": "8.4 Gruppierung von Variablen",
    "text": "8.4 Gruppierung von Variablen\nWir wollen jedoch nicht immer nur die zusammenfassenden Statistiken für einen gesamten Datensatz kennen. Normalerweise wollen wir bestimmte Gruppen vergleichen (z. B. Vergleich der Reaktionszeiten bei lexikalischen Entscheidungen zwischen Altersgruppen)\n\n8.4.1 .by =\nDas semi-neue (und experimentelle) Argument .by = in summarise() berechnet unsere Berechnungen auf gruppierten Teilmengen der Daten. Es nimmt eine Variable (d.h. einen Spaltennamen) und gruppiert nach den Stufen dieser Variable.\n\ndf_eng |&gt;\n  drop_na() |&gt;\n  summarise(mean_lexdec = mean(rt_lexdec),\n            sd_lexdec = sd(rt_lexdec),\n            N = n(),\n            .by = age_subject) |&gt;\n  arrange(mean_lexdec)\n\n# A tibble: 2 × 4\n  age_subject mean_lexdec sd_lexdec     N\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n1 young              630.      69.1  2283\n2 old                787.      96.2  2284\n\n\n\n\n8.4.2 Gruppieren nach mehreren Variablen\n\nWir können auch nach mehreren Variablen gruppieren\n\ndafür brauchen wir concatenate (c())\n\n\n\ndf_eng |&gt;\n  drop_na() |&gt;\n  summarise(mean_lexdec = mean(rt_lexdec),\n            sd_lexdec = sd(rt_lexdec),\n            N = n(),\n            .by = c(age_subject, word_category)) |&gt;\n  arrange(age_subject)\n\n# A tibble: 4 × 5\n  age_subject word_category mean_lexdec sd_lexdec     N\n  &lt;chr&gt;       &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n1 old         N                    790.     101.   1452\n2 old         V                    780.      86.5   832\n3 young       N                    633.      70.8  1451\n4 young       V                    623.      65.7   832\n\n\n\n\n\n\n\n\ngroup_by()\n\n\n\n\nAnstelle des neuen .by-Arguments können wir das dplyr-Verb group_by() und ungroup() verwenden\n\nIch bevorzuge das neue .by, weil es die Gruppierung lokal hält (keine Notwendigkeit für ungroup())\nBehalten Sie dies im Hinterkopf, Sie könnten group_by() in freier Wildbahn sehen\n\n\n\ndf_eng |&gt;\n  group_by(age_subject, word_category) |&gt; \n  summarise(mean_lexdec = mean(rt_lexdec),\n            sd_lexdec = sd(rt_lexdec),\n            N = n()) |&gt; \n  ungroup() |&gt; \n  arrange(age_subject)\n\n# A tibble: 4 × 5\n  age_subject word_category mean_lexdec sd_lexdec     N\n  &lt;chr&gt;       &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n1 old         N                    790.     101.   1452\n2 old         V                    780.      86.5   832\n3 young       N                    633.      70.8  1452\n4 young       V                    623.      65.7   832"
  },
  {
    "objectID": "mats/08-desc_stats.html#anscombes-quartett",
    "href": "mats/08-desc_stats.html#anscombes-quartett",
    "title": "8  Deskriptive Statistik",
    "section": "8.5 Anscombes Quartett",
    "text": "8.5 Anscombes Quartett\nFrancis Anscombe erstellte 1973 vier Datensätze, um zu veranschaulichen, wie wichtig es ist, Daten zu visualisieren, bevor man sie analysiert und ein Modell erstellt. Diese vier Diagramme stellen 4 Datensätze dar, die alle einen nahezu identischen Mittelwert und eine Standardabweichung, aber sehr unterschiedliche Verteilungen aufweisen.\n\n\n\n\nTabelle 8.2: Summary stats of Anscombe’s quratet datasets\n\n\ngrp\nmean_x\nmean_y\nmin_x\nmin_y\nmax_x\nmax_y\ncrrltn\n\n\n\n\nGroup 1\n9\n7.500909\n4\n4.26\n14\n10.84\n0.8164205\n\n\nGroup 2\n9\n7.500909\n4\n3.10\n14\n9.26\n0.8162365\n\n\nGroup 3\n9\n7.500000\n4\n5.39\n14\n12.74\n0.8162867\n\n\nGroup 4\n9\n7.500909\n8\n5.25\n19\n12.50\n0.8165214\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 8.1: Plots of Anscombe’s quratet distributions\n\n\n\n\n\n8.5.1 DatasaurRus\nDas Paket datasauRus (Davies et al., 2022) enthält einige weitere Datensätze, die ähnliche Mittelwerte und sd, aber unterschiedliche Verteilungen aufweisen, die in Tabelle 8.3 angegeben sind.\n\npacman::p_load(\"datasauRus\")\n\n\ndatasaurus_dozen |&gt;\n    group_by(dataset) |&gt;\n    summarize(\n      mean_x    = mean(x),\n      mean_y    = mean(y),\n      std_dev_x = sd(x),\n      std_dev_y = sd(y),\n      corr_x_y  = cor(x, y)\n    ) |&gt;\n  knitr::kable() |&gt;\n  kableExtra::kable_styling(font_size = 20)\n\n\n\nTabelle 8.3: Summary stats of datasauRus datasets\n\n\ndataset\nmean_x\nmean_y\nstd_dev_x\nstd_dev_y\ncorr_x_y\n\n\n\n\naway\n54.26610\n47.83472\n16.76983\n26.93974\n-0.0641284\n\n\nbullseye\n54.26873\n47.83082\n16.76924\n26.93573\n-0.0685864\n\n\ncircle\n54.26732\n47.83772\n16.76001\n26.93004\n-0.0683434\n\n\ndino\n54.26327\n47.83225\n16.76514\n26.93540\n-0.0644719\n\n\ndots\n54.26030\n47.83983\n16.76774\n26.93019\n-0.0603414\n\n\nh_lines\n54.26144\n47.83025\n16.76590\n26.93988\n-0.0617148\n\n\nhigh_lines\n54.26881\n47.83545\n16.76670\n26.94000\n-0.0685042\n\n\nslant_down\n54.26785\n47.83590\n16.76676\n26.93610\n-0.0689797\n\n\nslant_up\n54.26588\n47.83150\n16.76885\n26.93861\n-0.0686092\n\n\nstar\n54.26734\n47.83955\n16.76896\n26.93027\n-0.0629611\n\n\nv_lines\n54.26993\n47.83699\n16.76996\n26.93768\n-0.0694456\n\n\nwide_lines\n54.26692\n47.83160\n16.77000\n26.93790\n-0.0665752\n\n\nx_shape\n54.26015\n47.83972\n16.76996\n26.93000\n-0.0655833\n\n\n\n\n\n\n\n\nWenn wir die Datensätze grafisch darstellen, sehen sie alle sehr unterschiedlich aus (Abbildung 8.2)!\n\n\n\n\n\nAbbildung 8.2: Plots of datasauRus dataset distributions\n\n\n\n\nDer Punkt hier ist: Stellen Sie Ihre Daten immer grafisch dar und betrachten Sie nicht nur die beschreibenden Statistiken!!! Beides ist sehr wichtig für das Verständnis Ihrer Daten. Wir haben bereits gesehen, wie wir unsere Rohdaten mithilfe von Histogrammen, Dichteplots, Balkendiagrammen und Streudiagrammen darstellen können. Nächste Woche werden wir uns ansehen, wie wir unsere zusammenfassenden Statistiken darstellen und wie wir die Rohdaten in die Darstellung mit mehrteiligen Diagrammen einbeziehen können."
  },
  {
    "objectID": "mats/08-desc_stats.html#lernziele-1",
    "href": "mats/08-desc_stats.html#lernziele-1",
    "title": "8  Deskriptive Statistik",
    "section": "Lernziele 🏁",
    "text": "Lernziele 🏁\nToday we learned…\n\nüber Maße der zentralen Tendenz ✅\nüber Streuungsmaße ✅\nwie man die Funktion summarise() von dplyr verwendet ✅\nwie man Zusammenfassungen nach Gruppen erstellt ✅"
  },
  {
    "objectID": "mats/08-desc_stats.html#hausaufgaben",
    "href": "mats/08-desc_stats.html#hausaufgaben",
    "title": "8  Deskriptive Statistik",
    "section": "8.6 Hausaufgaben",
    "text": "8.6 Hausaufgaben\n::: nonincremental\n\nBerechnen Sie die Standardabweichung der Werte 152, 19, 1398, 67, 2111, ohne die Funktion sd() zu benutzen.\n\nzeige deine Arbeit. Die folgende R-Syntax könnte nützlich sein (je nachdem, wie Sie es machen wollen):\n\nc()\nmean()\nx^2 berechnet das Quadrat eines Wertes (hier, x)\nsqrt() berechnet die Quadratwurzel\nlength() liefert die Anzahl der Beobachtungen in einem Vektor\n\n\n\n\nBenutze die Funktion sd(), um die Standardabweichung der obigen Werte zu drucken. Haben Sie es richtig gemacht?\nBenutze summarise, um den Mittelwert, die Standardabweichung und die Anzahl der Beobachtungen für rt_naming im df_lexdec Datenrahmen zu drucken.\n\nHinweis: Müssen Sie fehlende Werte (NA) entfernen?\n\nMachen Sie dasselbe, aber fügen Sie das Argument .by() hinzu, um die mittlere Reaktionszeit der Benennungsaufgabe (rt_naming) pro Monat zu ermitteln\n\nOrdnen Sie die Ausgabe nach der mittleren Antwortzeit für die Namensgebung an."
  },
  {
    "objectID": "mats/08-desc_stats.html#session-info",
    "href": "mats/08-desc_stats.html#session-info",
    "title": "8  Deskriptive Statistik",
    "section": "Session Info",
    "text": "Session Info\nErstellt mit R version 4.3.0 (2023-04-21) (Already Tomorrow) und RStudioversion 2023.9.0.463 (Desert Sunflower).\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] datasauRus_0.1.6 patchwork_1.1.3  janitor_2.2.0    here_1.0.1      \n [5] lubridate_1.9.2  forcats_1.0.0    stringr_1.5.0    dplyr_1.1.3     \n [9] purrr_1.0.2      readr_2.1.4      tidyr_1.3.0      tibble_3.2.1    \n[13] ggplot2_3.4.3    tidyverse_2.0.0 \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4      xfun_0.39         htmlwidgets_1.6.2 lattice_0.21-8   \n [5] tzdb_0.4.0        vctrs_0.6.3       tools_4.3.0       generics_0.1.3   \n [9] parallel_4.3.0    fansi_1.0.4       highr_0.10        pacman_0.5.1     \n[13] pkgconfig_2.0.3   Matrix_1.5-4      webshot_0.5.4     lifecycle_1.0.3  \n[17] compiler_4.3.0    farver_2.1.1      munsell_0.5.0     snakecase_0.11.0 \n[21] htmltools_0.5.5   yaml_2.3.7        pillar_1.9.0      crayon_1.5.2     \n[25] nlme_3.1-162      tidyselect_1.2.0  rvest_1.0.3       digest_0.6.33    \n[29] stringi_1.7.12    labeling_0.4.3    splines_4.3.0     rprojroot_2.0.3  \n[33] fastmap_1.1.1     grid_4.3.0        colorspace_2.1-0  cli_3.6.1        \n[37] magrittr_2.0.3    utf8_1.2.3        withr_2.5.0       scales_1.2.1     \n[41] bit64_4.0.5       timechange_0.2.0  rmarkdown_2.22    httr_1.4.6       \n[45] bit_4.0.5         hms_1.1.3         kableExtra_1.3.4  evaluate_0.21    \n[49] knitr_1.44        viridisLite_0.4.2 mgcv_1.8-42       rlang_1.1.1      \n[53] glue_1.6.2        xml2_1.3.4        svglite_2.1.1     rstudioapi_0.14  \n[57] vroom_1.6.3       jsonlite_1.8.7    R6_2.5.1          systemfonts_1.0.4"
  },
  {
    "objectID": "mats/08-desc_stats.html#literaturverzeichnis",
    "href": "mats/08-desc_stats.html#literaturverzeichnis",
    "title": "8  Deskriptive Statistik",
    "section": "Literaturverzeichnis",
    "text": "Literaturverzeichnis\n\n\nDavies, R., Locke, S., & D’Agostino McGowan, L. (2022). datasauRus: Datasets from the Datasaurus Dozen. https://CRAN.R-project.org/package=datasauRus\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for Data Science (2. Aufl.).\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547"
  },
  {
    "objectID": "mats/09-wrangling_2.html#lernziele",
    "href": "mats/09-wrangling_2.html#lernziele",
    "title": "9  Data Wrangling 2",
    "section": "Lernziele",
    "text": "Lernziele\nIn diesem Kapitel werden wir lernen…\n\nüber breite versus lange Daten\nwie man breite Daten länger machen kann\nwie man lange Daten breiter macht"
  },
  {
    "objectID": "mats/09-wrangling_2.html#lesungen",
    "href": "mats/09-wrangling_2.html#lesungen",
    "title": "9  Data Wrangling 2",
    "section": "Lesungen",
    "text": "Lesungen\nDie Pflichtlektüre zur Vorbereitung auf dieses Thema ist Kapital 6 (Data tidying) in Wickham et al. (2023).\nEine ergänzende Lektüre ist Kapital 8 (Data tidying) in Nordmann & DeBruine (2022)."
  },
  {
    "objectID": "mats/09-wrangling_2.html#wiederholung",
    "href": "mats/09-wrangling_2.html#wiederholung",
    "title": "9  Data Wrangling 2",
    "section": "9.1 Wiederholung",
    "text": "9.1 Wiederholung\nIm letzten Kapitel haben wir etwas über deskriptive Statistik gelernt, insbesondere über Maße der zentralen Tendenz (Mittelwert, Median, Modus) und der Streuung (Bereich, Standardabweichung). Wir haben auch gesehen, wie man diese Werte mit Base R (z. B. mean(), sd()) und der tidyverse (z. B. summarise()) und nach Gruppen (summarise(.by = )) berechnet.\nIn diesem Kapitel werden wir das Konzept der aufgeräumten Daten besprechen und sehen, wie wir unsere Daten organisieren und neu anordnen können, damit sie aufgeräumt sind."
  },
  {
    "objectID": "mats/09-wrangling_2.html#einrichtung",
    "href": "mats/09-wrangling_2.html#einrichtung",
    "title": "9  Data Wrangling 2",
    "section": "9.2 Einrichtung",
    "text": "9.2 Einrichtung\nWir brauchen die Pakete tidyverse, here, und janitor.\nWe’ll use the languageR_english.csv dataset (in daten folder)."
  },
  {
    "objectID": "mats/09-wrangling_2.html#tidy-arbeitsablauf",
    "href": "mats/09-wrangling_2.html#tidy-arbeitsablauf",
    "title": "9  Data Wrangling 2",
    "section": "9.3 ‘Tidy’ Arbeitsablauf",
    "text": "9.3 ‘Tidy’ Arbeitsablauf\nAbbildung 9.1 zeigt einen Überblick über den typischen Data-Science-Prozess, bei dem wir unsere Daten importieren, sie bereinigen und dann einen Zyklus von Umwandlung, Visualisierung und Modellierung durchlaufen, bevor wir schließlich unsere Ergebnisse mitteilen.\n\n\n\n\n\nAbbildung 9.1: Image source: Wickham et al. (2023) (all rights reserved)\n\n\n\n\nWir haben bereits gesehen, wie wir unsere Daten importieren (readr::read_csv), transformieren (Paket dplyr) und visualisieren (Paket ggplot) können. Aber wir haben bisher nur aufgeräumte Daten gesehen, so dass wir den Schritt “aufräumen” nicht durchführen mussten."
  },
  {
    "objectID": "mats/09-wrangling_2.html#tidy-daten",
    "href": "mats/09-wrangling_2.html#tidy-daten",
    "title": "9  Data Wrangling 2",
    "section": "9.4 ‘Tidy’ Daten",
    "text": "9.4 ‘Tidy’ Daten\nDieselben Daten können auf verschiedene Weise dargestellt werden. Die folgenden Datensätze zeigen alle dieselben Werte für vier Variablen: Land, Jahr, Bevölkerungszahl und Anzahl der Tuberkulosefälle. Jeder Datensatz ordnet die Werte anders an. Nehmen Sie sich einen Moment Zeit, um die verschiedenen Optionen zu betrachten. Welche ist am einfachsten zu lesen?\n\n\n\n\nTabelle 9.1: Tabelle 1\n\n\ncountry\nyear\ncases\npopulation\n\n\n\n\nAfghanistan\n1999\n745\n19987071\n\n\nAfghanistan\n2000\n2666\n20595360\n\n\nBrazil\n1999\n37737\n172006362\n\n\nBrazil\n2000\n80488\n174504898\n\n\nChina\n1999\n212258\n1272915272\n\n\nChina\n2000\n213766\n1280428583\n\n\n\n\n\n\n\n\n\n\n\n\nTabelle 9.2: Tabelle 2\n\n\ncountry\nyear\ntype\ncount\n\n\n\n\nAfghanistan\n1999\ncases\n745\n\n\nAfghanistan\n1999\npopulation\n19987071\n\n\nAfghanistan\n2000\ncases\n2666\n\n\nAfghanistan\n2000\npopulation\n20595360\n\n\nBrazil\n1999\ncases\n37737\n\n\nBrazil\n1999\npopulation\n172006362\n\n\nBrazil\n2000\ncases\n80488\n\n\nBrazil\n2000\npopulation\n174504898\n\n\nChina\n1999\ncases\n212258\n\n\nChina\n1999\npopulation\n1272915272\n\n\nChina\n2000\ncases\n213766\n\n\nChina\n2000\npopulation\n1280428583\n\n\n\n\n\n\n\n\n\n\n\n\nTabelle 9.3: Tabelle 3\n\n\ncountry\nyear\nrate\n\n\n\n\nAfghanistan\n1999\n745/19987071\n\n\nAfghanistan\n2000\n2666/20595360\n\n\nBrazil\n1999\n37737/172006362\n\n\nBrazil\n2000\n80488/174504898\n\n\nChina\n1999\n212258/1272915272\n\n\nChina\n2000\n213766/1280428583\n\n\n\n\n\n\n\n\nWahrscheinlich ist Tabelle 9.1 für Sie am einfachsten zu lesen. Das liegt daran, dass sie den drei Regeln für aufgeräumte Daten folgt (visualisiert in Abbildung 9.2):\n\nJede Variable ist eine Spalte, jede Spalte ist eine Variable\nJede Beobachtung ist eine Zeile, jede Zeile ist eine Beobachtung\nJeder Wert ist eine Zelle, jede Zelle ist ein Einzelwert\n\n\n\n\n\n\nAbbildung 9.2: Image source: Wickham et al. (2023) (all rights reserved)\n\n\n\n\nIn Tabelle 9.1 steht jede Spalte für eine Variable: country, year, population und case. Jede Zeile steht für eine einzelne Beobachtung: ein Land in einem bestimmten Jahr. Und schließlich enthält jede Zelle einen einzigen Wert.\n\n9.4.1 Warum ‘tidy’ Daten?\n\n“Glückliche Familien sind alle gleich; jede unglückliche Familie ist auf ihre eigene Art unglücklich.” — Leo Tolstoy\n\n\n“Saubere Datensätze sind alle gleich, aber jeder unordentliche Datensatz ist auf seine eigene Weise unordentlich.” — Hadley Wickham\n\nWenn Sie erst einmal ‘tidy’ Daten haben, verbringen Sie weniger Zeit mit dem Versuch, Ihre Daten in die richtige Form zu bringen, um das zu tun, was Sie wollen. Das Aufräumen von Daten erfordert im Vorfeld etwas Arbeit, ist aber langfristig gesehen hilfreich.\nDie Arbeit mit aufgeräumten Daten hat zwei wesentliche Vorteile:\n\nDie Arbeit mit einer einheitlichen Datenstruktur ermöglicht es uns, Konventionen zu übernehmen.\n\nDa aufgeräumte Daten die allgemein vereinbarte Datenstruktur sind, basieren die Konventionen auf der Annahme dieser Struktur.\nso haben die Werkzeuge eine zugrunde liegende Einheitlichkeit\n\nDie vektorisierte Natur von R kann glänzen\n\ndie meisten eingebauten R-Funktionen arbeiten mit Vektorwerten (und Spalten sind im Wesentlichen Vektoren)\nAlle Pakete im tidyverse sind darauf ausgelegt, mit aufgeräumten Daten zu arbeiten (z.B. ggplot2 und dplyr)\n\n\n\n\n\n\n\n\nRückblick: Vektoren\n\n\n\nVektoren sind der grundlegendste Datenobjekttyp in R. Ein Vektor enthält Daten desselben Typs und ist im Wesentlichen eine Liste. Sie können einen Vektor z.B. mit der Funktion c() erzeugen.\nVektor1 enthält numerische Werte, da alle Elemente Zahlen sind. vector2 wird alle Zeichenwerte (d.h. Text) enthalten, da es ein einziges eindeutiges Zeichenelement (\"x\") gibt. R liest also alle Elemente als Zeichentyp. Wir können einen Datenrahmen aus Vektoren gleicher Länge erstellen, indem wir z. B. die Funktion tibble() verwenden.\n\n\n# A tibble: 5 × 2\n  vector1 vector2\n    &lt;dbl&gt; &lt;chr&gt;  \n1       2 2      \n2       3 3      \n3       4 4      \n4       6 6      \n5       7 x      \n\n\n\n\nDie meisten Daten “in freier Wildbahn” sind unordentlich. Die Daten werden oft zunächst für ein anderes Ziel als die Analyse organisiert. Dieses Ziel ist in der Regel die Erleichterung der Dateneingabe: Wir wollen unsere Beobachtungen zunächst einfach dokumentieren können. Die meisten Menschen sind mit den Grundsätzen ordentlicher Daten nicht vertraut, und erst wenn sie viel Zeit mit Daten verbringen, wird klar, warum ordentliche Daten notwendig sind. Das bedeutet, dass die meisten echten Analysen zumindest ein gewisses Maß an Aufräumen erfordern.\n\n\n\n\n\n\nAufgabe 9.1: Tidy data\n\n\n\n\nBeispiel 9.1  \n\n\nGehen Sie zurück zu den Tabellen 1-3. Beschreiben Sie für jede Tabelle, was jede Beobachtung und jede Spalte darstellt.\nSkizzieren Sie das Verfahren, mit dem Sie die Rate für table1. berechnen würden. Sie brauchen nur ein Verb, das:\n\neine neue Variable erzeugt (nennen Sie sie rate), die Folgendes enthält:\n\ndie Anzahl der TB-Fälle (cases) pro Land und Jahr, geteilt durch\ndie entsprechende Bevölkerung (population) pro Land und Jahr,\nmultipliziert mit 10000\n\nHinweis: Welches dplyr-Verb erzeugt neue Variablen? (Sehen Sie sich das Kapitel 4 an.)\n\nSchauen Sie die Tabelle 9.2 und Tabelle 9.3 an. Wäre es so einfach gewesen, die rate mit diesen Datenstrukturen zu berechnen?"
  },
  {
    "objectID": "mats/09-wrangling_2.html#datenbereinigung",
    "href": "mats/09-wrangling_2.html#datenbereinigung",
    "title": "9  Data Wrangling 2",
    "section": "9.5 Datenbereinigung",
    "text": "9.5 Datenbereinigung\nDie Datenbereinigung besteht im Wesentlichen aus der Umwandlung breiter Daten in lange Daten und langer Daten in breite Daten (neben anderen Schritten). Das Ergebnis sind aufgeräumte Daten, bei denen jede Spalte eine Variable und jede Zeile eine Beobachtung darstellt. Wie genau wir eine Beobachtung definieren, hängt davon ab, was genau wir erreichen wollen, und kann sich von einem Analyseschritt zum anderen ändern.\n\n9.5.1 Datenaufräumung mit dem tidyverse\nDas Paket tidyr aus tidyverse hat zwei nützliche Funktionen zum Transponieren unserer Daten:\n\npivot_longer(): macht breite Daten länger\npivot_wider(): lange Daten breiter machen\n\nOft müssen wir zwischen diesen Formaten konvertieren, um verschiedene Arten von Zusammenfassungen oder Visualisierungen zu erstellen. Aber was genau sind breite und lange Daten?\n\n\n\n\n\nAbbildung 9.3: die berühmteste Verwendung des Wortes Pivot (zumindest für Millenials) (Friends)\n\n\n\n\n\n\n9.5.2 Breite versus lange Daten\nBei breiten Daten befinden sich alle Beobachtungen zu einer Sache in derselben Zeile. Breite Daten sind normalerweise nicht aufgeräumt. Bei langen Daten befindet sich jede Beobachtung in einer eigenen Zeile. Lange Daten sind normalerweise aufgeräumt. Beginnen wir mit dem typischsten Fall: der Umwandlung breiter Daten in lange Daten."
  },
  {
    "objectID": "mats/09-wrangling_2.html#verlängern-von-daten-df_eng",
    "href": "mats/09-wrangling_2.html#verlängern-von-daten-df_eng",
    "title": "9  Data Wrangling 2",
    "section": "9.6 Verlängern von Daten: df_eng",
    "text": "9.6 Verlängern von Daten: df_eng\n\nim Datensatz languageR_english.csv\n\njede Zeile ist eine Beobachtung\ndie erste Spalte beschreibt die Altersgruppe des Teilnehmers\ndie Spalten word, length_in_letters, written_frequency und word_category beschreiben Eigenschaften des Stimulus für eine bestimmte Beobachtung (d. h. das Wort)\nwir haben 4568 Beobachtungen\n\n\n\n\n\n\nTabelle 9.4: df_eng\n\n\nage_subject\nword\nlength_in_letters\nwritten_frequency\nword_category\nrt_lexdec\nrt_naming\n\n\n\n\nyoung\nace\n3\n4.219508\nN\n623.61\n456.3\n\n\nold\nace\n3\n4.219508\nN\n775.67\n607.8\n\n\nyoung\nact\n3\n8.118207\nV\n617.10\n445.8\n\n\nold\nact\n3\n8.118207\nV\n715.52\n639.7\n\n\nyoung\nadd\n3\n7.319203\nV\n575.70\n467.8\n\n\nold\nadd\n3\n7.319203\nV\n742.19\n605.4\n\n\n\n\n\n\n\n\n\nSind diese Daten in Tabelle 9.4 aufgeräumt?\nSind diese Daten zu breit oder zu lang?\nWie können wir diese Daten länger machen?\n\nOb wir diese Daten verlängern wollen oder nicht, hängt von der jeweiligen Aufgabe ab. Wenn wir die Antwortzeiten für die lexikalische Entscheidungsaufgabe (rt_lexdec) zusammen mit der Antwortzeit für die Benennungsaufgabe (rt_naming) aufzeichnen wollen, könnten wir die beiden in facet_wrap() einschließen. Allerdings nimmt facet_wrap() eine kategorische Variable als Argument und erzeugt Diagramme für jede Kategorie. Wir bräuchten eine neue Variable, zum Beispiel response, die die Stufen lexdec und naming enthält, und eine weitere, zum Beispiel time, die die Antwortzeit enthält. Versuchen wir das mal.\n\n9.6.1 pivot_longer()\nDie Funktion tidyr pivot_longer() konvertiert eine breite Datentabelle in ein längeres Format, indem sie die Überschriften der angegebenen Spalten in die Werte neuer Spalten umwandelt und die Werte dieser Spalten zu einer neuen, zusammengefassten Spalte kombiniert.\n\ndf_eng_long &lt;- \n  df_eng %&gt;% \n  pivot_longer(\n    cols = starts_with(\"rt_\"), \n    names_to = \"response\", \n    values_to = \"time\"\n  )\n\nDie Ausgabe der ersten 12 Zeilen (nach einigen zusätzlichen Formatierungen, um eine hübsche Tabelle zu erstellen) sollte wie Tabelle 9.5 aussehen.\n\ndf_eng_long %&gt;% \n  head(n = 12) %&gt;% \n  knitr::kable() %&gt;% \n  kableExtra::kable_styling(font_size = 20)\n\n\n\nTabelle 9.5: A pivoted version of df_billboard (first 10 rows)\n\n\nage_subject\nword\nlength_in_letters\nwritten_frequency\nword_category\nresponse\ntime\n\n\n\n\nyoung\nace\n3\n4.219508\nN\nrt_lexdec\n623.61\n\n\nyoung\nace\n3\n4.219508\nN\nrt_naming\n456.30\n\n\nold\nace\n3\n4.219508\nN\nrt_lexdec\n775.67\n\n\nold\nace\n3\n4.219508\nN\nrt_naming\n607.80\n\n\nyoung\nact\n3\n8.118207\nV\nrt_lexdec\n617.10\n\n\nyoung\nact\n3\n8.118207\nV\nrt_naming\n445.80\n\n\nold\nact\n3\n8.118207\nV\nrt_lexdec\n715.52\n\n\nold\nact\n3\n8.118207\nV\nrt_naming\n639.70\n\n\nyoung\nadd\n3\n7.319203\nV\nrt_lexdec\n575.70\n\n\nyoung\nadd\n3\n7.319203\nV\nrt_naming\n467.80\n\n\nold\nadd\n3\n7.319203\nV\nrt_lexdec\n742.19\n\n\nold\nadd\n3\n7.319203\nV\nrt_naming\n605.40\n\n\n\n\n\n\n\n\nNehmen wir uns einen Moment Zeit, um die Werte in Tabelle 9.5 mit denen der ersten 6 Zeilen in df_eng zu vergleichen, die in Tabelle 9.4 angegeben sind. Vergleichen Sie die Werte in der df_eng-Variablen rt_lexdec (Tabelle 9.4) mit den time-Werten, wenn response rt_lexdec (Tabelle 9.5) ist: Sie sind identisch. Was ist nun mit rt_naming sowohl in Tabelle 9.4 als auch in Tabelle 9.5? Sie sind ebenfalls identisch. Dies ist eine wichtige Erkenntnis: Wir haben keine Daten oder Beobachtungswerte geändert, sondern lediglich die Organisation der Datenpunkte neu strukturiert.\nWie hat pivot_longer() das gemacht? Hier ist eine Aufschlüsselung der Argumente, die pivot_longer() benötigt (die Sie auch durch Ausführen von ?pivot_longer in der Konsole untersuchen können):\n\ncol = gibt an, welche Spalten gepivotet werden müssen (sollte eine kategorische Variable sein)\n\nnimmt die gleiche Syntax wie select(), also könnten wir z.B. starts_with(\"\") verwenden\n\nnames_to = benennt die Variable, die in den aktuellen Spaltennamen gespeichert ist, hier ist es response\nvalues_to = benennt die in den Zellwerten gespeicherte Variable, die wir time nennen\nN.B., wir mussten response und time in Anführungszeichen setzen, weil sie noch keine Variablennamen sind.\n\n\n9.6.1.1 Plotten unserer ‘tidy’ Daten\nDa wir nun die response-Daten in einer Variable und die time-Daten in einer anderen Variable haben, wollen wir versuchen, ein Diagramm zu erstellen, in dem wir age_subject auf der x-Achse, time auf der y-Achse und response auf der y-Achse haben.\n\n\n\n\n\nAbbildung 9.4: Response times per age group for the lexical decision task vs. naming task\n\n\n\n\n\n\n\n\n\n\nAufgabe 9.1: Tidy data\n\n\n\n\nBeispiel 9.2  \n\nAbbildung 9.4 neu erstellen."
  },
  {
    "objectID": "mats/09-wrangling_2.html#verbreiterung-der-daten-df_eng",
    "href": "mats/09-wrangling_2.html#verbreiterung-der-daten-df_eng",
    "title": "9  Data Wrangling 2",
    "section": "9.7 Verbreiterung der Daten: df_eng",
    "text": "9.7 Verbreiterung der Daten: df_eng\nDie tidyr-Funktion pivot_wider() macht Datensätze breiter, indem sie Spalten vergrößert und Zeilen verkleinert. Dies ist hilfreich, wenn eine Beobachtung über mehrere Zeilen verteilt ist. Obwohl diese Art von Daten in der freien Wildbahn nicht sehr häufig vorkommt, ist sie zum Beispiel bei Regierungsdaten ziemlich verbreitet.\nWir können wieder mit df_eng beginnen, um die Daten zu erweitern. Zum Beispiel könnten wir eine einzelne Zeile pro Wort haben, die eine einzelne Variable für die Antwort des “jungen” Probanden und die Antwort des “alten” Probanden enthält.\n\n9.7.1 pivot_wider()\nPivot wider nimmt ähnliche Argumente wie pivot_longer(), mit einigen leichten Unterschieden (z.B. ?pivot_wider):\n\nid_cols: identifizierende Spalten (welche Spalten identifizieren jede Beobachtung eindeutig?)\nnames_from: wie soll die neue Spalte heißen, die die vorherigen Spaltennamen enthält (muss eine kategorische Variable sein)?\nnames_prefix: Präfix für die neuen Spaltennamen (optional)\nWerte_von`: neue Spaltenwerte\n\nErstellen wir zwei neue Variablen, die ihre Namen von age_subject und ihre Werte von rt_lexdec übernehmen. Das Ergebnis sollte wie ?tbl-eng_wider aussehen.\n\n\n\n\nTabelle 9.6: Wider df_eng data\n\n\nword\nlength_in_letters\nwritten_frequency\nword_category\nlexdec_young\nlexdec_old\n\n\n\n\nace\n3\n4.219508\nN\n623.61\n775.67\n\n\nact\n3\n8.118207\nV\n617.10\n715.52\n\n\nadd\n3\n7.319203\nV\n575.70\n742.19\n\n\nage\n3\n8.397959\nN\n592.42\n748.37\n\n\naid\n3\n6.927558\nV\n541.67\n824.76\n\n\naide\n4\n4.615120\nN\n693.50\n895.29\n\n\n\n\n\n\n\n\nTabelle 9.7 zeigt wieder die ersten 6 Zeilen des Originaldatensatzes. Wie werden die Daten aus Tabelle 9.6 in Tabelle 9.7 dargestellt?\n\n\n\n\nTabelle 9.7: head(df_eng, n = 6)\n\n\nage_subject\nword\nlength_in_letters\nwritten_frequency\nword_category\nrt_lexdec\nrt_naming\n\n\n\n\nyoung\nace\n3\n4.219508\nN\n623.61\n456.3\n\n\nold\nace\n3\n4.219508\nN\n775.67\n607.8\n\n\nyoung\nact\n3\n8.118207\nV\n617.10\n445.8\n\n\nold\nact\n3\n8.118207\nV\n715.52\n639.7\n\n\nyoung\nadd\n3\n7.319203\nV\n575.70\n467.8\n\n\nold\nadd\n3\n7.319203\nV\n742.19\n605.4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarnung\n\n\n\n\n\n\nWo ist rt_naming geblieben? Wir haben es entfernt, weil es ebenfalls einen einzigen Wert pro Wort und Altersgruppe hat. Wenn wir es nicht entfernen, bedeutet das, dass wir die Länge unseres Datensatzes nicht ändern (immer noch eine Zeile pro Wort und Altersgruppe), sondern nur die Breite und die Einführung von NA-Werten für lexdec_young für alte Probanden und NA-Werten für lexdec_old für junge Probanden. Hätten wir sie nicht entfernt, sähen unsere ersten 6 Zeilen wie Tabelle 9.8 aus. Vergleichen Sie dies mit der Ausgabe in Tabelle 9.6, sehen Sie den Unterschied?\n\n\n\n\nTabelle 9.8: Wider data with missing values\n\n\nword\nlength_in_letters\nwritten_frequency\nword_category\nrt_naming\nlexdec_young\nlexdec_old\n\n\n\n\nace\n3\n4.219508\nN\n456.3\n623.61\nNA\n\n\nace\n3\n4.219508\nN\n607.8\nNA\n775.67\n\n\nact\n3\n8.118207\nV\n445.8\n617.10\nNA\n\n\nact\n3\n8.118207\nV\n639.7\nNA\n715.52\n\n\nadd\n3\n7.319203\nV\n467.8\n575.70\nNA\n\n\nadd\n3\n7.319203\nV\n605.4\nNA\n742.19"
  },
  {
    "objectID": "mats/09-wrangling_2.html#lernziele-1",
    "href": "mats/09-wrangling_2.html#lernziele-1",
    "title": "9  Data Wrangling 2",
    "section": "Lernziele 🏁",
    "text": "Lernziele 🏁\nIn diesem Kapitel haben wir gelernt…\n\nüber breite versus lange Daten ✅\nwie man breite Daten länger macht ✅\nwie man lange Daten breiter macht ✅"
  },
  {
    "objectID": "mats/09-wrangling_2.html#hausaufgaben",
    "href": "mats/09-wrangling_2.html#hausaufgaben",
    "title": "9  Data Wrangling 2",
    "section": "9.8 Hausaufgaben",
    "text": "9.8 Hausaufgaben\nFür diese Aufgaben werden wir mit dem Datensatz df_eng arbeiten.\n\nVerwenden Sie pivot_wider, um mit rt_naming neue Variablen zu erstellen: naming_old und naming_young, die die Reaktionszeiten beim Benennen für alte bzw. junge Teilnehmer enthalten. Hinweis: Sie müssen rt_lexdec entfernen. Der resultierende Datenrahmen sollte 2284 Beobachtungen und 6 Variablen enthalten.\nErstellen Sie Abbildung 9.5 neu. Hinweis: Sie benötigen pivot_wider().\n\n\n\n\n\n\nAbbildung 9.5: Scatterplot of lexical decision task response times per word for old versus young participants\n\n\n\n\n\nWarum brauchen wir unseren df_eng_wide-Datensatz, um Abbildung 9.5 zu erstellen? Mit anderen Worten, warum ist df_eng_wide die geeignete Struktur, aber nicht df_eng_long für ein solches Streudiagramm?\nBenutze df_eng_long und die Funktion summarise(), die wir im letzten Abschnitt gesehen haben, und reproduziere die folgende Zusammenfassung:\n\n\n\n# A tibble: 2 × 3\n  response   mean    sd\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 rt_lexdec  708.  115.\n2 rt_naming  566.  101.\n\n\nHinweis: Müssen Sie NA entfernen (wir haben im letzten Kapital gesehen, wie man das macht)?"
  },
  {
    "objectID": "mats/09-wrangling_2.html#session-info",
    "href": "mats/09-wrangling_2.html#session-info",
    "title": "9  Data Wrangling 2",
    "section": "Session Info",
    "text": "Session Info\nHergestellt mit R version 4.3.0 (2023-04-21) (Already Tomorrow) und RStudioversion 2023.9.0.463 (Desert Sunflower).\n\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] janitor_2.2.0   here_1.0.1      lubridate_1.9.2 forcats_1.0.0  \n [5] stringr_1.5.0   dplyr_1.1.3     purrr_1.0.2     readr_2.1.4    \n [9] tidyr_1.3.0     tibble_3.2.1    ggplot2_3.4.3   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.3        generics_0.1.3    xml2_1.3.4        stringi_1.7.12   \n [5] hms_1.1.3         digest_0.6.33     magrittr_2.0.3    evaluate_0.21    \n [9] grid_4.3.0        timechange_0.2.0  fastmap_1.1.1     rprojroot_2.0.3  \n[13] jsonlite_1.8.7    httr_1.4.6        rvest_1.0.3       fansi_1.0.4      \n[17] viridisLite_0.4.2 scales_1.2.1      cli_3.6.1         rlang_1.1.1      \n[21] crayon_1.5.2      bit64_4.0.5       munsell_0.5.0     withr_2.5.0      \n[25] yaml_2.3.7        tools_4.3.0       parallel_4.3.0    tzdb_0.4.0       \n[29] colorspace_2.1-0  webshot_0.5.4     pacman_0.5.1      kableExtra_1.3.4 \n[33] vctrs_0.6.3       R6_2.5.1          magick_2.7.4      lifecycle_1.0.3  \n[37] snakecase_0.11.0  htmlwidgets_1.6.2 bit_4.0.5         vroom_1.6.3      \n[41] pkgconfig_2.0.3   pillar_1.9.0      gtable_0.3.4      Rcpp_1.0.11      \n[45] glue_1.6.2        systemfonts_1.0.4 highr_0.10        xfun_0.39        \n[49] tidyselect_1.2.0  rstudioapi_0.14   knitr_1.44        farver_2.1.1     \n[53] htmltools_0.5.5   labeling_0.4.3    svglite_2.1.1     rmarkdown_2.22   \n[57] compiler_4.3.0"
  },
  {
    "objectID": "mats/09-wrangling_2.html#literaturverzeichnis",
    "href": "mats/09-wrangling_2.html#literaturverzeichnis",
    "title": "9  Data Wrangling 2",
    "section": "Literaturverzeichnis",
    "text": "Literaturverzeichnis\n\n\nNordmann, E., & DeBruine, L. (2022). Applied Data Skills. Zenodo. https://doi.org/10.5281/zenodo.6365078\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for Data Science (2. Aufl.)."
  },
  {
    "objectID": "mats/10-dataviz_3.html#lernziele",
    "href": "mats/10-dataviz_3.html#lernziele",
    "title": "10  Datenvisualisierung 3",
    "section": "Lernziele",
    "text": "Lernziele\nIn diesem Kapital lernen wir wie man…\n\nBoxplots zu erstellen und zu interpretieren\nMittelwerte und Standardabweichungen zu visualisieren"
  },
  {
    "objectID": "mats/10-dataviz_3.html#ressourcen",
    "href": "mats/10-dataviz_3.html#ressourcen",
    "title": "10  Datenvisualisierung 3",
    "section": "Ressourcen",
    "text": "Ressourcen\nFür weitere Lektüre und Übungen zu diesem Thema empfehle ich die Lektüre von Abschnitt 2.5 (Visualisierung von Relationen) in Wickham et al. (2023), Kapitel 4 (Darstellung von zusammenfassenden Statistiken) in Nordmann et al. (2022) und die Abschnitte 3.5-3.9 in Winter (2019)."
  },
  {
    "objectID": "mats/10-dataviz_3.html#einrichten",
    "href": "mats/10-dataviz_3.html#einrichten",
    "title": "10  Datenvisualisierung 3",
    "section": "Einrichten",
    "text": "Einrichten\n\nPakete\nWie üblich laden wir die tidyverse Familie von Paketen. Um uns beim Laden unserer Daten zu helfen, laden wir auch das here-Paket und das janitor-Paket, das nützlich ist, um unsere Daten aufzuräumen (z.B. die clean_names()-Funktion). Um unsere Diagramme anzupassen, verwenden wir auch die Pakete ggthemes und patchwork. Ersteres hilft uns bei der Erstellung von farbenblindenfreundlichen Diagrammen, während letzteres uns erlaubt, mehrere Diagramme zusammen zu drucken.\n\npacman::p_load(tidyverse,\n               here,\n               janitor,\n               ggthemes,\n               patchwork)\n\n\n\nDaten\nWir arbeiten wieder mit unserer leicht veränderten Version des english-Datensatzes aus dem languageR-Paket. Sie sollten langaugeR_english.csv in Ihrem Daten Ordner haben. Der folgende Code lädt den Datensatz, bereinigt die Namen und korrigiert einige fehlerhafte Namen.\n\ndf_eng &lt;- read_csv(\n  here(\n    \"daten\",\n    \"languageR_english.csv\"\n  )\n) |&gt; \n  clean_names() |&gt; \n  rename(\n    rt_lexdec = r_tlexdec,\n    rt_naming = r_tnaming\n  )"
  },
  {
    "objectID": "mats/10-dataviz_3.html#rückblick-visualisierung-von-verteilungen",
    "href": "mats/10-dataviz_3.html#rückblick-visualisierung-von-verteilungen",
    "title": "10  Datenvisualisierung 3",
    "section": "10.1 Rückblick: Visualisierung von Verteilungen",
    "text": "10.1 Rückblick: Visualisierung von Verteilungen\nWir haben bereits mehrere Arten von Diagrammen gesehen, die zur Visualisierung der Verteilung und der Beziehungen zwischen Variablen verwendet werden:\n\nHistogramme (1 numerische Variable)\nDichteplots (1 numerische Variable)\nStreudiagramme (2 numerische Variablen)\nBalkendiagramme (kategorische Variablen)\n\nSchauen Sie sich jede Abbildung in Abbildung 10.1 an. Wie viele Variablen werden jeweils dargestellt, und um welche Typen von Variablen handelt es sich? Welche zusammenfassende(n) Statistik(en) wird/werden in jedem Diagramm dargestellt?\n\n\n\n\n\nAbbildung 10.1: Verschiedene Diagrammtypen zur Visualisierung der Verteilung von Rohdaten: Histogramm (A), Dichte-Diagramm (B), Streudiagramm (C), gestapeltes Balkendiagramm (D) und unscharfes Balkendiagramm (E)"
  },
  {
    "objectID": "mats/10-dataviz_3.html#darstellung-von-zusammenfassenden-statistiken",
    "href": "mats/10-dataviz_3.html#darstellung-von-zusammenfassenden-statistiken",
    "title": "10  Datenvisualisierung 3",
    "section": "10.2 Darstellung von zusammenfassenden Statistiken",
    "text": "10.2 Darstellung von zusammenfassenden Statistiken\nIn Kapitel 8 haben wir etwas über zusammenfassende Statistiken gelernt. Wir behandelten Maße der zentralen Tendenz, nämlich Modus, Median und Mittelwert, sowie Maße der Streuung, wie Bereich und Standardabweichung. Wie können wir zusammenfassende Statistiken visualisieren?\nWir haben bereits gesehen, dass Histogramme, Dichtediagramme und nun auch Geigenplots den Modus (höchster Wert) und den Bereich (niedrigster und höchster Wert) visualisieren. Jetzt lernen wir zwei weitere Arten von Diagrammen kennen, eines zur Darstellung der Verteilung der beobachteten Werte und eines zur Darstellung von Mittelwert und Standardabweichung.\n\n10.2.1 Boxplot\nBoxplots (manchmal auch Box-and-Whisker-Plots genannt, z. B. Abbildung 10.2) bestehen aus einer Box mit einer Linie in der Mitte (die “Box”) und Linien, die an beiden Enden der Box herausragen (die “Whisker”), sowie manchmal einigen Punkten. Schauen Sie sich Abbildung 10.2 an und identifizieren Sie jeden dieser 4 Aspekte der Darstellung. Kannst du erraten, was jeder dieser Aspekte darstellen könnte und wie du die Darstellung interpretieren solltest?\n\n\n\n\n\nAbbildung 10.2: Boxplot von df_eng (Körpermasse nach Alter_Proband)\n\n\n\n\nDie Box und die Whiskers stellen eine Vielzahl von Informationen in einer einzigen Visualisierung dar. Die Linie in der Mitte des Boxplots stellt den Median dar, auch Q2 genannt (2. Quartil; der mittlere Wert, über/unter dem 50% der Daten liegen). Die Box selbst stellt den Interquartilsbereich (IQR; der Wertebereich, der zwischen den mittleren 50% der Daten liegt) dar. Die Grenzen der Box stellen Q1 (1. Quartil, unter dem 25% der Daten liegen) und Q3 (3. Quartil, über dem 25% der Daten liegen) dar. Die Whisker stellen 1,5*IQR von Q1 (unterer Whisker) oder Q3 (oberer Whisker) dar. Alle Punkte, die außerhalb der Whisker liegen, stellen Ausreißer dar (d. h. Extremwerte, die außerhalb des IQR liegen).\nAbbildung 10.3 zeigt die Beziehung zwischen der Verteilung einer Variablen, wie sie in einem Histogramm dargestellt wird, und einem Boxplot. Während das Histogramm die Balkenhöhe verwendet, um die Anzahl der Beobachtungen innerhalb eines bestimmten Bereichs anzuzeigen, verwendet der Boxplot die Box und die Whiskers, um die Schwellenwerte anzugeben, in denen bestimmte Anteile der Daten enthalten sind (d. h. der Interquartilsbereich).\n\n\n\n\n\nAbbildung 10.3: Image source: Winter (2019) (all rights reserved)\n\n\n\n\nAbbildung 10.4 bietet einen ähnlichen Vergleich, wobei die einzelnen Beobachtungen im Streudiagramm auf der linken Seite hinzugefügt wurden.\n\n\n\n\n\nAbbildung 10.4: Image source: Wickham et al. (2023) (all rights reserved)\n\n\n\n\nIch hoffe, Sie haben jetzt ein wenig verstanden, wie man Boxplots interpretiert. Man braucht etwas Übung, aber das Wichtigste ist, sich daran zu erinnern, dass die mittleren 50% der Daten in der Box enthalten sind, während die “Schwänze” der Daten durch die “Whisker” dargestellt werden.\n\n10.2.1.1 geom_boxplot()\nWir können Boxplots mit der Funktion geom_boxplot() von ggplot2 erstellen. Zumindest müssen wir eine numerische Variable als x oder y Achse angeben (Abbildung 10.5). Wenn wir Boxplots für verschiedene Gruppen erstellen wollen, können wir den Namen einer kategorischen Variable auf der anderen Achse angeben (Abbildung 10.6).\n\ndf_eng |&gt; \n  ggplot(aes(y = rt_lexdec)) +\n  geom_boxplot() +\n  theme_bw() +\n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n\n\n\nAbbildung 10.5: Ein Boxplot für alle Beobachtungen einer kontinuierlichen Variablen\n\n\n\n\n\ndf_eng |&gt; \n  ggplot(aes(x = age_subject, y = rt_lexdec)) +\n  geom_boxplot() +\n  theme_bw()\n\n\n\n\nAbbildung 10.6: Ein Boxplot für zwei Gruppen\n\n\n\n\n\n\n10.2.1.2 Gruppierter Boxplot\nGenau wie ein Bargraph können wir gruppierte Boxplots erstellen, um mehr Variablen zu visualisieren. Ordnen Sie einfach eine neue Variable mit colour oder fill ästhetisch zu.\n\ndf_eng |&gt; \n  ggplot(aes(x = age_subject, y = rt_lexdec, colour = word_category)) +\n  geom_boxplot() +\n  labs(\n    x = \"Altersgruppe\",\n    y = \"LDT-Reaktionszeit (ms)\",\n    color = \"Wortart\"\n  ) +\n  scale_colour_colorblind() +\n  theme_bw()\n\n\n\n\nEin gruppierter Boxplot\n\n\n\n\n\n\n\n\n\n\nBoxplots in R\n\n\n\nMit der Funktion boxplot(), die einen kontinuierlichen (d.h. numerischen) Vektor als Argument akzeptiert, kann ein Boxplot in der Base-R-Syntax erstellt werden. Da Datenrahmen eine Ansammlung von Vektoren (d.h. die Variablen/Spalten) gleicher Länge sind, können wir auch eine kontinuierliche Variable in einem Datenrahmen als Argument verwenden. Dazu verwenden wir den Subsetting-Operator $, der einen Datenrahmen in eine einzelne Variable, in unserem Fall rt_lexdec, unterteilt.\n\nboxplot(df_eng$rt_lexdec)\n\n\n\n\nAbbildung 10.7: Boxplot erstellt mit Basis R\n\n\n\n\nWir können auch eine kategoriale Variable als “Prädiktor” verwenden, mit der Syntax kontinuierlich ~ kategorisch, wobei ~ als “vorhergesagt von” gelesen werden kann.\n\nboxplot(df_eng$rt_lexdec ~ df_eng$age_subject)\n\n\n\n\nAbbildung 10.8: Boxplot erstellt mit Basis R"
  },
  {
    "objectID": "mats/10-dataviz_3.html#visualisierung-des-mittelwerts",
    "href": "mats/10-dataviz_3.html#visualisierung-des-mittelwerts",
    "title": "10  Datenvisualisierung 3",
    "section": "10.3 Visualisierung des Mittelwerts",
    "text": "10.3 Visualisierung des Mittelwerts\nBoxplots zeigen ein Maß für die zentrale Tendenz (Median) und mehrere Maße für die Streuung. In der Regel wird auch der Mittelwert mit der Standardabweichung dargestellt.1. Wie könnte man dies tun?\n\n10.3.1 Fehlerbalken-Diagramme\nFehlerbalkendiagramme werden üblicherweise verwendet, um den Mittelwert und die Standardabweichung mit Hilfe von Fehlerbalken zu visualisieren. Auch hier werden in der Regel Standardfehler oder Konfidenzintervalle (oder glaubwürdige Intervalle) durch Fehlerbalken dargestellt, die wir in diesem Kurs jedoch nicht behandeln werden. Diese Diagramme bestehen aus zwei Teilen: dem Mittelwert, der mit geom_point() dargestellt wird, und der Standardabweichung, die mit geom_errorbar() dargestellt wird. Die Fehlerbalken stellen den Bereich von 1 Standardabweichung über und unter dem Mittelwert dar (Mittelwert +/- 1SD).\n\n\n\n\n\nAbbildung 10.9: Fehlerbalken-Diagramm von df_eng (Körpermasse nach Alter_Proband)\n\n\n\n\nEs gibt einige Möglichkeiten, Fehlerbalken-Diagramme zu erstellen, aber wir werden uns auf die Verwendung von ggplot2 und die Erstellung von zusammenfassenden Statistiken konzentrieren, wie wir sie in Kapitel 8 mit der Funktion summarise() von dplyr gesehen haben.\n\n10.3.1.1 Berechnung der zusammenfassenden Statistik\nZunächst müssen wir den Mittelwert und die Standardabweichung berechnen, gruppiert nach den Variablen, die wir visualisieren wollen. Bleiben wir bei rt_lexdec nach age_subject. Wie können wir den Mittelwert und die Standardabweichung von rt_lexdec nach age_subject berechnen?\n\n\nClick here to see how\ndf_eng |&gt; \n  summarise(mean = mean(rt_lexdec),\n            sd = sd(rt_lexdec),\n            N = n(),\n            .by = age_subject) |&gt; \n  arrange(age_subject)\n\n\n# A tibble: 2 × 4\n  age_subject  mean    sd     N\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 old          787.  96.2  2284\n2 young        630.  69.1  2284\n\n\nUm zusammenfassende Statistiken zu erstellen, können wir entweder den obigen Code direkt in ein ggplot-Objekt einfügen, indem wir eine Pipe verwenden, oder wir können die Zusammenfassung als ein Objekt speichern, das wir dann in ggplot einfügen. Beide Optionen erzeugen das gleiche Diagramm, wie wir unten sehen.\n\nNeues ObjektWith a pipe\n\n\n\n## Neues Objekt mit Zusammenfassungen erstellen\nsum_eng &lt;- df_eng |&gt; \n  summarise(mean = mean(rt_lexdec),\n            sd = sd(rt_lexdec),\n            N = n(),\n            .by = age_subject) |&gt; \n  arrange(age_subject, age_subject)\n\n## Neues Objekt in ggplot einfügen\nsum_eng |&gt; \n  ggplot(aes(x = age_subject, y = mean, colour = age_subject)) \n\n\n\n\n\n\n\ndf_eng |&gt; \n  summarise(mean = mean(rt_lexdec),\n            sd = sd(rt_lexdec),\n            N = n(),\n            .by = age_subject) |&gt; \n  arrange(age_subject, age_subject) |&gt; \n  arrange(age_subject, age_subject) |&gt; \n  ggplot() +\n  aes(x = age_subject, y = mean, colour = age_subject)\n\n\n\n\n\n\n\nIch neige dazu, eine Mischung aus diesen beiden Optionen zu verwenden. Manchmal erstelle ich ein neues Objekt und manchmal nicht, je nachdem, was für meinen Arbeitsablauf am sinnvollsten ist. In den Fällen, in denen ich die zusammenfassenden Statistiken auch drucken oder im Auge behalten möchte, würde ich ein Objekt erstellen, das die Zusammenfassung enthält. Dies hat den zusätzlichen Vorteil, dass es mit zusätzlichen Formatierungen gedruckt werden kann, um eine schöne Tabelle zu erstellen (wie Tabelle 10.1).\n\n\n\n\nTabelle 10.1: Formatierte Tabelle von sum_eng\n\n\nAltersgruppe\nMittlere LDT (ms)\nSD\nN\n\n\n\n\nold\n786.7\n96.2\n2284\n\n\nyoung\n629.5\n69.1\n2284\n\n\n\n\n\n\n\n\n\n\n10.3.1.2 Plotten von Mittelwerten\nAber alles, was wir bis jetzt haben, ist eine leere Leinwand, wir müssen unsere geoms hinzufügen. Zuerst fügen wir die Mittelwerte mit geom_point() ein.\n\nsum_eng |&gt; \n  ggplot() +\n  aes(x = age_subject, y = mean) +\n  geom_point()\n\n\n\n\n\n\n10.3.1.3 Hinzufügen von Fehlerbalken\nFügen wir nun unsere Fehlerbalken hinzu, die eine Standardabweichung über und unter dem Mittelwert darstellen. Wir tun dies mit geom_errorbar(), das ymin und ymax als Argumente benötigt. Diese sind jeweils gleich mean-/+sd. Wir haben sie der Übersichtlichkeit halber in einen weiteren aes()-Aufruf innerhalb von geom_errorbar() eingefügt, aber sie könnten auch im ersten aes()-Aufruf erscheinen.\n\nsum_eng |&gt; \n  ggplot() +\n  aes(x = age_subject, y = mean) +\n  geom_point() +\n  geom_errorbar(aes(ymin = mean-sd, \n                    ymax = mean+sd)) +\n  theme_bw()\n\n\n\n\nHier sehen wir also den Mittelwert mit +/-1SD für die älteren und jüngeren Teilnehmergruppen. Und wenn wir einige weitere Anpassungen hinzufügen, erhalten wir ?fig-errorbar-custom.\n\nsum_eng |&gt; \n  ggplot() +\n  aes(x = age_subject, y = mean, colour = age_subject, shape = age_subject) +\n  labs(title = \"Mittlere LDT-Zeiten (+/-1SD)\",\n    x = \"Altersgruppe\",\n    y = \"Reaktionszeit (ms)\",\n    color = \"Altersgruppe\"\n  ) +\n  geom_point(size = 3) +\n  geom_errorbar(width = .5, aes(ymin=mean-sd, ymax=mean+sd)) +\n  scale_color_colorblind() +\n  theme_bw() +\n  theme(\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\n\nstat_summary()\n\n\n\nIn ggplot2 gibt es eine weitere nützliche Funktion, mit der zusammenfassende Statistiken visualisiert werden können, ohne dass zuvor mit dplyr::sumarise() Zusammenfassungen erstellt werden müssen. Die Funktion stat_summary() erlaubt es uns, zusammenfassende Statistiken direkt in unserem ggplot()-Objekt zu erstellen, was bedeutet, dass wir mehrere zusammenfassende Statistiken im selben Plot darstellen können (was wir noch nicht tun werden…).\nDie Funktion stat_summary() benötigt mindestens zwei Argumente: stat =, das ist der Typ der Statistik, die man darstellen möchte, und geom =, das ist der Typ des geom, mit dem man es visualisieren möchte. Wir können Mittelwerte leicht mit Punkten (Abbildung 10.10) oder einem Balkenplot (Abbildung 10.11) darstellen, obwohl ich dringend empfehle, Balkenplots zu vermeiden, wenn ein Punktwert wie ein Mittelwert dargestellt werden soll.\n\ndf_eng |&gt; \n  ggplot() +\n  aes(x = age_subject, y = rt_lexdec, colour = age_subject) +\n  stat_summary(fun = \"mean\", geom = \"point\") +\n  labs(title = 'geom = \"point\"')\n\n\n\n\nAbbildung 10.10: stat_summary(stat_summary(fun = \"mean\", geom = \"point\"))\n\n\n\n\n\ndf_eng |&gt; \n  ggplot() +\n  aes(x = age_subject, y = rt_lexdec, fill = age_subject) +\n  stat_summary(fun = \"mean\", geom = \"bar\") +\n  labs(title = 'geom = \"bar\"')\n\n\n\n\nAbbildung 10.11: stat_summary(stat_summary(fun = \"mean\", geom = \"bar\"))\n\n\n\n\nWir können auch Fehlerbalken mit stat_summary() einfügen, wie in Abbildung 10.12. Dies erzeugt doppelte Standardabweichungen, so dass wir die fun.args =-Werte einfügen müssen, um anzugeben, dass wir einfache Standardabweichungen visualisieren wollen.\n\ndf_eng |&gt; \n  ggplot() +\n  aes(x = age_subject, y = rt_lexdec, colour = age_subject) +\n  stat_summary(fun = \"mean\", geom = \"point\") +\n  stat_summary(fun.data = \"mean_sdl\",\n               geom = \"errorbar\",\n               fun.args = list (mult = 1)) +\n  labs(title = 'Fehlerbalken-Darstellung mit `stat_summary()`') +\n  theme_bw()\n\n\n\n\nAbbildung 10.12: stat_summary(fun.data = \"mean_sdl\", geom = \"errorbar\",...\n\n\n\n\nWie Sie sehen können, ist das Hinzufügen von Fehlerbalken mit stat_summary() etwas weniger einfach, weshalb wir uns für den Weg summarise() |&gt; ggplot() + ... entschieden haben. Ein zusätzlicher Vorteil der Verwendung von summarise() ist, dass Sie Ihre Zusammenfassung als Tibble (d.h. als Tabelle oder Datenrahmen) speichern können, die zusätzlich zum Plot gedruckt werden kann (wie wir mit Tabelle 9.4 gesehen haben). Ich habe erst vor ein oder zwei Jahren begonnen, dplyr::summarise() anstelle von ggplot2::stat_summary() zu verwenden, und bevorzuge Ersteres, weil ich dann die berechneten Werte vor dem Plotten überprüfen kann. Dies ist eine Frage der persönlichen Vorliebe, wenn Sie also neugierig sind, schlage ich vor, dass Sie stat_summary() ausprobieren, um zu sehen, ob Sie eine Vorliebe haben. Wenn Sie mehr über stat_summary() erfahren wollen, können Sie ?stat_summary in der Console eingeben oder nach Tutorials oder YouTube-Videos googeln, es gibt viele davon.\n\n\n\n\n\n10.3.2 Balkendiagramm der Mittelwerte: Finger weg!\nIch flehe Sie an, nicht Mittelwerte mit Balkendiagramme darzustellen! Sie werden sehr oft Balkendiagramme von Mittelwerten sehen, und andere unterrichten dies vielleicht sogar in anderen Kursen, aber es gibt viele Gründe, warum dies eine schlechte Idee ist!!!\nErstens können sie sehr irreführend sein. Sie beginnen bei 0 und vermitteln den Eindruck, dass die Daten beim Mittelwert enden, obwohl etwa die Hälfte der Daten (normalerweise) über dem Mittelwert liegt.\nAußerdem hat der Balkenplot ein schlechtes Daten-Tinten-Verhältnis, d. h. die Menge der Datentinte geteilt durch die Gesamttinte, die zur Erstellung der Grafik benötigt wird, oder die Menge der Tinte, die entfernt werden kann, ohne dass Informationen verloren gehen. Beispielsweise beginnen Balkenplots normalerweise bei Null und enden beim Mittelwert. Was aber, wenn es nur sehr wenige oder gar keine Beobachtungen in der Nähe von Null gibt? Wir verbrauchen eine Menge Tinte, wo es keine Beobachtungen gibt! Ein ebenso abscheuliches Verbrechen ist, dass der Balken nur den Bereich abdeckt, in dem die untere Hälfte der Beobachtungen liegt; ebenso viele Beobachtungen liegen über dem Mittelwert!\nMeiner Meinung nach sollten Balkendiagramme nur für Zählungen oder Häufigkeiten verwendet werden. Abgesehen davon sind Fehlerbalken allein nicht die Lösung. Die Darstellung nur des Mittelwerts und der Standardabweichung (oder des Standardfehlers/des Konfidenzintervalls/der glaubwürdigen Intervalle) verbirgt eine Menge Informationen über die tatsächliche Streuung und Verteilung der Daten. Erinnern Sie sich an das Paket datasauRus, das Datensätze mit ähnlichen Mittelwerten, Standardabweichungen und Anzahl der Beobachtungen, aber sehr unterschiedlichen Verteilungen enthält. Abbildung 10.13 zeigt die Verteilung von 5 dieser Datensätze (A), einen Balkenplot des Mittelwerts, der Standardabweichung und der Anzahl der Beobachtungen für die Variablen “x” und “y” (B) sowie einen Fehlerbalkenplot (C).\n\n\n\n\n\nAbbildung 10.13: Datasets with the same means, sds, and Ns, but very different distributions\n\n\n\n\nSie werden sehen, dass die Verteilungen sehr unterschiedlich aussehen (in Abbildung 10.13 A), aber Abbildung 10.13 B und C vermitteln das nicht. Aus diesem Grund ist es ein guter Grund, die Rohdatenpunkte immer zu visualisieren, unabhängig davon, welche zusammenfassende Darstellung Sie erstellen (z. B. verbergen Errorbar-Plots auch viele Daten). Eine gute Möglichkeit, alle Grundlagen abzudecken, besteht darin, die Verteilung der Daten zusammen mit einer Visualisierung der zusammenfassenden Statistiken darzustellen. Sie werden dies in der Hausaufgabe üben, und in ?sec-dataviz4 werden wir sehen, wie man diese zusammen in einem Diagramm visualisiert."
  },
  {
    "objectID": "mats/10-dataviz_3.html#lernziele-1",
    "href": "mats/10-dataviz_3.html#lernziele-1",
    "title": "10  Datenvisualisierung 3",
    "section": "Lernziele 🏁",
    "text": "Lernziele 🏁\nIn diesem Kapital haben wir gelernt, wie man…\n\nBoxplots zu erstellen und zu interpretieren ✅\nMittelwerte und Standardabweichungen zu visualisieren ✅"
  },
  {
    "objectID": "mats/10-dataviz_3.html#hausaufgabe",
    "href": "mats/10-dataviz_3.html#hausaufgabe",
    "title": "10  Datenvisualisierung 3",
    "section": "Hausaufgabe",
    "text": "Hausaufgabe\n\nBoxplot mit Facette\n\n\nErzeugen Sie einen Plot namens fig_boxplot, der ein Boxplot der df_eng Daten ist, mit:\n\nage_subject auf der x-Achse\nrt_naming auf der y-Achse\nage_subject als colour oder fill (wähle eine, es gibt keine falsche Wahl)\nWort_Kategorie in zwei Facetten mit facet_wrap() aufgetragen\ndie von Ihnen gewählte theme_-Einstellung (z.B. theme_bw(); für weitere Optionen siehe hier)\n\n\n\n\n\nErrorbar plot\n\n\nVersuchen Sie, Abbildung 10.14 zu reproduzieren. Hinweis: Sie werden die Variable rt_naming aus df_eng verwenden.\n\n\n\n\n\n\n\nAbbildung 10.14: Plot to be reproduced\n\n\n\n\n\n\nPatchwork\n\n\nVerwenden Sie das Paket patchwork, um Ihren Boxplot und Ihre Fehlerbalkenplots nebeneinander darzustellen. Es sollte ungefähr so aussehen wie Abbildung 10.15. Hinweis: Wenn Sie die “tag-level” (“A” und “B”) zu den Plots hinzufügen möchten, müssen Sie + plot_annotation(tag_level = \"A\") aus patchwork hinzufügen.\n\n\n\n\n\n\n\nAbbildung 10.15: Combined plots with patchwork"
  },
  {
    "objectID": "mats/10-dataviz_3.html#session-info",
    "href": "mats/10-dataviz_3.html#session-info",
    "title": "10  Datenvisualisierung 3",
    "section": "Session Info",
    "text": "Session Info\nHergestellt mit R version 4.3.0 (2023-04-21) (Already Tomorrow) und RStudioversion 2023.9.0.463 (Desert Sunflower).\n\nprint(sessionInfo(),locale = F)\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.2.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] magick_2.7.4    patchwork_1.1.3 ggthemes_4.2.4  janitor_2.2.0  \n [5] here_1.0.1      lubridate_1.9.2 forcats_1.0.0   stringr_1.5.0  \n [9] dplyr_1.1.3     purrr_1.0.2     readr_2.1.4     tidyr_1.3.0    \n[13] tibble_3.2.1    ggplot2_3.4.3   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.4      xfun_0.39         htmlwidgets_1.6.2 tzdb_0.4.0       \n [5] vctrs_0.6.3       tools_4.3.0       generics_0.1.3    parallel_4.3.0   \n [9] fansi_1.0.4       cluster_2.1.4     pacman_0.5.1      pkgconfig_2.0.3  \n[13] data.table_1.14.8 checkmate_2.2.0   webshot_0.5.4     lifecycle_1.0.3  \n[17] compiler_4.3.0    farver_2.1.1      munsell_0.5.0     datasauRus_0.1.6 \n[21] snakecase_0.11.0  htmltools_0.5.5   yaml_2.3.7        htmlTable_2.4.1  \n[25] Formula_1.2-5     pillar_1.9.0      crayon_1.5.2      Hmisc_5.1-0      \n[29] rpart_4.1.19      tidyselect_1.2.0  rvest_1.0.3       digest_0.6.33    \n[33] stringi_1.7.12    labeling_0.4.3    rprojroot_2.0.3   fastmap_1.1.1    \n[37] grid_4.3.0        colorspace_2.1-0  cli_3.6.1         magrittr_2.0.3   \n[41] base64enc_0.1-3   utf8_1.2.3        foreign_0.8-84    withr_2.5.0      \n[45] backports_1.4.1   scales_1.2.1      bit64_4.0.5       timechange_0.2.0 \n[49] rmarkdown_2.22    httr_1.4.6        nnet_7.3-18       bit_4.0.5        \n[53] gridExtra_2.3     png_0.1-8         hms_1.1.3         kableExtra_1.3.4 \n[57] evaluate_0.21     knitr_1.44        viridisLite_0.4.2 rlang_1.1.1      \n[61] Rcpp_1.0.11       glue_1.6.2        xml2_1.3.4        svglite_2.1.1    \n[65] rstudioapi_0.14   vroom_1.6.3       jsonlite_1.8.7    R6_2.5.1         \n[69] systemfonts_1.0.4"
  },
  {
    "objectID": "mats/10-dataviz_3.html#literaturverzeichnis",
    "href": "mats/10-dataviz_3.html#literaturverzeichnis",
    "title": "10  Datenvisualisierung 3",
    "section": "Literaturverzeichnis",
    "text": "Literaturverzeichnis\n\n\nNordmann, E., McAleer, P., Toivo, W., Paterson, H., & DeBruine, L. M. (2022). Data Visualization Using R for Researchers Who Do Not Use R. Advances in Methods and Practices in Psychological Science, 5(2), 251524592210746. https://doi.org/10.1177/25152459221074654\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for Data Science (2. Aufl.).\n\n\nWinter, B. (2019). Statistics for Linguists: An Introduction Using R. In Statistics for Linguists: An Introduction Using R. Routledge. https://doi.org/10.4324/9781315165547"
  },
  {
    "objectID": "mats/10-dataviz_3.html#footnotes",
    "href": "mats/10-dataviz_3.html#footnotes",
    "title": "10  Datenvisualisierung 3",
    "section": "",
    "text": "Anstelle der Standardabweichung werden in der Regel Standardfehler oder Konfidenzintervalle (oder glaubwürdige Intervalle) dargestellt, die jedoch in diesem Kurs nicht behandelt werden. Aus diesem Grund sollten wir im Titel der Grafik vermerken, was die Fehlerbalken darstellen↩︎"
  },
  {
    "objectID": "mats/11-bericht_2.html#einrichten",
    "href": "mats/11-bericht_2.html#einrichten",
    "title": "11  Bericht 2",
    "section": "11.1 Einrichten",
    "text": "11.1 Einrichten\nFühren Sie den folgenden Code aus, um Ihre Umgebung für die folgenden Aufgaben einzurichten.\n\nPackages\nFühren Sie den folgenden Code aus, um die erforderlichen Pakete zu laden: tidyverse, here, janitor, und patchwork.\n\npacman::p_load(\n  tidyverse,\n  here,\n  janitor,\n  patchwork\n)\n\n\n\nDaten laden\nNachfolgend finden Sie einen Code, der einen Datensatz von Biondo et al. (2022) lädt, eine Studie zur Beobachtung von Augenbewegungen beim Lesen. Es gibt einen Kommentar, in dem beschrieben wird, was die einzelnen Zeilen bewirken, falls Sie daran interessiert sind. Dieser Datensatz muss zuerst heruntergeladen und in Ihrem Daten-Ordner gespeichert werden.\n\ndf_biondo &lt;-\n  read_csv(here(\"daten\", \"Biondo.Soilemezidi.Mancini_dataset_ET.csv\"),\n           # spezielle Formatierung für spanische Zeichen\n           locale = locale(encoding = \"Latin1\")) |&gt; \n  # tidy Variablennamen\n  clean_names() |&gt; \n  # Grammatikalität umschlüsseln\n  mutate(gramm = ifelse(gramm == 0, \"ungramm\", \"gramm\")) |&gt; \n  # nur Beobachtungen von deiktischen Adverbien behalten\n  filter(adv_type == \"Deic\",\n         # und die Satzregionen Adverb (2) und Verb (4)\n         roi %in% c(2,4))\n\n\n\nDatenumwandlung 1: Transformation\nFügen Sie unter Verwendung von Pipes (|&gt;) dem obigen Code-Stück eine Zeile hinzu:\n\neine Zeile, in der Sie die Variable verb_t in tense umbenennen\neine Zeile, in der Sie nur die Variablen roi, label, tense, gramm, fp, und tt auswählen\n\nSie sollten dann einen Datenrahmen mit 7680 Beobachtungen und 6 Variablen haben."
  },
  {
    "objectID": "mats/11-bericht_2.html#plot-interpretation-verteilung",
    "href": "mats/11-bericht_2.html#plot-interpretation-verteilung",
    "title": "11  Bericht 2",
    "section": "11.2 Plot-Interpretation: Verteilung",
    "text": "11.2 Plot-Interpretation: Verteilung\nBetrachten Sie Abbildung 11.1 A und B und beschreiben Sie die Diagramme. Beide enthalten nur Daten aus der Verbregion eines Satzes (roi == 4). Geben Sie den ungefähren Modus sowie die Minimal- und Maximalwerte für den gesamten Datensatz (?fig-Verteilung A) und den Median, den Minimal- und den Maximalwert pro Bedingung (?fig-Verteilung B) an.\n\n\n\n\n\nAbbildung 11.1: Zu interpretierende Plots"
  },
  {
    "objectID": "mats/11-bericht_2.html#data-wrangling-2-aufräumen",
    "href": "mats/11-bericht_2.html#data-wrangling-2-aufräumen",
    "title": "11  Bericht 2",
    "section": "11.3 Data wrangling 2: Aufräumen",
    "text": "11.3 Data wrangling 2: Aufräumen\nVerwenden Sie die Funktion pivot_longer(), um den Datensatz zu verlängern, wobei die Spalten (cols =) fp und tt zu einer Spalte (names_to =) namens measure werden und ihre Werte in einer Spalte (values_to =) namens time gespeichert werden. Speichern Sie das Ergebnis als df_longer. Es sollte 15360 Beobachtungen und 6 Spalten enthalten.\n\ndf_longer &lt;-"
  },
  {
    "objectID": "mats/11-bericht_2.html#zusammenfassende-statistik",
    "href": "mats/11-bericht_2.html#zusammenfassende-statistik",
    "title": "11  Bericht 2",
    "section": "11.4 Zusammenfassende Statistik",
    "text": "11.4 Zusammenfassende Statistik\nVerwenden Sie die Funktion summarise(), um den Mittelwert und die Standardabweichung von time zu ermitteln. Gruppieren Sie die Ergebnisse nach measure, tense, gramm und roi (entweder mit .by = oder group_by()).\n\nsum_et &lt;-\n\nDrucken Sie die Zusammenfassung."
  },
  {
    "objectID": "mats/11-bericht_2.html#visualisierung-zusammenfassender-statistiken",
    "href": "mats/11-bericht_2.html#visualisierung-zusammenfassender-statistiken",
    "title": "11  Bericht 2",
    "section": "11.5 Visualisierung zusammenfassender Statistiken",
    "text": "11.5 Visualisierung zusammenfassender Statistiken\nIn dieser Aufgabe erstellen Sie zwei Fehlerdiagramme und drucken sie nebeneinander aus.\n\nAdverb-Region\nErzeugen Sie ein Fehlerdiagramm namens fig_adverb für die Region adverb (roi == 2) der soeben erstellten Zusammenfassung mit folgender Ästhetik: + Grammatikalität auf der x-Achse + Mittelwert auf der y-Achse + Zeitform als Farbe und Form + Fehlerbalken mit +/- 1 Standardabweichung + Facetten für die Messung + ein geeigneter Titel für die Darstellung und Beschriftungen der x- und y-Achse\n\nfig_adverb &lt;-\n\n\n\nVerb-Region\nErzeugen Sie die gleiche Darstellung für die Region verb (roi == 4) mit dem Namen fig_verb.\nTipp: Sie können einfach den Code aus der Darstellung der Adverbregion kopieren und die Region (roi) in das Verb ändern!\n\nfig_verb &lt;-\n\n\n\nPlots drucken\nStellen Sie Ihre beiden Fehlerbalken nebeneinander dar, indem Sie das Paket patchwork verwenden"
  },
  {
    "objectID": "mats/11-bericht_2.html#plot-interpretation-zusammenfassende-statistiken",
    "href": "mats/11-bericht_2.html#plot-interpretation-zusammenfassende-statistiken",
    "title": "11  Bericht 2",
    "section": "11.6 Plot-Interpretation: zusammenfassende Statistiken",
    "text": "11.6 Plot-Interpretation: zusammenfassende Statistiken\nBeschreiben Sie etwaige Unterschiede zwischen den Bedingungen und Regionen auf der Grundlage der von Ihnen erstellten Zusammenfassung und der aus der Zusammenfassung generierten Diagramme.\n\n\n\n\nBiondo, N., Soilemezidi, M., & Mancini, S. (2022). Yesterday Is History, Tomorrow Is a Mystery: An Eye-Tracking Investigation of the Processing of Past and Future Time Reference during Sentence Reading. Journal of Experimental Psychology: Learning, Memory, and Cognition, 48(7), 1001–1018. https://doi.org/10.1037/xlm0001053"
  }
]