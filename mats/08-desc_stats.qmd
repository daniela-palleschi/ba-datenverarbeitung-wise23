---
subtitle: "Ma√üe der zentralen Tendenz und Streuung"
author: "Daniela Palleschi"
institute: Humboldt-Universit√§t zu Berlin
footer: "Woche 8 - Dateneinlesung" 
date: "12/06/2023"
date-format: "ddd [den] DD.MM.YYYY"
date-modified: last-modified
---

# Deskriptive Statistik {#sec-desc-stats}

```{r}
#| echo: false
knitr::opts_chunk$set(eval = T, ## evaluate chunks
                      echo = T, ## 'print code chunk?'
                      message = F, ## 'print messages (e.g., warnings)?'
                      error = T, ## continueeven when error encountered
                      warning = F) ## don't print warnings
```

## Lernziele {.unnumbered}

In diesem Kapitel werden wir lernen...

- √ºber Ma√üe der zentralen Tendenz (Mittelwert, Median, Modus)
- √ºber Streuungsma√üe (Bereich, Standardabweichung)
- wie man die Funktion `summarise()` von `dplyr` benutzt
- wie man Zusammenfassungen `.by` Gruppe erstellt

## Lesungen {.unnumbered}

Die **Pflichtlekt√ºre** zur Vorbereitungen auf dieses Thema sind

1. Kap. 3, Abschnitt 3.4-3.9 (Descriptive statistics, models, and distributions) in @winter_statistics_2019 (online verf√ºgbar √ºber das [HU Grimm Zentrum](https://hu-berlin.hosted.exlibrisgroup.com/permalink/f/uig076/TN_cdi_askewsholts_vlebooks_9781351677431).

2. [Bereich 4.5 (Groups)](https://r4ds.hadley.nz/data-transform#groups) in Kapital 4 (Data Transformation) in @wickham_r_2023.

## Einrichten

### Umgebung l√∂schen

Ein wichtiger Schritt, √ºber den wir noch nicht viel gesprochen haben, ist sicherzustellen, dass Sie ein neues Skript *immer* mit einer leeren R-Umgebung starten. Das bedeutet, dass wir keine Objekte in der Umgebung gespeichert haben sollten, aber auch keine Pakete geladen haben sollten. Wir wollen n√§mlich sicherstellen, dass alles, was wir tun, ausschlie√ülich in diesem Skript ausgef√ºhrt wird und nicht von einem Paket oder Daten abh√§ngt, die wir aus einem anderen Skript geladen haben. Um dies zu erreichen, k√∂nnen Sie auf `Sitzung > R neu starten` klicken, um mit einer neuen Umgebung zu beginnen, oder die Tastenkombination `Cmd/Strg+Strg+0` verwenden.

### Pakete

Wir m√ºssen die Pakete `tidyverse`, `here` und `janitor` laden. Die letzten beiden brauchen wir, weil wir lokale CSV-Datens√§tze laden werden.

```{r}
pacman::p_load(tidyverse,
               here,
               janitor)
```

```{r}
#| echo: false
pacman::p_load(patchwork)
```

### Daten laden

Wir werden heute zwei Datens√§tze verwenden: eine leicht ver√§nderte Version des `groesse_geburtstag`-Datensatzes aus dem letzten Abschnitt (`groesse_geburtstag_ws2324.csv`) und `languageR_english.csv`, das eine k√ºrzere Version des `english`-Datensatzes aus dem `languageR`-Paket ist. Wenn Sie diese Daten noch nicht haben, laden Sie sie direkt in Ihren `Daten`-Ordner vom GitHub-Kurs herunter (klicken Sie auf "Download raw file" neben dem "Raw"-Button): 

- [languageR_english.csv](https://github.com/daniela-palleschi/r4ling_student/blob/main/daten/languageR_english.csv)
- [groesse_geburtstag_ws2324.csv](https://github.com/daniela-palleschi/r4ling_student/blob/main/daten/groesse_geburtstag_ws2324.csv)


```{r}
#| eval: false
#| echo: false
library(languageR)

df_eng <- english |> 
  select(AgeSubject, Word, LengthInLetters, WrittenFrequency, WordCategory, RTlexdec, RTnaming) |>   mutate(RTlexdec = exp(RTlexdec),
         RTnaming = exp(RTnaming),
         RTnaming = ifelse(Word == "age" & AgeSubject == "young", NA, RTnaming)) 

write_csv(df_eng, here("daten", "languageR_english.csv"))

df_groesse <- read_csv(here("daten", "groesse_geburtstag_ws2324.csv"),
                       # fix N/A values
                       na = c("", "N/A")) |> 
  mutate(Gr√∂√üe = ifelse(Gr√∂√üe == 168, 167, Gr√∂√üe)) |> 
  clean_names() |> 
  rename(groesse = groesse,
         muttersprache = l1,
         geburtsmonat = monat_der_geburt,
         geburtstag = tag)

write_csv(df_groesse, here("daten", "groesse_geburtstag_ws2324.csv"))
```

```{r}
df_groesse <- read_csv(here("daten", "groesse_geburtstag_ws2324.csv"))
```


```{r}
df_eng <- read_csv(here("daten", "languageR_english.csv")) |> 
  clean_names() |> 
  # fix some wonky variable names:
  rename(rt_lexdec = r_tlexdec,
         rt_naming = r_tnaming)
```


## Deskriptive Statistik

Deskriptive Statistiken beschreiben quantitativ die zentrale Tendenz, die Variabilit√§t und die Verteilung von Daten. Sie werden manchmal auch als zusammenfassende Statistiken bezeichnet, weil wir die beobachteten Daten *zusammenfassen*. Zu den g√§ngigen zusammenfassenden Statistiken geh√∂ren der Wertebereich (Minimum, Maximum), der Mittelwert und die Standardabweichung. Deskriptive Statistiken helfen uns, unsere Daten in vollem Umfang zu verstehen, und sind ein wichtiger Schritt bei der Untersuchung unseres Datensatzes, bevor wir fortgeschrittenere *Inferenzstatistiken* durchf√ºhren (die wir in diesem Kurs nicht behandeln werden).

### Anzahl der Beobachtungen ($n$)

Die Anzahl der Beobachtungen in einem Datensatz ist keine statistische Gr√∂√üe, sondern eine wichtige Information bei der Zusammenfassung oder Beschreibung von Daten. Wenn wir mehr Daten haben (h√∂her $n$), k√∂nnen wir den Schlussfolgerungen, die wir aus unseren Daten ziehen, mehr Vertrauen schenken, da wir mehr Beweise haben. Umgekehrt kann es sein, dass bei weniger Daten (niedriger $n$) unsere zusammenfassende Statistik nicht auf die Grundgesamtheit verallgemeinerbar ist. Wir k√∂nnen die Anzahl der Beobachtungen in einem Datensatz mit der R-eigenen Funktion `nrow()` √ºberpr√ºfen:
  
```{r}
#| output-location: fragment
nrow(df_groesse)
```

::: callout-note
#### `length()` gegen√ºber `nrow()`
Die Funktion `length()` sagt uns, wie viele (horizontale) Werte in einem Objekt enthalten sind. Wenn das Objekt ein Datenrahmen (statt eines Vektors) ist, sagt sie uns, wie viele *Spalten* wir haben.

```{r}
#| output-location: fragment
length(df_groesse)
```

Wenn es sich bei dem Objekt jedoch um einen Vektor handelt, dann gibt uns `length()` die Anzahl der Beobachtungen an.

```{r}
vector <- c(1,5,2,6,8,4,7,8,3)
length(vector)
```

:::

### Ma√üe der zentralen Tendenz (Lagema√üe)

Ma√üe der zentralen Tendenz beschreiben quantitativ die Mitte unserer Daten. Wahrscheinlich haben Sie schon einmal drei Ma√üe der zentralen Tendenz kennengelernt: den Mittelwert, den Median und den Modus.

#### Mittelwert ($\mu$ oder $\bar{x}$)

Der Mittelwert oder Durchschnitt ist die Summe aller Werte geteilt durch die Anzahl der Werte (wie in Gleichung \ref{eq-mean}). In der mathematischen Notation wird *sum* mit dem gro√üen griechischen Sigma ($\sum$) geschrieben, wie in der Gleichung \ref{eq-sigma}.

\begin{align}
\mu &= \frac{Summe\;der\;Werte} 
           {n} \label{eq-mean} \\
\bar{x} &= \frac{\sum{x}}      
           {n} \label{eq-sigma} 
\end{align}

::: .callout-tip

#### Populationsmittelwert ($\mu$) versus Stichprobenmittelwert ($\bar{x}$)

Beide Gleichungen bedeuten dasselbe, verwenden aber unterschiedliche Schreibweisen, um dieselbe Gleichung darzustellen. W√§hrend $\mu$ den *Populationsmittelwert* darstellt, repr√§sentiert $\bar{x}$ den *Stichprobenmittelwert*. Der Populationsmittelwert ist der wahre Mittelwert einer Messung in einer gesamten Population (z. B. die K√∂rpergr√∂√üe aller Studenten an der Humboldt-Universit√§t zu Berlin). Ein *Stichprobenmittel* ist der Mittelwert einer *Stichprobenpopulation*, aus der wir unsere Daten erhoben haben. Wir haben zum Beispiel `r nrow(df_groesse)` Beobachtungen in `df_groesse`. Diese Daten stellen eine Stichprobe von Daten aus einer gr√∂√üeren Grundgesamtheit dar.
:::

Wir k√∂nnen den Mittelwert leicht von Hand berechnen, wenn wir nur ein paar Werte haben. Erinnern Sie sich an unseren Datensatz von letzter Woche, in dem wir unsere H√∂hen in Zentimetern gesammelt haben (`171, 168, 182, 190, 170, 163, 164, 167, 189`). Es gibt 9 Werte, also m√ºssen wir diese H√∂hen addieren und die Summe durch 9 teilen.

```{r}
#| output-location: fragment
171+ 168+ 182+ 190+ 170+ 163+ 164+ 167+ 189 / 9
```

Daraus ergibt sich eine durchschnittliche K√∂rpergr√∂√üe von `r 171+ 168+ 182+ 190+ 170+ 163+ 164+ 167+ 189 / 9` cm. Das kann nicht richtig sein, was ist also schief gelaufen? Wir k√∂nnen die obige Gleichung korrigieren, indem wir die H√∂hen in Klammern setzen (`()`), bevor wir durch $n$ dividieren.

```{r}
#| output-location: fragment
(171+ 168+ 182+ 190+ 170+ 163+ 164+ 167+ 189) / 9
```

Dieses Problem wurde durch die *Reihenfolge der Operationen* verursacht, die im Folgenden n√§her beschrieben wird. Das Wichtigste ist, dass Sie sicher sein k√∂nnen, dass das *Ergebnis* einer bestimmten Operation vor allen anderen Operationen ausgef√ºhrt wird, wenn Sie es in Paranthesen einschlie√üen.

::: {.content-visible when-format="html"}
::: callout-tip

### Operatorrangfolge: KEMDAS

Vielleicht erinnern Sie sich, dass Sie als Kind im Mathematikunterricht etwas √ºber die Reihenfolge der Operationen gelernt haben. Dies bezieht sich auf die Reihenfolge der Ausf√ºhrung, wenn wir eine mathematische Gleichung mit mehreren Operatoren wie Division, Addition und Multiplikation haben. `R` folgt auf `KEMDAS` (das ich von `PEMDAS` im Englischen √ºbernommen habe), was f√ºr:

```{r}
#| echo: false
#| label: tbl-kemdas
#| tbl-cap: "KEMDAS"
tribble(
  ~letter, ~operation, ~R,
  "K", "Klammern", "(x + y)",
  "E", "Exponenten", "x^y",
  "M", "Multiplikation", "x*y",
  "D", "Division", "x/y",
  "A", "Addierung", "x + y",
  "S", "Subtraktion", "x - y"
) |> 
  knitr::kable() |> 
  kableExtra::kable_styling()
```

Multiplikation und Division werden jedoch von links nach rechts ausgef√ºhrt, ebenso wie Addition und Subtraktion.

:::
:::

Wir k√∂nnen auch die Ergebnisse einer Gleichung als Objekt oder mehrere Werte als Vektor (eine Liste von Werten der gleichen Klasse) speichern. Wir k√∂nnten dann die Funktionen `sum()` und `length()` verwenden, um den Mittelwert zu berechnen, oder einfach die Funktion `mean()` benutzen.

```{r}
#| output-location: fragment
# save groesse as a vector
groesse <- c(171, 168, 182, 190, 170, 163, 164, 167, 189)
# divide the sum of groesse by the n of groesse
sum(groesse)/length(groesse)
```

```{r}
# or use the mean() function
mean(groesse)
```

Unsere Daten sind oft nicht in einem einzelnen Vektor gespeichert, sondern in einem Datensatz. Wir k√∂nnen die Funktion `mean()` auf eine Variable in einem Datenrahmen anwenden, indem wir den Operator `$` verwenden, um anzugeben, dass wir eine Spalte aus einem Datenrahmen ausw√§hlen wollen (`datenrahmen$variable`).
  
```{r}
#| output-location: fragment
mean(df_groesse$groesse)
```

Der `$`-Operator ist Teil der nativen R-Syntax und √§hnelt dem Operator `pdf_groesse |>select(groesse)` in der `dplyr`-Syntax.

#### Median

Ein weiteres Ma√ü f√ºr die zentrale Tendenz ist der `Median`, d. h. der Wert in der Mitte des Datensatzes. Wenn Sie alle Ihre Werte in aufsteigender (oder absteigender) Reihenfolge anordnen, ist der mittlere Wert der Median. Wenn Sie zum Beispiel 5 Werte haben, ist der 3. Bei 6 Werten ist der Mittelwert des 3. und 4. Wertes der Median. Die H√§lfte der Daten liegt unter dem Median, die andere H√§lfte √ºber dem Median.

Um unsere Daten in aufsteigender Reihenfolge zu sortieren, k√∂nnen wir die Funktion `sort()` verwenden. Wir k√∂nnen dann einfach z√§hlen, welches der mittlere Wert ist:   

```{r}
#| output-location: fragment
sort(df_groesse$groesse)
```

Das ist einfach, wenn wir nur ein paar Beobachtungen haben. Wir k√∂nnten alternativ einfach die Funktion `Median()` verwenden.

```{r}
median(df_groesse$groesse)
```

Ein wichtiges Merkmal des Medians ist, dass er nicht von Ausrei√üern oder Extremwerten beeinflusst wird. Schauen wir uns an, was passiert, wenn wir unsere gr√∂√üte K√∂rpergr√∂√üe (190 cm) so √§ndern, dass sie der Gr√∂√üe der derzeit gr√∂√üten Person der Welt entspricht: 251 cm. 

```{r}
df_groesste <- df_groesse |> mutate(groesse = ifelse(groesse == 190, 251, groesse))
```

```{r}
sort(df_groesste$groesse)
```

```{r}
median(df_groesste$groesse)
```

```{r}
mean(df_groesste$groesse)
```

Wir sehen, dass sich der Mittelwert von ungef√§hr `r round(mean(df_groesse$groesse),0)`cm auf `r round(mean(df_groesste$groesse),0)`cm ge√§ndert hat. Der Median blieb jedoch gleich (`r median(df_groesste$groesse)` cm), weil der Mittelwert unabh√§ngig von den anderen Werten in einem Datensatz ist. Aus diesem Grund wird der Median h√§ufig anstelle des Mittelwerts angegeben, wenn die Daten stark zu extremeren Werten neigen, wie z. B. bei der Angabe der Einkommen in einer Bev√∂lkerung. Durchschnittseinkommen k√∂nnen aufgrund einer kleinen Gruppe von extrem gut Verdienenden stark verzerrt sein und sind in der Regel nicht repr√§sentativ f√ºr das Einkommen der Mehrheit der B√ºrger.

#### Modus

Der Modus ist der Wert, der in einem Datensatz am h√§ufigsten vorkommt, und ist ein weiteres Ma√ü f√ºr die zentrale Tendenz. Es gibt keine R-Funktion, um den Modus zu bestimmen, aber wir haben bereits einige g√§ngige M√∂glichkeiten gesehen, ihn zu visualisieren: mit einem Histogramm oder einem Dichteplot.

```{r}
#| output-location: column-fragment
df_groesse |>
  ggplot(aes(x = groesse)) +
  geom_histogram(binwidth = .5) +
  theme_minimal() 
```

### Streuungsma√üe

Ma√üe der zentralen Tendenz beschreiben (normalerweise) die Mitte der Daten. Streuungsma√üe beschreiben die Streuung der Datenpunkte und sagen etwas dar√ºber aus, wie die Daten insgesamt verteilt sind.

#### Bereich

Der "Bereich" von Werten kann sich auf den h√∂chsten (maximalen) und den niedrigsten (minimalen) Wert oder auf die Differenz zwischen h√∂chstem und niedrigstem Wert beziehen. Die R-Basisfunktionen `max()` und `min()` geben die h√∂chsten und niedrigsten Werte aus.

```{r}
#| output-location: fragment
max(groesse)
```

```{r}
#| output-location: fragment
min(groesse)
```

Oder wir k√∂nnen einfach die Funktion `range()` verwenden, die diese beiden Zahlen nebeneinander ausgibt.

```{r}
#| output-location: fragment
range(groesse)
```

Wir k√∂nnen die Differenz zwischen diesen Werten ermitteln, indem wir den Minimalwert vom Maximalwert subtrahieren.

```{r}
#| output-location: fragment
max(groesse) - min(groesse)
```

In einem Histogramm oder Dichteplot werden diese Werte durch den niedrigsten und den h√∂chsten Wert auf der x-Achse dargestellt.

```{r}
#| echo: false
fig_hist <-
  df_groesse |> 
  ggplot() + 
  aes(x = groesse) + 
  labs(title = "Histogram of groesse") +
  scale_y_continuous(breaks = c(1,2)) +
  geom_histogram(binwidth = .5)

fig_dens <-
  df_groesse |> 
  ggplot() + 
  aes(x = groesse) + 
  labs(title = "Density plot of groesse") +
  geom_density()

fig_hist + fig_dens
```


#### Standardabweichung (`sd` oder $\sigma$)

Die Standardabweichung ist ein Ma√ü daf√ºr, wie weit die Daten *im Verh√§ltnis zum Mittelwert* gestreut sind. Eine niedrige Standardabweichung bedeutet, dass die Daten um den Mittelwert herum gruppiert sind (d. h. es gibt weniger Streuung), w√§hrend eine hohe Standardabweichung bedeutet, dass die Daten st√§rker gestreut sind. Ob eine Standardabweichung hoch oder niedrig ist, h√§ngt von der Skala und der Ma√üeinheit ab, in der die Daten vorliegen. Die Standardabweichung wird sehr oft angegeben, wenn der Mittelwert berichtet wird. 

Die Standardabweichung (`sd`) ist gleich der Quadratwurzel ($\sqrt{}$ oder `sqrt()` in R) der Summe der quadrierten Wertabweichungen vom Mittelwert ($(x - \mu)^2$) geteilt durch die Anzahl der Beobachtungen minus 1 ($n-1$), angegeben in Gleichung \ref{eq-sd}.

\begin{align}
\sigma & = \sqrt{\frac{(x_1-\mu)^2 + (x_2-\mu)^2 + ... + (x_N-\mu)^2}{N-1}} \label{eq-sd}
\end{align}

Das sieht einsch√ºchternd aus, aber wir k√∂nnen die Standardabweichung in R mit der Funktion `sd()` berechnen.

```{r}
#| output-location: fragment
sd(groesse)
```

Wenn man jedoch wei√ü, wie man die Standardabweichung von Hand berechnen kann, versteht man, was die Zahl bedeutet. Lassen Sie uns die Berechnung der Standardabweichung f√ºr eine kleine Gruppe von Werten √ºben. Unter Ber√ºcksichtigung der Gleichung f√ºr die Standardabweichung in \ref{eq-sd} k√∂nnen wir die Standardabweichung von Hand berechnen, wenn wir den Wert jeder Beobachtung, den Mittelwert dieser Werte und die Anzahl dieser Werte kennen. In einem Vektor mit 3 Beobachtungen (`3, 5, 9`) sind unsere Werte ($x$) zum Beispiel folgende:

```{r}
#| output-location: column-fragment
values <- c(3,5,16)
values
```

Setzt man diese in die Gleichung f√ºr die Standardabweichung ein, erh√§lt man Gleichung \ref{eq-sd1}.

\begin{align}
\sigma & = \sqrt{\frac{(3-\mu)^2 + (5-\mu)^2 + (16-\mu)^2}{N-1}} \label{eq-sd1}
\end{align}

Unser Mittelwert ($\mu$) ist:

```{r}
#| output-location: column-fragment
mean(values)
```

Wenn wir dies zu Gleichung \ref{eq-sd1} hinzuf√ºgen, erhalten wir Gleichung \ref{eq-sd2}.

\begin{align}
\sigma & = \sqrt{\frac{(3-8)^2 + (5-8)^2 + (16-8)^2}{N-1}} \label{eq-sd2}
\end{align}

Die Anzahl der Werte ($n$) ist:

```{r}
#| output-location: column-fragment
length(values)
```

Wenn wir dies zu Gleichung \ref{eq-sd2} hinzuf√ºgen, erhalten wir Gleichung \ref{eq-sd3}.

\begin{align}
\sigma & = \sqrt{\frac{(3-8)^2 + (5-8)^2 + (16-8)^2}{3-1}} \label{eq-sd3}
\end{align}

If we carry out all of the operations following PEDMAS, then we get Equations \ref{eq-sd4} through \ref{eq-sd}:

\begin{align}
\sigma & = \sqrt{\frac{(-5)^2 + (-3)^2 + (8)^2}{3-1}} \\ \label{eq-sd4}
\\
& = \sqrt{\frac{25 + 9 + 64}{3-1}}
\\
& = \sqrt{\frac{98}{2}} \\
& = \sqrt{49} \\
& = 7
\end{align}

Um unsere Arbeit zu √ºberpr√ºfen, berechnen wir die Standardabweichung ($\sigma$) in "R":

```{r}
#| output-location: column-fragment
sd(values)
```

#### Warum Standardabweichung?

Die Standardabweichung ist ein Ma√ü daf√ºr, wie "eng" die beobachteten Werte am Mittelwert liegen. Wenn die meisten Beobachtungen sehr nahe am Mittelwert liegen, ist die Standardabweichung im Verh√§ltnis zum Mittelwert eine kleine Zahl. Wenn es viele Beobachtungen mit gro√üen Abweichungen vom Mittelwert gibt, wird die Standardabweichung tendenziell eine gro√üe Zahl sein (relativ zum Mittelwert).

Verschiedene Datens√§tze k√∂nnen denselben Mittelwert, aber sehr unterschiedliche Standardabweichungen aufweisen. Ein Beispiel:


```{r}
values2 <- c(55,55,55,55,55,57,57,57,57,57)
values3 <- c(1,1,1,1,100,100,100,100,100)
```

```{r}
#| output-location: column-fragment
mean(values2)
```

```{r}
#| output-location: column-fragment
mean(values3)
```

Wir sehen, dass `values2` und `values3` den gleichen Mittelwert haben. Daraus k√∂nnte man schlie√üen, dass die Daten √§hnlich sind. Aber ihre Standardabweichungen werden sich unterscheiden, weil ihre jeweiligen beobachteten Werte alle unterschiedlich weit vom Mittelwert abweichen. Welcher Vektor wird Ihrer Meinung nach die *geringste* Standardabweichung haben? Und warum?

```{r}
#| output-location: column-fragment
sd(values2)
```

```{r}
#| output-location: column-fragment
sd(values3)
```

Die gr√∂√üere Standardabweichung f√ºr `Werte3` spiegelt die Tatsache wider, dass die Werte tendenziell sehr weit vom Mittelwert entfernt sind. Die kleinere Standardabweichung f√ºr `Werte2` spiegelt die Tatsache wider, dass der Wert f√ºr diese Variable tendenziell recht nahe am Mittelwert liegt.

::: callout-tip
#### Quadrat und Quadratwurzel

Warum quadrieren wir die Abweichung jeder Beobachtung vom Mittelwert, um dann sp√§ter die Quadratwurzel aus ihrer Summe geteilt durch $N-1$ zu berechnen? Da die H√§lfte unserer Beobachtungen unterhalb und die H√§lfte oberhalb des Mittelwerts liegen wird, sind die resultierenden Differenzen, wenn wir den Mittelwert von den Werten abziehen, zur H√§lfte negativ und zur H√§lfte positiv. Wenn wir positive und negative Werte zusammenz√§hlen, heben sie sich gegenseitig auf. Wenn wir also alle diese Abweichungen vom Mittelwert quadrieren, werden alle Werte positiv sein (eine positive Zahl multipliziert mit einer positiven Zahl ist eine positive Zahl, w√§hrend eine negative Zahl multipliziert mit sich selbst ebenfalls eine positive Zahl ergibt). Wenn wir dann die Quadratwurzel dieser Werte berechnen, erhalten wir die urspr√ºngliche Gr√∂√üe der Abweichung, aber immer als positiven Wert.

:::

::: callout-tip

### Eigenschaften der Grundgesamtheit

Sowohl der Mittelwert als auch die Standardabweichung sagen etwas √ºber die Grundgesamtheit aus, aus der unsere Datenstichprobe stammt. Je mehr Beobachtungen wir sammeln, desto genauer werden diese Ma√üe im Durchschnitt sein.

:::

## Zusammenfassende Statistiken mit R

Wir haben bereits einige n√ºtzliche Funktionen zur Berechnung von zusammenfassenden Statistiken gesehen (z.B. `mean()`, `median()`, `sd()`). In der Regel m√∂chten wir jedoch mehrere zusammenfassende Statistiken auf einmal erstellen und zusammenfassende Statistiken zwischen Gruppen vergleichen. Um dies zu erreichen, bietet das Paket `dplyr` aus dem `tidyverse` einige hilfreiche Funktionen. Lassen Sie uns nun den `df_eng`-Datensatz verwenden, um diese `dplyr`-Verben kennenzulernen.

### `dplyr::summarise`

Die Funktion `summarise()` von `dplyr` berechnet Zusammenfassungen von Daten, aber wir m√ºssen ihr sagen, *was* sie berechnen soll, und f√ºr welche Variable(n). Die Funktion `n()` liefert zum Beispiel die Anzahl der Beobachtungen (nur wenn sie innerhalb von `summarise()` oder `mutate()` verwendet wird). Lassen Sie uns zun√§chst pr√ºfen, wie viele Beobachtungen wir im Datensatz `df_eng` haben:

```{r}
#| output-location: fragment
df_eng |>
  summarise(N = n())
```

Werfen wir nun einen Blick auf das Histogramm von `rt_lexdec`, der Variable, die die lexikalische Entscheidungsantwortzeit in Millisekunden enth√§lt:

```{r}
df_eng |> 
  ggplot() +
  aes(x = rt_lexdec) +
  geom_histogram()
```

Wir sehen, dass die Antwortzeit zwischen 500 ms und 1320 ms liegt, wobei die meisten Antworten zwischen 550 ms und 900 ms liegen. Wir sehen auch eine *bimodale* Verteilung, d. h. es gibt zwei Modi (zwei Spitzen). Der allgemeine Modus liegt bei 700 ms (500 Beobachtungen), mit einer zweiten Spitze bei 600 ms (~420 Beobachtungen).

Wir k√∂nnen auch mehrere Berechnungen auf einmal durchf√ºhren. Lassen Sie uns auch den Mittelwert und die Standardabweichung der lexikalischen Entscheidungsaufgabe (`rt_lexdec`, in Millisekunden) berechnen.

```{r}
#| output-location: fragment
df_eng |>
  summarise(mean_lexdec = mean(rt_lexdec, na.rm=T),
            sd_lexdec = sd(rt_lexdec, na.rm = T),
            N = n()) 
```

Jetzt sehen wir, dass die durchschnittliche lexikalische Entscheidungsantwortzeit `r round(mean(df_eng$rt_lexdec),1)` ms betrug, mit einer Standardabweichung von `r round(sd(df_eng$rt_lexdec),1)`.

Und wir k√∂nnen Berechnungen mit typischen mathematischen Operatoren (z.B. `+, -, /, *, ^` ...) und/oder Funktionen angeben. Was war der Unterschied zwischen der l√§ngsten und der k√ºrzesten lexikalischen Entscheidungsantwortzeit?

```{r}
#| output-location: fragment
df_eng |>
  summarise(range_lexdec = max(rt_lexdec) - min(rt_lexdec))
```

::: callout-tip

### Fehlende Werte

Einige Berechnungen sind nicht m√∂glich, wenn Werte fehlen. Die Variable `rt_naming` hat einen fehlenden Wert. Dies ist in der Ausgabe der Funktion `summary()` zu sehen, die vor der Berechnung der zusammenfassenden Statistik alle `NA`-Werte l√∂scht.

```{r}
#| output-location: column-fragment
df_eng |>
  select(rt_lexdec, rt_naming) |>
  summary()
```

Die Funktion `mean()` entfernt jedoch *nicht* die `NA`-Werte.

```{r}
#| output-location: column-fragment
df_eng |>
  summarise(mean_naming = mean(rt_naming))
```

Was tun wir mit fehlenden Werten? Bei der Arbeit mit realen Daten ist es nicht trivial, wie wir mit fehlenden Werten umgehen. Wir k√∂nnten z. B. alle `NA`-Werte in `0` umwandeln, wenn wir wollen, dass sie zur Berechnung des Mittelwerts beitragen. Meistens wollen wir sie jedoch einfach entfernen.

Wir k√∂nnen dies leicht mit dem `dplyr`-Verb `drop_na()` tun:

```{r}
df_eng |>
  drop_na() |>
  summarise(mean_naming = mean(rt_naming))
```

:::

## Gruppierung von Variablen

Wir wollen jedoch nicht immer nur die zusammenfassenden Statistiken f√ºr einen gesamten Datensatz kennen. Normalerweise wollen wir bestimmte Gruppen *vergleichen* (z. B. Vergleich der Reaktionszeiten bei lexikalischen Entscheidungen zwischen Altersgruppen)

### `.by =`

Das semi-neue (und experimentelle) Argument `.by =` in `summarise()` berechnet unsere Berechnungen auf gruppierten Teilmengen der Daten. Es nimmt eine `Variable` (d.h. einen Spaltennamen) und gruppiert nach den Stufen dieser Variable.


```{r}
#| output-location: fragment
df_eng |>
  drop_na() |>
  summarise(mean_lexdec = mean(rt_lexdec),
            sd_lexdec = sd(rt_lexdec),
            N = n(),
            .by = age_subject) |>
  arrange(mean_lexdec)
```

### Gruppieren nach mehreren Variablen

- Wir k√∂nnen auch nach mehreren Variablen gruppieren
  + daf√ºr brauchen wir `concatenate` (`c()`)

```{r}
#| output-location: column-fragment
#| code-line-numbers: "7"
df_eng |>
  drop_na() |>
  summarise(mean_lexdec = mean(rt_lexdec),
            sd_lexdec = sd(rt_lexdec),
            N = n(),
            .by = c(age_subject, word_category)) |>
  arrange(age_subject)
```

::: callout-note
### `group_by()`

- Anstelle des neuen `.by`-Arguments k√∂nnen wir das `dplyr`-Verb `group_by()` und `ungroup()` verwenden
  + Ich bevorzuge das neue `.by`, weil es die Gruppierung lokal h√§lt (keine Notwendigkeit f√ºr `ungroup()`)
  + Behalten Sie dies im Hinterkopf, Sie k√∂nnten `group_by()` in freier Wildbahn sehen

```{r}
#| code-line-numbers: "4,9"
df_eng |>
  group_by(age_subject, word_category) |> 
  summarise(mean_lexdec = mean(rt_lexdec),
            sd_lexdec = sd(rt_lexdec),
            N = n()) |> 
  ungroup() |> 
  arrange(age_subject)
```
:::

## Anscombes Quartett

Francis Anscombe erstellte 1973 vier Datens√§tze, um zu veranschaulichen, wie wichtig es ist, Daten zu visualisieren, bevor man sie analysiert und ein Modell erstellt. Diese vier Diagramme stellen 4 Datens√§tze dar, die alle einen nahezu identischen Mittelwert und eine Standardabweichung, aber sehr unterschiedliche Verteilungen aufweisen.

```{r}
#| echo: false
## https://michael-franke.github.io/intro-data-analysis/Chap-02-04-Anscombe-example.html
data("anscombe")
tidy_anscombe <- anscombe |>
  pivot_longer(
    everything(),
    names_pattern = "(.)(.)",      
    names_to = c(".value", "grp")  
  ) |>
  mutate(grp = paste0("Group ", grp))
```

```{r}
#| label: tbl-anscombe
#| tbl-cap: Summary stats of Anscombe's quratet datasets
#| echo: false
tidy_anscombe |>
  group_by(grp) |>
  summarise(
    mean_x    = mean(x),
    mean_y    = mean(y),
    min_x     = min(x),
    min_y     = min(y),
    max_x     = max(x),
    max_y     = max(y),
    crrltn    = cor(x, y)
  ) |>
  knitr::kable() |>
  kableExtra::kable_styling(font_size=20)
```

```{r}
#| label: fig-anscombe
#| fig-cap: Plots of Anscombe's quratet distributions
#| echo: false
tidy_anscombe |>
  ggplot(aes(x, y)) +
    geom_smooth(method = lm, se = F, color = "darkorange") +
    geom_point(size = 2) +
    scale_y_continuous(breaks = scales::pretty_breaks()) +
    scale_x_continuous(breaks = scales::pretty_breaks()) +
    labs(
      title = "Anscombe's Quartet", x = NULL, y = NULL,
      subtitle = bquote(y == 0.5 * x + 3 ~ (r %~~% .82) ~ "for all groups")
    ) +
    facet_wrap(~grp, ncol = 2, scales = "free_x") +
    theme(strip.background = element_rect(fill = "#f2f2f2", colour = "white")) +
  theme_minimal()
```

### DatasaurRus

Das Paket datasauRus [@datasauRus-package] enth√§lt einige weitere Datens√§tze, die √§hnliche `Mittelwerte` und `sd`, aber unterschiedliche Verteilungen aufweisen, die in @tbl-datasauRus angegeben sind.

```{r}
pacman::p_load("datasauRus")
```

```{r}
#| label: tbl-datasauRus
#| tbl-cap: Summary stats of datasauRus datasets
#| output-location: column-fragment
datasaurus_dozen |>
    group_by(dataset) |>
    summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
    ) |>
  knitr::kable() |>
  kableExtra::kable_styling(font_size = 20)
```

Wenn wir die Datens√§tze grafisch darstellen, sehen sie alle sehr unterschiedlich aus (@fig-datasauRus)!

```{r}
#| label: fig-datasauRus
#| fig-cap: Plots of datasauRus dataset distributions
#| out-width: "50%"
#| fig-asp: 1
#| echo: false
ggplot(datasaurus_dozen, aes(x = x, y = y, colour = dataset))+
  geom_point() +
  theme_void() +
  theme(legend.position = "none")+
  facet_wrap(~dataset, ncol = 3)
```

Der Punkt hier ist: ***Stellen Sie Ihre Daten immer grafisch dar*** und betrachten Sie nicht nur die beschreibenden Statistiken!!! Beides ist sehr wichtig f√ºr das Verst√§ndnis Ihrer Daten. Wir haben bereits gesehen, wie wir unsere Rohdaten mithilfe von Histogrammen, Dichteplots, Balkendiagrammen und Streudiagrammen darstellen k√∂nnen. N√§chste Woche werden wir uns ansehen, wie wir unsere zusammenfassenden Statistiken darstellen und wie wir die Rohdaten in die Darstellung mit mehrteiligen Diagrammen einbeziehen k√∂nnen.

## Lernziele üèÅ {.unnumbered .unlisted}

Today we learned...

- √ºber Ma√üe der zentralen Tendenz ‚úÖ
- √ºber Streuungsma√üe ‚úÖ
- wie man die Funktion `summarise()` von `dplyr` verwendet ‚úÖ
- wie man Zusammenfassungen nach Gruppen erstellt ‚úÖ

## Hausaufgaben

::: nonincremental

1. Berechnen Sie die Standardabweichung der Werte `152, 19, 1398, 67, 2111`, ohne die Funktion `sd()` zu benutzen.
    + zeige deine Arbeit. Die folgende R-Syntax k√∂nnte n√ºtzlich sein (je nachdem, wie Sie es machen wollen):
      + `c()`
      + `mean()`
      + `x^2` berechnet das Quadrat eines Wertes (hier, `x`) 
      + `sqrt()` berechnet die Quadratwurzel
      + `length()` liefert die Anzahl der Beobachtungen in einem Vektor
      
```{r}
#| echo: false
#| eval: false
x <- c(152, 19, 1398, 67, 2111)
sqrt((sum((x-mean(x))^2))/(length(x)-1))
```

2. Benutze die Funktion `sd()`, um die Standardabweichung der obigen Werte zu drucken. Haben Sie es richtig gemacht?
3.  Benutze `summarise`, um den Mittelwert, die Standardabweichung und die Anzahl der Beobachtungen f√ºr `rt_naming` im `df_lexdec` Datenrahmen zu drucken.
    - Hinweis: M√ºssen Sie fehlende Werte (`NA`) entfernen?
4.  Machen Sie dasselbe, aber f√ºgen Sie das Argument `.by()` hinzu, um die mittlere Reaktionszeit der Benennungsaufgabe (`rt_naming`) pro Monat zu ermitteln
    - Ordnen Sie die Ausgabe nach der mittleren Antwortzeit f√ºr die Namensgebung an.

## Session Info {.unnumbered}

```{r}
#| eval: false
#| echo: false
RStudio.Version()$version
RStudio.Version()$release_name
```

Erstellt mit `r R.version.string` (`r R.version$nickname`) und RStudioversion 2023.9.0.463 (Desert Sunflower).

```{r}
sessionInfo()
```

## Literaturverzeichnis {.unlisted .unnumbered visibility="uncounted"}

::: {#refs custom-style="Bibliography"}
:::